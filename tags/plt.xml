<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>osa1.net - Posts tagged plt</title>
    <link href="http://osa1.net/tags/plt.xml" rel="self" />
    <link href="http://osa1.net" />
    <id>http://osa1.net/tags/plt.xml</id>
    <author>
        <name>Ömer Sinan Ağacan</name>
        <email>omeragacan@gmail.com</email>
    </author>
    <updated>2025-06-28T00:00:00Z</updated>
    <entry>
    <title>Why I'm excited about effect systems</title>
    <link href="http://osa1.net/posts/2025-06-28-why-effects.html" />
    <id>http://osa1.net/posts/2025-06-28-why-effects.html</id>
    <published>2025-06-28T00:00:00Z</published>
    <updated>2025-06-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Imagine a programming language where you can have full control over whether and how functions, modules, or libraries interact with shared resources like the scheduler for threading, the file system and other OS-level resources like sockets and other file descriptors, timers for things like delaying the current thread for timed updates or scheduling timed callbacks, and so on.</p>
<p>In this language, a function (or module, library, …) needs to declare its interactions with the shared resources in its type.</p>
<p>When a function accesses e.g. the file system, the caller has full control over how it accesses the file system. All file system access functions can be specified (or overridden if they have a default) by the caller.</p>
<p>Furthermore, assume that this language can also suspend functions and resume them later, similar to <code>async</code> functions in many languages today, which are paused and resumed later when the value of e.g. a <code>Future</code> becomes available.</p>
<p>This language lends itself to a more composable system compared to anything that we have today. This system is composable, flexible, and testable by default.</p>
<p>If you think about it, it’s really strange that today we find it acceptable that I can import a library, and the library can spawn threads, use the file system, block the current thread with things like <code>sleep</code> or with blocking IO operations, and I have no control over it.</p>
<p>Most of the time, this kind of thing will be at least documented, but if I use a library that fundamentally needs these things, unless the library accounts for my use case, I may not be able to use it in my application.</p>
<p>For example, maybe it spawns threads but I want it to use my own thread pool where in addition to limiting number of threads, I attach priorities to threads and schedule based on priorities.</p>
<p>Or, maybe I have a library that builds/compiles things by reading files, processing them, and generating files. If I have control over the file system API that the library uses, it takes no effort (e.g. no planning ahead of time) to test this library using an in-memory file system, in parallel, without worrying about races and IO bottlenecks. I don’t have to consider testing scenarios in the library and structure my code accordingly.</p>
<p>Or, maybe I have code that polls some resources, and maybe posts periodic updates. It creates a thread that does the periodic work, and <code>sleep</code>s. With control over threads, schedulers, and timers, I can fast-forward in time (to the next event) in my tests without actually waiting for <code>sleep</code>s and any other timed events, to test my code quickly.</p>
<p>These are some of the things I get to do with an effect system.</p>
<h2 id="whats-in-an-effect-system">What’s in an effect system?</h2>
<p>At a high-level, an effect system has two components: (1) a type system, and (2) runtime features.</p>
<p>These two components are somewhat orthogonal: you can have one without the other, depending on what you want to make possible.</p>
<p>In the systems available today, (1) typically involves adding a type component to function types, for the effects a function can invoke.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>For example, in <a href="https://koka-lang.github.io/">Koka</a>, if you define stdin/stdout operations in an effect named <code>console</code>, and have a function that uses the <code>console</code> effects, the function’s type signature looks like this:</p>
<pre><code>fun sayHi() -&gt; console ()
  print(&quot;hi&quot;)</code></pre>
<p>This type says <code>sayHi</code> returns unit (<code>()</code>) and uses the <code>console</code> effect.</p>
<p>(2) typically involves capturing the continuation of the effect invocation and passing it to a “handler”. Depending on the system, the handler can then do things (e.g. memory operations, invoking other effects) and “jump” to (or “tail call”) the continuation with the value returned by the invoked effect.</p>
<p>With the <code>console</code> effect above, a handler may just record the printed string in a data structure, which can then be used for testing. Another handler may actually write to <code>stdout</code>, which would then be used when you run the application.</p>
<p>Depending on the exact (1) and (2) features, you get to do different things. The current effect systems in various languages support different (1) and (2) features, and there are some systems that omit one of (1) or (2) entirely.</p>
<p>For the purposes of this blog post, we won’t consider the full spectrum of features you can have, and what those features allow.</p>
<h2 id="example-a-simple-grep-implementation-in-koka">Example: a simple grep implementation in Koka</h2>
<p>There isn’t a language today that gives us everything we need for the use cases I describe at the beginning.</p>
<p>However among the languages that we have, Koka comes close, so we’ll use Koka for a simple example.</p>
<p>Imagine a simple “grep” command that takes a string and a list of file paths as arguments, and finds occurrences of the string in the file contents and reports them.</p>
<p>In Koka, the standard library definitions for these “effects” could look like this:</p>
<pre><code>effect fs
  ctl read-file(path: path): string

effect console
  ctl println(s: string): ()</code></pre>
<p>Using these effects, the code that reads the files and searches for the string is not different from how it would look like in any other “functional”<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> language:</p>
<pre><code>fun search(pattern: string, files: list&lt;string&gt;): &lt;fs, console&gt;()
  val pattern-size = pattern.count()
  files.foreach fn(file)
    val contents = read-file(file.path)
    val parts = contents.split(pattern)
    report-matches(file, pattern-size, parts)

fun report-matches(file: string, pattern-size: int, parts: list&lt;string&gt;): &lt;console&gt;()
  if parts.length == 0 then
    return ()

  println(file)

  var line := 0
  var column := 0
  parts.init.foreach fn(part)
    part.vector.foreach fn(char)
      if char == &#39;\n&#39; then
        line := line + 1
        column := 0
      else
        column := column + 1

    println((line + 1).show ++ &quot;:&quot; ++ (column + 1).show)</code></pre>
<p>When calling <code>search</code>, I have to provide handlers for <code>fs</code> and <code>console</code> effects.</p>
<p>In the executable that I generate for users, I can use handlers that do actual file system operations and print to <code>stdout</code>:</p>
<pre><code>val fs-io = handler
  ctl read-file(path: path)
    resume(read-text-file(path))

val console-terminal = handler
  ctl println(s: string)
    write-to-stdout(s)
    resume(())</code></pre>
<p>In the tests, I can use a <code>read-file</code> handler that reads from an in-memory map, and add printed lines to a list, to compare with the expected test outputs:</p>
<pre><code>struct test-case
  files: list&lt;test-file&gt;
  pattern: string
  expected-output: list&lt;string&gt;

struct test-file
  path: path
  contents: string

val test-cases: list&lt;test-case&gt; = [
  Test-case(
    files = [Test-file(&quot;file1&quot;.path, &quot;test\ntest&quot;), Test-file(&quot;file2&quot;.path, &quot;a\n test\nb&quot;)],
    pattern = &quot;test&quot;,
    expected-output = [&quot;file1&quot;, &quot;1:1&quot;, &quot;2:1&quot;, &quot;file2&quot;, &quot;2:2&quot;]
  ),
]

fun test(): &lt;exn&gt;()
  var printed-lines := Nil

  test-cases.foreach fn (test)
    with handler
      ctl read-file(path_: path)
        match test.files.find(fn (file) file.path.string == path_.string)
          Just(file) -&gt; resume(file.contents)
          Nothing -&gt; throw(&quot;file not found&quot;, ExnAssert)

    with handler
      ctl println(s: string)
        printed-lines := Cons(s, printed-lines)
        resume(())

    search(test.pattern, test.files.map(fn (file) file.path.string))

    if printed-lines.reverse != test.expected-output then
      throw(&quot;unexpected test output&quot;, ExnAssert)</code></pre>
<p>You can see the full example <a href="https://gist.github.com/osa1/a5e7fdfa30d69125970c0797c525ede2">here</a>.</p>
<h2 id="i-can-already-do-this-in-language-x-using-libraryframework-y">I can already do this in language X using library/framework Y?</h2>
<p>The point with effect systems is that, you don’t get a composable and testable system <em>when you design for it</em>, you get it <em>by default</em>.</p>
<p>If you implement a library that uses the file system, I can run it with an in-memory file system, or intercept file accesses to prevent certain things, or log certain things, and so on, regardless of whether you designed for it or not.</p>
<p>The Koka code above does not demonstrate this fully, and there’s no system available today that can. I’m just using whatever is available today.</p>
<p>In an ideal system, you would have to go out of your way to have access to the filesystem without using an effect, rather than the other way around.</p>
<p>When comparing languages we never talk about what’s possible: almost everything is possible in almost every general purpose programming language.</p>
<p>What we’re talking about is things like: the idiomatic and performant way of doing things.</p>
<p>The language where what I talk about is idiomatic and performant does not exist today.</p>
<h2 id="how-do-we-know-that-this-ideal-system-is-possible">How do we know that this ideal system is possible?</h2>
<p>We mentioned that the two components of an effect system are somewhat orthogonal. In the design that I have in mind (more on this below), without the type system part of it you still get 90% of the benefits. So let’s focus on the runtime parts.</p>
<p>What you need for a flexible effect system is, <em>conceptually</em>, a way of suspending the stack when calling an effect, passing the suspended stack (you may want to call it a “continuation”) to the handler for the effect invoked.</p>
<p>This kind of thing is already possible in many of the high-level languages today. If your language supports lightweight threads (green threads, fibers, etc.), coroutines, generators, or similar features where the code is suspended when it does something like <code>await</code> or <code>yield</code>, and then resumed later, you already have the runtime features for a flexible effect system.</p>
<h2 id="for-me-its-about-composable-and-testable-libraries">For me, it’s about composable and testable libraries</h2>
<p>I deliberately didn’t mention in this blog post so far that effect systems generalize features like async/await, iterators/generators, exceptions, and many other features.</p>
<p>The reason is because, as a user, I don’t care whether these features are implemented using an effect system under the hood, or in some other ways. For example, Dart has all of these features, but it doesn’t use an effect system to implement them. As a user, it doesn’t matter to me as long as I have the features.</p>
<p>Instead, what I’m more interested in as a user is: how it influences or affects library design, and what it allows me to do at a high level, in large code bases.</p>
<p>However it would be a shame to not mention that, yes, effect systems generalize all these features, and more. The paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/asynceffects-msr-tr-2017-21.pdf">“Structured Asynchrony with Algebraic Effects”</a> shows how these features can be implemented in Koka.</p>
<h2 id="to-be-continued">To be continued</h2>
<p>Some of the recent discussions online about effect systems left me somewhat dissatisfied, because most posts seem to focus on small-scale benefits of effect systems, and I wanted to share my incomplete (but hopefully not incoherent!) perspective on effect systems.</p>
<p>In the future posts I’m hoping to cover some of the open problems when designing such a system.</p>
<hr />
<p>Thanks to <a href="https://github.com/TimWhiting/">Tim Whiting</a> for reviewing a draft of this blog post.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>This is a somewhat rough estimate on what these effect types in function types indicate. In practice it’s more complicated than “effects the function invokes”: if you read it as that you fail to explain some of the type errors, or why some code of the code type checks. More on this (hopefully) in a future post.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>“Functional” in quotes because I don’t think that word means much these days. Maybe more on this later.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></summary>
</entry>
<entry>
    <title>Changes to variants in Fir</title>
    <link href="http://osa1.net/posts/2025-06-12-fir-new-variants.html" />
    <id>http://osa1.net/posts/2025-06-12-fir-new-variants.html</id>
    <published>2025-06-12T00:00:00Z</published>
    <updated>2025-06-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In the previous two posts (<a href="https://osa1.net/posts/2025-01-18-fir-error-handling.html">1</a>, <a href="https://osa1.net/posts/2025-04-17-throwing-iterators-fir.html">2</a>) we looked at how Fir utilizes variant types for exceptions tracked at function types, aka. checked exceptions.</p>
<p>As I wrote more and more Fir, it quickly became obvious that the current variant type design is just too verbose and difficult to use.</p>
<p>To see the problems, consider a JSON parsing library. This library may throw a parse error when the input is not valid. Before the recent changes, the parsing function would look like this:</p>
<pre><code>parse(input: Str) Json / [ParseError, ..exn]:
    ...
    # When things go wrong:
    throw(~ParseError)
    ...</code></pre>
<p>(As a reminder: <code>[ParseError, ..exn]</code> part is the variant type for the exceptions that this function throws. <code>ParseError</code> is a label for the exception value, and it has no fields. <code>..exn</code> part is the row extension, allowing this function to be called in functions that throw other exceptions.)</p>
<p>This error type is not that useful, because the label <code>ParseError</code> doesn’t contain any information like the error location.</p>
<p>When we start adding fields to it, things quickly get verbose:</p>
<pre><code>parse(input: Str) Json / [ParseError(errorByteIdx: U32, msg: Str), ..exn]:
    ...
    # When things go wrong:
    throw(~ParseError(
        errorByteIdx = ...,
        msg = ...,
    ))
    ...</code></pre>
<p>Now every function that propagates this error needs to include the same fields in the label.</p>
<p>As a second problem, suppose that there’s another library that parses YAML, which also throws an exception with the same label <code>ParseError</code>. Because we can’t have the same label multiple times in a variant (as we would have no way of distinguishing them in pattern matching), we can’t call both library functions in the same function, doing that would result in a type error about duplicate labels with different fields.</p>
<p><em>For the verbosity of labels with fields:</em> we could have type synonyms for variant alternatives, but this doesn’t solve the problem with using the same labels in different libraries.</p>
<p><em>For the label conflicts:</em> we could manually make the labels unique, maybe by including library name in the label, like <code>JsonParseError(...)</code> and <code>YamlParseError(...)</code>.</p>
<p>This makes labels longer, and it doesn’t guarantee that conflicts won’t occur. For example, if we allow linking different versions of the same library in a program, two different versions of the library might have the same label <code>JsonParseError</code>, but with different fields.</p>
<p>A combination of more creative features may solve the problem completely, but features add complexity to the language, even when they work well together. If possible, it would be preferable to improve the utility of existing features instead.</p>
<p>As a solution that uses only existing features, Fir variants now hold named types. The example above now looks like this:</p>
<pre><code>type ParseError:
    errorByteIdx: U32
    msg: Str

parse(input: Str) Json / [ParseError, ..exn]:
    ...
    # When things go wrong:
    throw(~ParseError(
        errorByteIdx = ...,
        msg = ...,
    ))
    ...</code></pre>
<p>(A named type in Fir is anything other than a record or variant. See <a href="https://osa1.net/posts/2021-04-10-sums-and-products.html">this post</a> for more details on named and anonymous types.)</p>
<p>From the type checker’s point of view, a variant is still a map of labels to fields, but we now implicitly use the fully qualified names of types as the labels.</p>
<p>So the variant above looks like this to the type checker: <code>[Label("P.M.ParseError")(P.M.ParseError), ...exn]</code>, where <code>P</code> is the package name and <code>M</code> is the module path to the type <code>ParseError</code>, and <code>(...)</code> part after the label indicates a single positional field.</p>
<p>This solves all of the problems with labels, and has several of other advantages:</p>
<ul>
<li><p>Named types are concise as we don’t have to list all of the fields every time we mention them.</p></li>
<li><p>Named types and their fields can be documented.</p></li>
<li><p>Named types can have methods.</p></li>
<li><p>Named types can be extended with more fields without breaking backwards compatibility. So now it’s possible to add more fields to <code>ParseError</code> without breaking existing users.</p></li>
<li><p>A type with the same name defined in different packages or even modules can now be used in the same variant type.</p>
<p>(When showing a variant type to the user in an error message, we add package and module prefixes as necessary to disambiguate.)</p></li>
<li><p>If I import a named type <code>Foo</code> as <code>Bar</code> in a module, I can use <code>Bar</code> in my variant types and it would be seen as <code>Foo</code> elsewhere.</p></li>
<li><p>Named types can implement traits. This opens up possibilities for implicitly deriving traits for variant types.</p></li>
</ul>
<p>One implication of using the fully qualified path of a type as the label is that we don’t allow the same type constructor applied to different types in the same variant. E.g. <code>[Option[U32], Option[Bool]]</code> is not allowed.</p>
<p>This is the same limitation with duplicate labels in the original version, where <code>[Label1(x: U32), Label1(y: Str)]</code> wasn’t allowed. I don’t think this will be an issue in practice.</p>
<p>Pattern matching works as before, but we now omit the labels, as they’re inferred from the types of patterns. Here’s a contrived example demonstrating the syntax:</p>
<pre><code>f() / [Option[U32], ..exn]:
    throw(~Option.None)

g() / [Result[Str, Bool], ..exn]:
    throw(~Result.Ok(Bool.True))

main():
    match try({
        f()
        g()
    }):
        Result.Ok(()): print(&quot;OK&quot;)
        Result.Err(~Option.None): print(&quot;NA&quot;)
        Result.Err(~Result.Ok(bool)): print(&quot;Bool: `bool`&quot;)
        Result.Err(~Result.Err(str)): print(&quot;Str: `str`&quot;)</code></pre>
<p>This is essentially the same as before, just with variant labels omitted.</p>
<p>To keep things simple, I haven’t implemented supporting literals in variant syntax yet: <code>~123</code>, <code>~"Hi"</code>, or <code>~'a'</code> doesn’t work yet. It wouldn’t be too much work to implement this, but I don’t need it right now.</p>
<hr />
<p>In retrospect, using named types in variants is such an obvious improvement, with practically no downsides. But it took a few thousands of lines of Fir for me to realize this.</p>
<p>If I discover cases where explicit labels are useful, the current design is not incompatible with the old one. The type checker still uses the same variant representation, with a label and a field for each alternative (with multiple fields are represented as records). It shouldn’t be too difficult to support both named types and labels in variant types.</p>
<p>This new design improves error handling quite a bit, but there are still a few problems we need to solve. In a future post I’m hoping to talk about the issues with adding a type component to the function types for exceptions.</p>]]></summary>
</entry>
<entry>
    <title>Throwing iterators in Fir</title>
    <link href="http://osa1.net/posts/2025-04-17-throwing-iterators-fir.html" />
    <id>http://osa1.net/posts/2025-04-17-throwing-iterators-fir.html</id>
    <published>2025-04-17T00:00:00Z</published>
    <updated>2025-04-17T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Recently I’ve been working on extending <a href="https://github.com/fir-lang/fir">Fir</a>’s <code>Iterator</code> trait to allow iterators to throw exceptions.</p>
<p>It took a few months of work, because we needed multiple parameter traits for it to work, which took <a href="https://github.com/fir-lang/fir/pull/73">a few months of hacking</a><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> to implement.</p>
<p>Then there was a lot of bug fixing and experimentation, but it finally works, and I’m excited to share what you can do with Fir iterators today.</p>
<p>As usual, link to the online interpreter with all of the code in this post is at the end.</p>
<p>Before starting, I recommend reading the <a href="https://osa1.net/posts/2025-01-18-fir-error-handling.html">previous post</a>. It’s quite short and it explains the basics of error handling in Fir.</p>
<p>Previous post did not talk about traits at all, so in short, traits in Fir is the same feature as Rust’s traits and Haskell’s typeclasses<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>The <code>Iterator</code> trait in Fir is also the same as the trait with the same name in Rust, and it’s used the same way, in <code>for</code> loops.</p>
<p>Here’s a simple example of what you can do with iterators:</p>
<pre><code>sum(nums: Vec[U32]): U32
    let result: U32 = 0
    for i: U32 in nums.iter():
        result += i
    result</code></pre>
<p>The <code>Vec.iter</code> method returns an iterator that returns the next element every time its <code>next</code> method is called. <code>for</code> loop implicitly calls the <code>next</code> method to get the next element, until the <code>next</code> method returns <code>Option.None</code>.</p>
<p>Similar to Rust’s <code>Iterator</code>, Fir’s <code>Iterator</code> trait also comes with a <code>map</code> method that allows mapping iterated elements:</p>
<pre><code>parseSum(nums: Vec[Str]): U32
    let result: U32 = 0
    for i: U32 in nums.iter().map(parseU32):
        result += i
    result

parseU32(s: Str): U32
    if s.len() == 0:
        panic(&quot;Empty input&quot;)

    let result: U32 = 0

    for c: Char in s.chars():
        if c &lt; &#39;0&#39; || c &gt; &#39;9&#39;:
            panic(&quot;Invalid digit&quot;)

        let digit = c.asU32() - &#39;0&#39;.asU32()

        result *= 10
        result += digit

    result</code></pre>
<p>This version takes a <code>Vec[Str]</code> as argument, and parses the elements as integers.</p>
<p>The problem with this version is that it panics on unexpected cases: invalid digits and empty input, and it ignores overflows.</p>
<p>Until now, there wasn’t a convenient way to use the <code>Iterator</code> API and <code>for</code> loops to do this kind of thing, while also propagating exceptions to the call site of the <code>for</code> loop, or to the loop variable. But now we can do this: (<code>parseU32Exn</code> is from the previous post)</p>
<pre><code>parseSum(nums: Vec[Str]): [Overflow, EmptyInput, InvalidDigit, ..errs] U32
    let result: U32 = 0
    for i: U32 in nums.iter().map(parseU32Exn):
        result += i
    result</code></pre>
<p>Errors that <code>parseU32Exn</code> can throw are now implicitly thrown from the <code>for</code> loop and reflected in the function’s type.</p>
<p>This new <code>Iterator</code> API is flexible enough to allow handling some (or all) of the exceptions thrown by a previous iterator. For example, here’s how we can handle <code>InvalidDigit</code> exceptions and yield <code>0</code> instead:</p>
<pre><code>parseSumHandleInvalidDigits(nums: Vec[Str]): [Overflow, EmptyInput, ..errs] U32
    let result: U32 = 0
    for i: U32 in nums.iter().map(parseU32Exn).mapResult(handleInvalidDigit):
        result += i
    result

handleInvalidDigit(parseResult: Result[[InvalidDigit, ..errs], Option[U32]]): [..errs] Option[U32]
    match parseResult:
        Result.Ok(result): result
        Result.Err(~InvalidDigit): Option.Some(0u32)
        Result.Err(other): throw(other)</code></pre>
<p><code>InvalidDigit</code> is no longer in the exception type of the function because <code>mapResult(handleInvalidDigit)</code> handles them.</p>
<p>We can also convert exceptions thrown by an iterator to <code>Result</code> values:</p>
<pre><code>parseSumHandleInvalidDigitsLogRest(nums: Vec[Str]): U32
    let result: U32 = 0
    for i: Result[[Overflow, EmptyInput], U32] in \
            nums.iter().map(parseU32Exn).mapResult(handleInvalidDigit).try():
        match i:
            Result.Err(~Overflow): printStr(&quot;Overflow&quot;)
            Result.Err(~EmptyInput): printStr(&quot;Empty input&quot;)
            Result.Ok(i): result += i
    result</code></pre>
<p>This function no longer has an exception type, because exceptions thrown by the iterator are passed to the loop variable.</p>
<p>In summary, we started with an iterator that doesn’t throw (<code>nums.iter()</code>), mapped it with a function that throws (<code>map(parseU32Exn)</code>), which made the <code>for</code> loop propagate the exceptions thrown by the map function. We then handled one of the exceptions (<code>mapResult(handleInvalidDigit)</code>), and finally, we handled all of the exceptions and started passing a <code>Result</code> value to the loop variable (<code>try()</code>).</p>
<p>The function’s exception type was updated each time to reflect the exceptions thrown by the function.</p>
<p>Once we had multiple parameter traits (which are important even without exceptions, and something we were going to implement anyway), no language features were needed specifically for the throwing iterators API that composes. Changes in the <code>for</code> loop type checking were necessary to allow throwing iterators in <code>for</code> loops. Composing iterators like <code>iter().map(...).mapResult(...).try()</code> in the examples above did not require any changes to the trait system or exceptions.</p>
<p>This demonstrates that Fir traits and exceptions work nicely together.</p>
<p>You can try the code in this blog post <a href="https://fir-lang.github.io/?file=ThrowingIter.fir">in your browser</a>.</p>
<h1 id="im-looking-for-contributors">I’m looking for contributors</h1>
<p>I’m planning a blog post on my vision of Fir, why I think it matters, and a roadmap, but if you already like what you see, know a thing or two about implementing programming languages, and have the time to energy to contribute to a new language, please don’t hesitate to reach out!</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>I started this work in one country, and when finished, I was living in another! This PR really felt like an eternity to finish.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Implementation-wise, it’s closer to Rust than Haskell as we monomorphise.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></summary>
</entry>
<entry>
    <title>Error handling in Fir</title>
    <link href="http://osa1.net/posts/2025-01-18-fir-error-handling.html" />
    <id>http://osa1.net/posts/2025-01-18-fir-error-handling.html</id>
    <published>2025-01-18T00:00:00Z</published>
    <updated>2025-01-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>A while ago I came up with an <a href="https://gist.github.com/osa1/38fd51abe5247462eddb7d014f320cd2">“error handling expressiveness benchmark”</a>, some common error handling cases that I want to support in <a href="https://github.com/fir-lang/fir">Fir</a>.</p>
<p>After 7 months of pondering and hacking, I think I designed a system that meets all of the requirements. Error handling in Fir is safe, expressive, and convenient to use.</p>
<p>Here are some examples of what we can do in Fir today:</p>
<p>(Don’t pay too much attention to type syntax for now. Fir is still a prototype, the syntax will be improved.)</p>
<p>When we have multiple ways to fail, we don’t have to introduce a sum type with all the possible ways that we can fail, we can use variants:</p>
<pre><code>parseU32(s: Str): Result[[InvalidDigit, Overflow, EmptyInput, ..r], U32]
    if s.len() == 0:
        return Result.Err(~EmptyInput)

    let result: U32 = 0

    for c in s.chars():
        if c &lt; &#39;0&#39; || c &gt; &#39;9&#39;:
            return Result.Err(~InvalidDigit)

        let digit = c.asU32() - &#39;0&#39;.asU32()

        result = match checkedMul(result, 10):
            Option.None: return Result.Err(~Overflow)
            Option.Some(newResult): newResult

        result = match checkedAdd(result, digit):
            Option.None: return Result.Err(~Overflow)
            Option.Some(newResult): newResult

    Result.Ok(result)</code></pre>
<p>An advantage of variants is, in pattern matching, we “refine” types of binders to drop handled variants from the type. This allows handling some of the errors and returning the rest to the caller:</p>
<pre><code>defaultEmptyInput(res: Result[[EmptyInput, ..r], U32]): Result[[..r], U32]
    match res:
        Result.Err(~EmptyInput): Result.Ok(0u32)
        Result.Err(other): Result.Err(other)
        Result.Ok(val): Result.Ok(val)</code></pre>
<p>Here <code>EmptyInput</code> is removed from the error value type in the return type. The caller does not need to handle <code>EmptyInput</code>.</p>
<p>(We don’t refine types of variants nested in other types for now, so the last two branches cannot be replaced with <code>other: other</code> for now.)</p>
<p>Another advantage is that they allow composing error returning functions that return different error types:</p>
<p>(Fir supports variant constructors with fields, but to keep things simple we don’t use them in this post.)</p>
<pre><code>readFile(s: Str): Result[[IoError, ..r], Str]
    # We don&#39;t have the standard library support for file IO yet, just return
    # an error for now.
    Result.Err(~IoError)

parseU32FromFile(filePath: Str): Result[[InvalidDigit, Overflow, EmptyInput, IoError, ..r], U32]
    let fileContents = match readFile(filePath):
        Result.Err(err): return Result.Err(err)
        Result.Ok(contents): contents

    parseU32(fileContents)</code></pre>
<p>In the early return I don’t have to manually convert <code>readFile</code>s error value to <code>parseU32</code>s error value to make the types align.</p>
<p>Variants work nicely with higher-order functions as well. Here’s a function that parses a vector of strings, returning any errors to the caller:</p>
<pre><code>parseWith(vec: Vec[Str], parseFn: Fn(Str): Result[errs, a]): Result[errs, Vec[a]]
    let ret = Vec.withCapacity(vec.len())

    for s in vec.iter():
        match parseFn(s):
            Result.Err(err): return Result.Err(err)
            Result.Ok(val): ret.push(val)

    Result.Ok(ret)</code></pre>
<p>If I have a function argument that returns more errors than my callback, I can still call it without any adjustments:</p>
<pre><code>parseWith2(vec: Vec[Str], parseFn: Fn(Str): Result[[OtherError, ..r], a]): Result[[..r], Vec[a]]
    let ret = Vec.withCapacity(vec.len())

    for s in vec.iter():
        match parseFn(s):
            Result.Err(~OtherError): continue
            Result.Err(err): return Result.Err(err)
            Result.Ok(val): ret.push(val)

    Result.Ok(ret)</code></pre>
<p><code>parseWith2(vec, parseU32)</code> type checks even though <code>parseU32</code> doesn’t return <code>OtherError</code>.</p>
<p>Similarly, if I have a function that handles more cases, I can pass it as a function that handles less:</p>
<pre><code>handleSomeErrs(error: [Overflow, OtherError]): U32 = 0

parseWithErrorHandler(
        input: Str,
        handler: Fn([Overflow, ..r1]): U3
    ): Result[[InvalidDigit, EmptyInput, ..r2], U32]
    match parseU32(input):
        Result.Err(~Overflow): Result.Ok(handler(~Overflow))
        Result.Err(other): Result.Err(other)
        Result.Ok(val): Result.Ok(val)</code></pre>
<p>Here I’m able to pass <code>handleSomeErrs</code> to <code>parseWithErrorHandler</code>, even though it handles more errors than what <code>parseWithErrorHandler</code> argument needs.</p>
<h1 id="variants-as-exceptions">Variants as exceptions</h1>
<p>When we use variants as exception values, we end up with a system that is</p>
<ul>
<li>Safe: All exceptions need to be handled before <code>main</code> returns.</li>
<li>Flexible: All of the flexibility of variants shown above apply to exceptions as well.</li>
<li>Convenient:
<ul>
<li>Error values are implicitly propagated to the caller when not handled.</li>
<li>When a library uses one way of error reporting (error values or exceptions) and you need the other, conversion is just a matter of calling one function.</li>
</ul></li>
</ul>
<p>At the core of exceptions in Fir are these three functions:</p>
<ul>
<li><p><code>throw</code>, which converts a variant into an exception:</p>
<pre><code>throw(exn: exn): exn a</code></pre></li>
<li><p><code>try</code>, which converts exceptions into <code>Result.Err</code> values:</p>
<pre><code>try(cb: Fn(): exn a): Result[exn, a]</code></pre></li>
<li><p><code>untry</code>, which converts a <code>Result.Err</code> value into an exception:</p>
<pre><code>untry(res: Result[exn, a]): exn a</code></pre></li>
</ul>
<p>Here are some of the code above, using exceptions instead of error values:</p>
<pre><code>parseU32Exn(s: Str): [InvalidDigit, Overflow, EmptyInput, ..r] U32
    if s.len() == 0:
        throw(~EmptyInput)

    let result: U32 = 0

    for c in s.chars():
        if c &lt; &#39;0&#39; || c &gt; &#39;9&#39;:
            throw(~InvalidDigit)

        let digit = c.asU32() - &#39;0&#39;.asU32()

        result = match checkedMul(result, 10):
            Option.None: throw(~Overflow)
            Option.Some(newResult): newResult

        result = match checkedAdd(result, digit):
            Option.None: throw(~Overflow)
            Option.Some(newResult): newResult

    result

readFileExn(s: Str): [IoError, ..r] Str
    # We don&#39;t have the standard library support for file IO yet, just throw
    # an error for now.
    throw(~IoError)

parseU32FromFileExn(filePath: Str): [InvalidDigit, Overflow, EmptyInput, IoError, ..r] U32
    parseU32Exn(readFileExn(filePath))

parseWithExn(vec: Vec[Str], parseFn: Fn(Str): exn a): exn Vec[a]
    let ret = Vec.withCapacity(vec.len())
    for s in vec.iter():
        ret.push(parseFn(s))
    ret</code></pre>
<p>When a library provides one of these, it’s trivial to convert to the other:</p>
<pre><code>parseU32UsingExnVersion(s: Str): Result[[InvalidDigit, Overflow, EmptyInput, ..r], U32]
    try({ parseU32Exn(s) })

parseU32UsingResultVersion(s: Str): [InvalidDigit, Overflow, EmptyInput, ..r] U32
    untry(parseU32(s))</code></pre>
<p>Nice!</p>
<hr />
<p>I’m quite excited about these results. There’s still so much to do, but I think it’s clear that this way of error handling has a lot of potential.</p>
<p>I’ll be working on some of the improvements I mentioned above (and I have others planned as well), and the usual stuff that every language needs (standard library, tools etc.). Depending on interest, I may also write more about variants, error handling, or anything else related to Fir.</p>
<p>You can try Fir online <a href="https://fir-lang.github.io/?file=ErrorHandling.fir">here</a>.</p>]]></summary>
</entry>
<entry>
    <title>When is inlining useful?</title>
    <link href="http://osa1.net/posts/2024-12-07-inlining.html" />
    <id>http://osa1.net/posts/2024-12-07-inlining.html</id>
    <published>2024-12-07T00:00:00Z</published>
    <updated>2024-12-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Especially in high-level languages, inlining is most useful when it leads to:</p>
<ul>
<li>Optimizing the callee’s body based on the arguments passed.</li>
<li>Optimizing the call site based on the callee’s return value.</li>
</ul>
<p>Let’s look at some examples.</p>
<h1 id="example-avoiding-redundant-bounds-checks">Example: avoiding redundant bounds checks</h1>
<p>Suppose we have a library for decoding some format of binary files with length-prefixed vectors of 32-bit integers, with all integers encoded as little-endian.</p>
<p>A simple implementation would be:</p>
<pre><code>/// Decode a length-prefixed 32-bit unsigned integer vector.
///
/// # Panics
///
/// Panics if the buffer does not have enough bytes.
pub fn decode_u32_vec(buffer: &amp;[u8]) -&gt; Vec&lt;u32&gt; {
    let len = decode_32_le(buffer, 0) as usize;
    let mut vec = vec![0; len];
    for i in 0..len {
        vec[i] = decode_32_le(buffer, (i + 1) * 4);
    }
    vec
}

/// Decode a single 32-bit unsigned integer, encoded as little-endian.
///
/// # Panics
///
/// Panics if the buffer does not have 4 bytes starting at `offset`.
#[inline(never)]  // this version isn&#39;t inlined
pub fn decode_32_le(buffer: &amp;[u8], offset: usize) -&gt; u32 {
    let b1 = buffer[offset];
    let b2 = buffer[offset + 1];
    let b3 = buffer[offset + 2];
    let b4 = buffer[offset + 3];
    u32::from_le_bytes([b1, b2, b3, b4])
}</code></pre>
<p>This version is not ideal, because <code>decode_32_le</code> checks bounds on each byte access. (<a href="https://godbolt.org/z/eTMa38nqT">compiler explorer</a>)</p>
<p>We can improve it by checking the bounds for all of the reads once:</p>
<pre><code>#[inline(never)]  // this version isn&#39;t inlined
pub fn decode_32_le(buffer: &amp;[u8], offset: usize) -&gt; u32 {
    if buffer.len() &lt; 4 || buffer.len() - 4 &lt; offset {
        panic!();
    }
    let b1 = buffer[offset];
    let b2 = buffer[offset + 1];
    let b3 = buffer[offset + 2];
    let b4 = buffer[offset + 3];
    u32::from_le_bytes([b1, b2, b3, b4])
}</code></pre>
<p>The conditional makes sure that in the rest of the function the slice indices are all within bounds, so the compiler doesn’t generate bounds checks for the accesses. The compiler is also able to optimize further now to load just one 32-bit word from the memory, instead of reading one byte at a time. (<a href="https://godbolt.org/z/MG9EaE5G3">compiler explorer</a>)</p>
<p><code>decode_32_le</code> is quite good now, but it still has to do one bounds check, and since <code>decode_u32_vec</code> calls it in each iteration, it does a bounds check in each iteration.</p>
<p>Ideally we want to be able to do one bounds check before the loop, just like we did in <code>decode_32_le</code>, and then omit bounds checks within the loop:</p>
<pre><code>pub fn decode_u32_vec(buffer: &amp;[u8]) -&gt; Vec&lt;u32&gt; {
    let len = decode_32_le(buffer, 0) as usize;
    if buffer.len() &lt; (len + 1) * 4 {
        panic!();
    }
    let mut vec = vec![0; len];
    for i in 0..len {
        vec[i] = decode_32_le(buffer, (i + 1) * 4);
    }
    vec
}</code></pre>
<p>But this cannot make the bounds checks in <code>decode_32_le</code> disappear, as it may have other call sites that may not always check the bounds before calling it.</p>
<p>Inlining <code>decode_32_le</code> in the use effectively lets us propagate the information in the call site to the callee’s code, and optimize it based on this information. If we change the <code>inline(never)</code> to <code>inline</code> in <code>decode_32_le</code>, with the extra bounds check in <code>decode_u32_vec</code>, we now check bounds once before the loop and don’t check it again in the loop. (<a href="https://godbolt.org/z/EeGbYrfP7">compiler explorer</a>)</p>
<h1 id="example-avoiding-redundant-error-checks">Example: avoiding redundant error checks</h1>
<p>Dart doesn’t have unsigned integers, and many standard library functions throw an <code>ArgumentError</code> when they are passed negative numbers.</p>
<p>One example of these functions is the <a href="https://api.dart.dev/dart-core/int/operator_triple_shift.html">unsigned right shift operator</a>. In many call sites, the shift amount is a <a href="https://github.com/dart-lang/sdk/blob/abb17bc59d8163273451b3ffb2aba784d20001b4/sdk/lib/_internal/wasm/lib/internal_patch.dart#L88-L97">constant positive number</a>. If we call the standard library function in these cases, the library function will check the sign of the arguments that we already know in the call site to be positive.</p>
<p>When we inline <a href="https://github.com/dart-lang/sdk/blob/abb17bc59d8163273451b3ffb2aba784d20001b4/sdk/lib/_internal/wasm/lib/boxed_int.dart#L94-L107">the operator</a> in a call site where the shift argument is constant, the conditional becomes <code>if (constant &lt; 0) throw ...</code>. The compiler can then simplify the condition as <code>true</code> or <code>false</code>, and then simplify this code to just <code>throw ...</code> or eliminate the conditional.</p>
<p>The <code>mix64</code> function linked above when compiled to Wasm, without inlining the right shift operator:</p>
<pre><code>(func $mix64 (param $var0 i64) (result i64)
  ...
  local.tee $var0
  i64.const 24
  call $BoxedInt.&gt;&gt;&gt;
  ...)

(func $BoxedInt.&gt;&gt;&gt; (param $var0 i64) (param $var1 i64) (result i64)
  local.get $var1
  i64.const 64
  i64.lt_u
  if
    local.get $var0
    local.get $var1
    i64.shr_u
    return
  end
  local.get $var1
  i64.const 0
  i64.lt_s
  if
    i32.const 64
    local.get $var1
    struct.new $BoxedInt
    call $ArgumentError
    call $Error._throwWithCurrentStackTrace
    unreachable
  end
  i64.const 0)</code></pre>
<p>With the shift operator inlined:</p>
<pre><code>(func $mix64 (param $var0 i64) (result i64)
  ...
  local.get $var0
  i64.const 24
  i64.shr_u
  ...)</code></pre>
<p>The call to <code>BoxedInt.&gt;&gt;&gt;</code> with error checking is optimized to a single <code>shr_u</code> (shift right, unsigned) instruction.</p>
<h1 id="example-avoiding-boxing">Example: avoiding boxing</h1>
<p>In languages where most values are passed around as boxed, inlining can eliminate boxing.</p>
<p>A common use case where this happens is FFI: pointers/references obtained from FFI calls need to be wrapped in a struct/class/etc. to make them the same “shape” as the language’s native values.</p>
<p>When you have a function that gets a reference from an FFI call, and pass it around to more FFI calls, inlining these FFI calls can avoid boxing the pointer/reference value.</p>
<p>Somewhat silly example, in Dart:</p>
<pre><code>import &#39;dart:ffi&#39;;

@Native&lt;Pointer&lt;Int64&gt; Function()&gt;()
external Pointer&lt;Int64&gt; intPtr();

@Native&lt;Int64 Function(Pointer&lt;Int64&gt;)&gt;()
external int derefIntPtr(Pointer&lt;Int64&gt; ptr);

void main() {
  Pointer&lt;Int64&gt; ptr = intPtr();
  ptr += 1;
  int i = derefIntPtr(ptr);
  print(i);
}</code></pre>
<p>Relevant parts of the generated code when compiled to Wasm:</p>
<pre><code>(func $main
  ...
  call $intPtr
  struct.get $Pointer $field2
  i32.const 8
  i32.add
  call $ffi.derefIntPtr (import)
  ...)

(func $intPtr (result (ref $Pointer))
  i32.const 71
  i32.const 0
  call $ffi.intPtr (import)
  struct.new $Pointer)</code></pre>
<p><code>intPtr</code> allocates a struct, which the call site directly unpacks (reads the field). Inlining <code>intPtr</code> eliminates this allocation:</p>
<pre><code>(func $main
  ...
  call $ffi.intPtr (import)
  i32.const 8
  i32.add
  call $ffi.derefIntPtr (import)
  ...)</code></pre>
<h1 id="example-avoiding-polymorphism">Example: avoiding polymorphism</h1>
<p>When a monomorphic type is passed to a polymorphic function, the polymorphic function can often be inlined to avoid polymorphic access to the monomorphic type.</p>
<p>An example, again in Dart, is <code>Int64List</code>, which is a monomorphic <code>List&lt;int&gt;</code>. It stores the integers unboxed, and when used directly, the integer arguments and return values do not need to be boxed.</p>
<p>When used in a polymorphic site though, the integer elements need to be boxed. Example:</p>
<pre><code>import &#39;dart:typed_data&#39;;

int sum(List&lt;int&gt; list) {
  int ret = 0;
  for (int i = 0; i &lt; list.length; i += 1) {
    ret += list[i];
  }
  return ret;
}

void main() {
  Int64List intList = Int64List.fromList([1, 2, 3, 4]);
  sum(intList);
  sum([1, 2, 3, 4]);
}</code></pre>
<p>Relevant parts of the output when compiled to Wasm:</p>
<pre><code>(func $main
  ;; Allocate `Int64List`, call `sum`:
  ...
  call $sum

  ;; Allocate the other `List&lt;int&gt;`, call `sum`:
  ...
  call $sum)

(func $sum (param $var0 (ref $Object))
  (local $var1 i64)
  (local $var2 i64)
  loop $label0
    ...
    if
      ...
      ;; Virtual call to `operator []`:
      struct.get $Object $field0
      i32.const 747
      i32.add
      call_indirect (param (ref $Object) i64) (result (ref null $#Top))

      ;; The virtual call returns a boxed integer, which we directly unbox:
      ref.cast $BoxedInt
      struct.get $BoxedInt $field1
      i64.add
      ...
    end
  end $label0)</code></pre>
<p>If we inline <code>sum</code>, the loop that iterates the <code>Int64List</code> accesses the unboxed integers directly:</p>
<pre><code>(func $main
  ...
  loop $label1
      ...
      local.get $var3
      local.get $var4
      local.get $var1
      i32.wrap_i64
      ;; Array access is now direct, no boxing.
      array.get $Array&lt;WasmI64&gt;
      i64.add
      local.set $var3
      local.get $var1
      i64.const 1
      i64.add
      local.set $var1
      br $label1
    end
  end $label1)</code></pre>
<p>A similar case is when a monomorphic type is used directly, but via a polymorphic interface. In the <code>Int64List</code> type above, <code>List64List.[]</code> is an override of <a href="https://api.dart.dev/dart-core/List/operator_get.html"><code>List&lt;E&gt;.[]</code></a>, and all overrides of a method need to have the same type.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>So when not inlined, it needs to return a boxed integer:</p>
<pre><code>(func $Int64List.[] (param $var0 (ref $Object)) (param $var1 i64) (result (ref null $#Top))
  ...
  array.get $Array&lt;WasmI64&gt;
  struct.new $BoxedInt)</code></pre>
<p>Similar to the previous example, inlining it eliminates the boxing in monomorphic use sites, as the allocated struct is immediately unboxed.</p>
<h1 id="example-eliminating-closures-and-indirect-calls">Example: eliminating closures and indirect calls</h1>
<p>In languages without monomorphisation, higher-order function arguments need to be allocated as closures.</p>
<p>When calling a closure, the caller needs to get the function pointer from the closure and call the function via the pointer.</p>
<p>These closure allocations and indirect function calls can be too slow in hot loops.</p>
<p>An example of this is in <a href="https://github.com/google/protobuf.dart">Dart protobuf library</a>. In protobufs, packed fields are encoded as a length prefix followed by the elements. In the Dart library, we decode these fields using <a href="https://github.com/google/protobuf.dart/blob/610943a3bed70c1c2079af5fca02462df10d223f/protobuf/lib/src/protobuf/coded_buffer.dart#L271-L277">this helper</a>:</p>
<pre><code>void _readPacked(CodedBufferReader input, void Function() readFunc) {
  input._withLimit(input.readInt32(), () {
    while (!input.isAtEnd()) {
      readFunc();
    }
  });
}</code></pre>
<p>Here the caller of <code>_readPacked</code> passes <code>readFunc</code> as a closure (allocation). <code>_readPacked</code> then allocates another closure, to be passed to <code>_withLimit</code>.</p>
<p>That’s two closure allocations for every packed field in the input. Calling these closures are slow too, because they’re indirect.</p>
<p>Inlining <code>_withLimit</code> in <code>_readPacked</code>, and <code>_readPacked</code> in its call sites (in <code>_mergeFromCodedBufferReader</code>) eliminates closure allocations, and calls to the closures become direct function calls. This <a href="https://github.com/google/protobuf.dart/pull/959">improves packed field decoding</a> significantly.</p>
<h1 id="a-trick-for-effective-inlining-outlining">A trick for effective inlining: outlining</h1>
<p>Consider <code>Int64List.[]</code> again. The implementation needs to check that the index is in bounds of the array, and throw an exception if not: (slightly simplified)</p>
<pre><code>class Int64List ... {
  ...

  @override
  int operator [](int index) {
    if (length.leU(index)) { // shorthand for `index &lt; 0 || index &gt;= length`
      ... // throw exception
    }
    return _data.read(index);
  }
}</code></pre>
<p>To avoid boxing when calling this function we want to always inline it, but if we’re not careful with the error throwing code path (the <code>if</code> body above), the function can get quite large, and when inlined the binary can bloat up significantly.</p>
<p>Ideally we want to inline the happy path that can lead to improvements when inlined, and leave the error path separate in a function, so that we can have the benefits of inlining without adding to the binary size too much.</p>
<p>This can be done by moving the error handling code to a separate function, and making sure that separate function is never inlined (ideally with an annotation to the compiler). In the example above, this may look like:</p>
<pre><code>class Int64List ... {
  @override
  @pragma(&#39;inline&#39;)
  int operator [](int index) {
    if (length.leU(index)) { // shorthand for `index &lt; 0 || index &gt;= length`
      fail(index, length);
    }
    return _data.read(index);
  }
}

@pragma(&#39;never-inline&#39;)
void fail(int index, int length) { ... }</code></pre>
<p>With this it doesn’t matter how large the error handling code is, because we never inline it.</p>
<p>This way of separating inlineable parts of a function from the parts we don’t want to inline is sometimes called “outlining” or “partial inlining”. We can do it manually (as in the example above), but it can also be done by a compiler based on heuristics.</p>
<p>An example transformation to this is <a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/75629BBEDB11D8463553A09BF5DEA235/S0956796809007175a.pdf/div-class-title-the-worker-wrapper-transformation-div.pdf">GHC’s worker/wrapper transformation</a>, which splits a function into parts that (1) handle unboxing and boxing before calling the function’s body, and (2) the function’s body that work on the unboxed representations of the arguments. (1) is then inlined to avoid redundant boxing of the arguments and return values.</p>
<p>Another example is <a href="https://github.com/WebAssembly/binaryen">wasm-opt</a> which does <a href="https://github.com/WebAssembly/binaryen/blob/6fe5103ab58a4eb751998d13768a0f25795a0de6/src/passes/Inlining.cpp#L684-L754">partial inlining</a>.</p>
<h1 id="a-tip-for-effective-inlining-avoid-inlining-in-slow-paths">A tip for effective inlining: avoid inlining in slow paths</h1>
<p>In the <a href="https://github.com/google/protobuf.dart/blob/610943a3bed70c1c2079af5fca02462df10d223f/protobuf/lib/src/protobuf/coded_buffer.dart#L54-L267">protobuf decoding loop</a> that we mentioned above, we have a big type switch to determine how to decode a field. It looks like this:</p>
<pre><code>switch (fieldType) {
  case PbFieldType._OPTIONAL_BOOL:
    fs._setFieldUnchecked(meta, fi, input.readBool());
    break;
  ...
  case PbFieldType._REPEATED_UINT64:
    final list = fs._ensureRepeatedField(meta, fi);
    if (wireType == WIRETYPE_LENGTH_DELIMITED) {
      _readPacked(input, () =&gt; list.add(input.readUint64()));
    } else {
      list.add(input.readUint64());
    }
    break;
  ...
  // 37 cases in total. 
}</code></pre>
<p>Assume that there’s a function that throws an exception (e.g. <code>_ensureRepeatedField</code> above), and it’s used in only once, in one of the <code>case</code>s of the <code>switch</code>.</p>
<p>Because the function is only used once, it may look like inlining it makes sense, as that would eliminate function call overhead, shave at least a few bytes off the binary, and potentially allow optimizations in the call site.</p>
<p>However since this switch is in a hot loop, and the inlined code branch is taken very rarely (unless the application is receiving a lot of malformed input), inlining this slow path can make the instruction cache usage much worse and slow down the decoder.</p>
<p>This kind of inlining can commonly happen when optimizing for size, e.g. with <code>wasm-opt -Os</code>. Because inlining single-use functions reduce binary sizes, optimization modes that aim to make the final binaries smaller can inline slow-path error throwing functions.</p>
<p>If we really want to inline a slow-path function, a way to avoid making instruction cache usage worse is to move the slow-path code to the end of the function, away from the common code paths.</p>
<p>This is often done with branch prediction hints, such as clang’s <a href="https://llvm.org/docs/BranchWeightMetadata.html#builtin-expect"><code>__builtin_expect</code></a>. When a branch is annotated as “not likely to be taken”, the compiler can move the branch target (the basic blocks) to the end of the current function, away from the hot code. This gives us the binary size benefits of inlining single-use functions, without filling the instruction cache with instructions that will never be executed.</p>
<h1 id="remarks">Remarks</h1>
<p>The main reason why the examples above are mostly in Dart is because I’ve been spending most of my time this year optimizing Dart’s Wasm backend’s standard library implementation, so the examples are still fresh in my memory.</p>
<p>The principles apply to most languages: inlining a function makes any information about the arguments available to the function’s body, and any information on its return value to the call site.</p>
<p>A big part of optimizing high-level statically-typed languages is about avoiding polymorphism, boxing, and redundant error checks. I’m not aware of any cases where inlining a function in a high-level language, when it doesn’t result in improving one of these, is worthwhile.</p>
<p>In a lower-level language with monomorphisation and control over allocations (e.g. Rust, C++), monomorphisation eliminates polymorphism in compile time, boxing is explicit, and redundant checks can be avoided by using unchecked (unsafe) functions.</p>
<p>In these cases where programs are often much faster by default, inlining to avoid stack/register shuffling and simplify control flow can make a difference.</p>
<p>One example of simplified control flow making a big difference can be seen in <a href="https://osa1.net/posts/2024-11-29-how-to-parse-3.html">the previous post</a>, where implementing a recursive parsing function in a non-recursive way improved performance by 22%.</p>
<h1 id="updates">Updates</h1>
<ul>
<li><strong>2024-12-07:</strong> Added link to wasm-opt in partial inlining section.</li>
<li><strong>2025-02-12:</strong> Added a higher-order function example.</li>
<li><strong>2025-02-14:</strong> Added a section about inlining in slow paths.</li>
</ul>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>More accurately, a method that can be called in a polymorphic call site needs to have a type that is a subtype of the least-upper-bound of the types of all functions that can be called in the polymorphic call sites.</p>
<p>Or more briefly, all methods in an override group need to have the same type.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></summary>
</entry>
<entry>
    <title>Resumable exceptions</title>
    <link href="http://osa1.net/posts/2024-11-04-resumable-exceptions.html" />
    <id>http://osa1.net/posts/2024-11-04-resumable-exceptions.html</id>
    <published>2024-11-04T00:00:00Z</published>
    <updated>2024-11-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>The main use case of resumable exceptions would be collecting a bunch of errors (instead of bailing out after the first one) to log or show to the user, or actually recovering and continuing from the point of error detection, rather than in a call site.</p>
<p><em>Why not design the code to allow error recovery, instead of using a language feature?</em> There are a few problems with this:</p>
<ul>
<li><p>Without a language feature to do this, libraries will have to implement their own ways to recover from errors, causing inconsistencies and fragmented ecosystem of error handling libraries.</p></li>
<li><p>With resumable exceptions, any code can be trivially made to transfer control to a exception handler, and back. Manually refactoring code to do the same can be a big task. This may even be infeasible.</p></li>
<li><p>With resumable exceptions as a part of the language, libraries will be designed with resumption in mind. Libraries that would normally not allow error recovery will allow error recovery, as it will be easy to do, and it will be a common thing to resume from errors.</p></li>
</ul>
<h1 id="example-use-case-parser-shared-by-a-compiler-and-a-language-server">Example use case: parser shared by a compiler and a language server</h1>
<p>Modern programming languages have complex syntax. Parsers for these languages are often thousands of lines of code.</p>
<p>Ideally, all tooling for a language would share the parser, as it’s a significant amount of work to implement, debug, maintain parsers for such large languages.</p>
<p>However not all of these tools will have the same error handling behavior. A compiler <em>cannot</em> continue in the presence of a parse error, but a language server <em>has to</em> continue.</p>
<p>With resumable exceptions, the compiler can abort after a parse error, the language server can provide placeholder AST nodes for failing parse operations and resume. This flexibility does not make the parser API any more complicated than a parser that throws an exception in any other language. A one-off refactoring script that uses the parser library doesn’t have to deal with error recovery just because the language server, which uses the same parser, needs to recover from parse errors and continue parsing.</p>
<h1 id="types-of-resumable-exceptions">Types of resumable exceptions</h1>
<p>With resumable exceptions <code>throw</code> expressions generate a value. The value depends on the exception type thrown. For example, a <code>FooDecodingException</code> can be resumed with a value of <code>Foo</code> provided by the handler.</p>
<p>This can be implemented with an abstract base class or typeclass/trait with a type parameter:</p>
<pre><code>// in a system with classes:
abstract class ResumableException&lt;Resume&gt; { 
    prim Resume throw();
    prim Never resume(Resume resumptionValue);
}

// or in a system with typeclasses/traits:
trait ResumableException&lt;Resume&gt; {
    prim fn throw(self) -&gt; Resume;
    prim fn resume(resumptionValue: Resume) -&gt; !;
}</code></pre>
<p>Here the <code>prim</code> keyword indicates that the <code>throw</code> and <code>resume</code> methods are provided by the compiler.</p>
<p><code>throw e</code> can then be type checked as <code>e.throw()</code>, and <code>resume e with value</code> can be type checked as <code>e.resume(value)</code>. Or we can use the function call syntax instead of special syntax for throwing and resuming.</p>
<p>Whether to make exceptions thrown by a function a part of its type signature or not is an orthogonal concern.</p>
<h1 id="exception-type-design-considerations">Exception type design considerations</h1>
<p>The same considerations when designing non-resumable exceptions apply to resumable exceptions:</p>
<ul>
<li>The more general an exception type gets, the less you can do with it.</li>
<li>We still want to distinguish “log and stop” kind of exceptions from recoverable ones.</li>
</ul>
<p>For example, it doesn’t make sense to resume from an <a href="https://api.dart.dev/stable/3.5.4/dart-core/ArgumentError-class.html"><code>ArgumentError</code></a>, so we don’t implement <code>ResumableException</code> for it.</p>
<p>To be able to meaningfully resume from an exception, the exception type should document when exactly it is thrown, or have a resumption value type that is specific enough to give an idea on when it is thrown.</p>
<p>For example, an exception that can be resumed with an <code>int</code> cannot be resumed without knowing what that <code>int</code> is going to be used for, so this should be documented. But an exception <code>FooDecodingError implements ResumableException&lt;Foo&gt;</code> makes it clear that it’s thrown when there’s an error during decoding a <code>Foo</code>, and the resumption value is the value to be used as the <code>Foo</code> being decoded.</p>]]></summary>
</entry>
<entry>
    <title>Subtyping and subsumption</title>
    <link href="http://osa1.net/posts/2024-10-21-subtyping-subsumption.html" />
    <id>http://osa1.net/posts/2024-10-21-subtyping-subsumption.html</id>
    <published>2024-10-21T00:00:00Z</published>
    <updated>2024-10-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Subtyping is a relation between two types. It often comes with a typing rule called “subsumption”, which says that if type B is a subtype of type A (usually shown as <code>B &lt;: A</code>), then a value of type B can be assumed to have type A.</p>
<p>The crucial part is that subsumption is <em>implicit</em>, the programmer doesn’t explicitly cast the value with type <code>B</code> to type <code>A</code>.</p>
<p>When we make an operation implicit in a language, we need to make sure that it is (1) safe (2) performant. Users will be doing it without realizing, and we don’t want to accidentally break things or make them slow.</p>
<p>Let’s consider how we can make subsumption safe and performant.</p>
<h1 id="safety-of-subsumption">Safety of subsumption</h1>
<p>Different languages give different safety guarantees. High-level languages often guarantee:</p>
<ol type="1">
<li><p>Memory safety: a memory read or write shouldn’t cause undefined behavior.</p>
<p>Examples: out-of-bounds array accesses should be caught, dangling pointers shouldn’t be allowed or dereferencing them should be caught in runtime.</p></li>
<li><p>Type safety: static guarantees of the language’s type system should be uphold.</p>
<p>Example: if I have a function <code>f : A -&gt; B</code> and a value <code>x : A</code> after subsumption, <code>f(x)</code> shouldn’t fail in compile time or runtime.</p></li>
</ol>
<p>There could be different safeties that the language guarantees. Some of those safeties may also be checked in runtime instead of compile time.</p>
<p>Whatever safeties the language guarantees, they must be preserved with subsumption.</p>
<p>From a programmer’s perspective however, these are not enough to make sure that the program will work as before when subsumption is used. If I can pass a value of type <code>B</code> where <code>A</code> is expected, I need to make sure <code>B</code>, when used as <code>A</code>, acts like <code>A</code>.</p>
<p>This is called “behavioral subtyping” (or “substitutability”), and it depends on not the types of <code>A</code>’s operations but the observable behaviors of <code>A</code> and its subtypes.</p>
<p>I don’t have a good real-world example of this, but you can imagine two types with the same public APIs that work differently. Since the public APIs are the same one can be made subtype of the other and (1) and (2) would still be satisfied, but doing that would cause bugs when one is accidentally passed as the other.</p>
<h1 id="performance-of-subsumption">Performance of subsumption</h1>
<p>Definition of “fast” or “performant” also depends on the language. A C++ programmer’s fast and Python programmer’s fast are often not the same.</p>
<p>However in general, heap allocation should be avoided.</p>
<p>Object-oriented languages (as defined in my <a href="https://osa1.net/posts/2024-10-09-oop-good.html">previous post</a>) without multiple inheritance can often implement subsumption of reference values as no-op, i.e. values of type <code>B</code> work as <code>A</code> in runtime without any changes or copying.</p>
<p>Multiple inheritance makes things more complicated, but a reference to an object can still be converted to a reference of one of its supertypes by just <a href="https://people.montefiore.uliege.be/declercq/INFO0004/documents/vtable.html">adjusting the pointer value</a>.</p>
<p>With unboxed/value types, conceptually, the value needs to be copied as its supertype, but that operation is often no-op. Consider an unboxed record <code>(x: Int, y: Int, z: Int)</code> that we store in a variable <code>a</code>. In runtime, <code>a</code> actually holds multiple stack locations or registers. When we copy it as <code>let b: (x: Int, y: Int) = a</code>, we don’t have to allocate new stack locations for <code>b.x</code> and <code>b.y</code>, we just map those locations to the same locations as <code>a.x</code> and <code>a.y</code>. When we pass <code>b</code> to a function, we pass <code>a.x</code> and <code>a.y</code>.</p>
<p>Where copying becomes a requirement and prohibitive is when you have something like <code>ReadOnlyList&lt;(x: Int, y: Int, z: Int)&gt;</code> and want to upcast it to <code>ReadOnlyList&lt;(x: Int, y: Int)&gt;</code> (the records are unboxed). From the safety perspective this operation is fine, but you have to allocate a new list and copy all the values.</p>
<p>I think this is rarely a problem in practice though, because most generic types, like <code>List&lt;T&gt;</code>, end up being invariant in <code>T</code> anyway, because their API often uses <code>T</code> in both covariant and contravariant positions. So <code>List&lt;(x: Int, y: Int)&gt;</code> is not a supertype of <code>List&lt;(x: Int, y: Int, z: Int)&gt;</code> and subsumption does not apply.</p>
<h1 id="no-conclusions-this-time">No conclusions this time</h1>
<p>In this short post I just wanted to give some definitions that I’m hoping to refer to in future posts.</p>]]></summary>
</entry>
<entry>
    <title>OOP is not that bad, actually</title>
    <link href="http://osa1.net/posts/2024-10-09-oop-good.html" />
    <id>http://osa1.net/posts/2024-10-09-oop-good.html</id>
    <published>2024-10-09T00:00:00Z</published>
    <updated>2024-10-09T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>OOP is certainly not my favorite paradigm, but I think mainstream statically-typed OOP does a few things right that are very important for programming with many people, over long periods of time.</p>
<p>In this post I want to explain what I think is the most important one of these things that the mainstream statically-typed OOP languages do well.</p>
<p>I will then compare the OOP code with Haskell, to try to make the point that OOP is not as bad in everything as some functional programmers seem to think.</p>
<h1 id="what-even-is-oop">What even is OOP?</h1>
<p>In this post I use the word “OOP” to mean programming in statically-typed language with:</p>
<ol type="1">
<li>Classes, that combine state and methods that can modify the state.</li>
<li>Inheritance, which allows classes to reuse state and methods of other classes.</li>
<li>Subtyping, where if a type <code>B</code> implements the public interface of type <code>A</code>, values of type <code>B</code> can be passed as <code>A</code>.</li>
<li>Virtual calls, where receiver class of a method call is not determined by the static type of the receiver but its runtime type.</li>
</ol>
<p>Examples of OO languages according to this definition: C++, Java, C#, Dart.</p>
<h1 id="an-example-of-what-this-allows">An example of what this allows</h1>
<p>This set of features allows a simple and convenient way of developing composable libraries, and extending the libraries with new functionality in a backwards compatible way.</p>
<p>It’s probably best explained with an example. Suppose we have a simple logger library:</p>
<pre><code>class Logger {
  // Private constructor: initializes state, returns an instance of `Logger`.
  Logger._();

  // Public factory: can return `Logger` or any of the subtypes.
  factory Logger() =&gt; Logger._();

  void log(String message, Severity severity) { /* ... */ }
}

enum Severity {
  Info,
  Error,
  Fatal,
}</code></pre>
<p>and another library that does some database stuff:</p>
<pre><code>class DatabaseHandle {
  /* ... */
}</code></pre>
<p>and an application that uses both:</p>
<pre><code>class MyApp {
  final Logger _logger;
  final DatabaseHandle _dbHandle;

  MyApp()
      : _logger = Logger(),
        _dbHandle = DatabaseHandle(...);
}</code></pre>
<p>As is usually the case, things that make network connections, change shared state etc. need to be mocked, faked, or stubbed to be able to test applications. We may also want to extend the libraries with new functionality. With the features that we have, we don’t have to see this coming and prepare the types based on this.</p>
<p>In the first iteration we might just add a concrete class that is just the copy of the current class, and make the current class abstract:</p>
<pre><code>// The class is now abstract.
abstract class Logger {
  // Public factory now returns an instance of a concrete subtype.
  factory Logger() =&gt; _SimpleLogger();

  Logger._();

  // `log` is now abstract.
  void log(String message, Severity severity);
}

class _SimpleLogger extends Logger {
  factory _SimpleLogger() =&gt; _SimpleLogger._();

  _SimpleLogger._() : super._() {/* ... */}

  @override
  void log(String message, Severity severity) {/* ... */}
}</code></pre>
<p>This change is backwards compatible, requires no changes in user code.</p>
<p>Now we might add more implementations, e.g. for ignoring log messages:</p>
<pre><code>abstract class Logger {
  factory Logger() =&gt; _SimpleLogger();

  // New.
  factory Logger.ignoring() =&gt; _IgnoringLogger();

  Logger._();

  void log(String message, Severity severity);
}

class _IgnoringLogger extends Logger {
  factory _IgnoringLogger() =&gt; _IgnoringLogger._();

  _IgnoringLogger._() : super._() {}

  @override
  void log(String message, Severity severity) {}
}</code></pre>
<p>Similarly we can add a logger that logs to a file, to a DB, etc.</p>
<p>We can do the same for the database handle class, but for mocking, faking, or stubbing, in tests.</p>
<p>To be able to use these new subtypes in our app, we implement a factory, or add a constructor to allow passing a logger and a db handle:</p>
<pre><code>class MyApp {
  final Logger _logger;
  final DatabaseHandle _dbHandle;

  MyApp()
      : _logger = Logger(),
        _dbHandle = DatabaseHandle();

  MyApp.withLoggerAndDb(this._logger, this._dbHandle);
}</code></pre>
<p>Note that we did not have to change any types, or add type parameters. Any methods of <code>MyApp</code> that use the <code>_logger</code> and <code>_dbHandle</code> fields do not have to know about the changes.</p>
<p>Now suppose one of the <code>DatabaseHandle</code> implementations also start using the logger library:</p>
<pre><code>abstract class DatabaseHandle {
  factory DatabaseHandle.withLogger(Logger logger) =&gt;
      _LoggingDatabaseHandle._(logger);

  factory DatabaseHandle() =&gt; _LoggingDatabaseHandle._(Logger.ignoring());

  DatabaseHandle._();

  /* ... */
}

class _LoggingDatabaseHandle extends DatabaseHandle {
  final Logger _logger;

  _LoggingDatabaseHandle._(this._logger) : super._();

  /* ... */
}</code></pre>
<p>In our app, we might test by disabling logging in the db library, but start logging db operations in production:</p>
<pre><code>class MyApp {
  // New
  MyApp.testingSetup()
      : _logger = Logger(),
        _dbHandle = DatabaseHandle.withLogger(Logger.ignoring());

  // Updated to start using the logging feature of the DB library.
  MyApp()
      : _logger = Logger(),
        _dbHandle = DatabaseHandle.withLogger(Logger.toFile(...));

  /* ... */
}</code></pre>
<p>As an example that adds more state to the types, we can add a logger implementation that only logs messages above certain severity:</p>
<pre><code>class _LogAboveSeverity extends _SimpleLogger {
  // Only logs messages with this severity or more severe.
  final Severity _severity;

  _LogAboveSeverity(this._severity) : super._();

  @override
  void log(String message, Severity severity) { /* ... */ }
}</code></pre>
<p>We can add another factory to the <code>Logger</code> abstract class that returns this type, or we can even implement this in another library:</p>
<pre><code>// Implemented in another library, not in `Logger`&#39;s library.
class LogAboveSeverity implements Logger {
  // Only logs messages with this severity or more severe.
  final Severity _severity;

  final Logger _logger;

  LogAboveSeverity(this._severity) : _logger = Logger();

  LogAboveSeverity.withLogger(this._severity, this._logger);

  @override
  void log(String message, Severity severity) { /* ... */ }
}</code></pre>
<p>As a final example to demonstrate adding more operations (rather than more state), we can have a logger that logs to a file, with a <code>flush</code> operation:</p>
<pre><code>class FileLogger implements Logger {
  final File _file;

  FileLogger(this._file);

  @override
  void log(String message, Severity severity) {/* ... */}

  void flush() {/* ... */}
}</code></pre>
<p>In summary:</p>
<ul>
<li>We started with a simple logging and database library and wrote an app.</li>
<li>We added more capabilities to the logging and database libraries for testing and also in production use. In particular, we added:
<ul>
<li>New functionality to the logger library, to disable logging, or logging to a file.</li>
<li>A new dependency to the database library for logging database operations. We also allowed the users to override the default logger used.</li>
</ul></li>
</ul>
<p>Crucially, we didn’t have to change any types while doing these changes, and the new code is still as type safe as before.</p>
<p>The logger and database libraries evolved in a completely backwards compatible way.</p>
<p>Since none of the types used in our application changed, <code>MyApp</code> methods didn’t have to change at all.</p>
<p>When we decide to take advantage of the new functionality, we updated only how we construct the logger and db handle instances in our app. Rest of the app didn’t change.</p>
<p>Now let’s consider how something like this could be done in Haskell.</p>
<h1 id="attempting-it-in-haskell">Attempting it in Haskell</h1>
<p>Immediately at the start, we have a few choices on how to represent it.</p>
<p><strong>Option 1:</strong> An ADT, with callback fields to be able to add different types of loggers later:</p>
<pre><code>data Logger = MkLogger
    { _log :: Message -&gt; Severity -&gt; IO ()
    }

simpleLogger :: IO Logger

data Severity = Info | Error | Fatal
    deriving (Eq, Ord)

log :: Logger -&gt; String -&gt; Severity -&gt; IO ()</code></pre>
<p>In this representation, extra state like the minimum severity level in our <code>_LogAboveSeverity</code> is not added to the type, but captured by the closures:</p>
<pre><code>logAboveSeverity :: Severity -&gt; IO Logger
logAboveSeverity minSeverity = MkLogger
    { _log = \message severity -&gt; if severity &gt;= minSeverity then ... else pure ()
    }</code></pre>
<p>If we need to update some of the state shared by the closures, the state needs to be stored in some kind of reference type like <code>IORef</code>.</p>
<p>Similar to the OOP code, the <code>FileLogger</code> needs to be a separate type:</p>
<pre><code>data FileLogger = MkFileLogger
  { _logger :: Logger   -- callbacks capture the file descriptor/buffer and write to it
  , _flush  :: IO ()    -- similarly captures the file descriptor/buffer, flushes it
  }

logFileLogger :: FileLogger -&gt; String -&gt; Severity -&gt; IO ()
logFileLogger = log . _logger</code></pre>
<p>However, unlike our OOP example, existing code that uses the <code>Logger</code> type and <code>log</code> function cannot work with this new type. There needs to be some refactoring, and how the user code will need to be refactored depends on how we want to expose this new type to the users.</p>
<p><strong>Option 2:</strong> A typeclass that we can implement for our concrete logger types:</p>
<pre><code>class Logger a where
    log :: a -&gt; String -&gt; Severity -&gt; IO ()

data SimpleLogger = MkSimpleLogger { ... }

simpleLogger :: IO SimpleLogger
simpleLogger = ...

instance Logger SimpleLogger where
  log = ...</code></pre>
<p>To allow backwards-compatible changes in the logger library, we need to hide the concrete logger class:</p>
<pre><code>module Logger
    ( Logger
    , simpleLogger -- I can export this without exporting its return type
    ) where

...</code></pre>
<p>With this module, we have to either add a type parameter to the functions and other types that use <code>Logger</code>, or use existentials.</p>
<p>Adding a type parameter is not a backwards compatible change, and in general it can cause snowball effect of propagating the type parameter to the direct users, and then their users, and so on, creating a massive change and difficult to use types.</p>
<p>The problem with existentials is that they are limited in how you can use them, and are somewhat strange in some areas. In our application we can do this:</p>
<pre><code>data MyApp = forall a . Logger a =&gt; MkMyApp
  { _logger :: a
  }</code></pre>
<p>But we can’t have a local variable with this existential type:</p>
<pre><code>createMyApp :: IO MyApp
createMyApp = do
  -- I can&#39;t add a type annotation to myLogger without the concrete type
  myLogger &lt;- simpleLogger      -- simpleLogger :: IO SimpleLogger
  return MkMyApp { _logger = myLogger }</code></pre>
<p>I also cannot have an existential type in a function argument:</p>
<pre><code>-- The type signature is accepted by the compiler, but the value cannot be used.
doStuffWithLogging :: (forall a . Logger a =&gt; a) -&gt; IO ()
doStuffWithLogging logger = log logger &quot;test&quot; Info -- some obscure type error</code></pre>
<p>Instead we have to “pack” the logger value with its typeclass dictionary in a new type:</p>
<pre><code>data LoggerBox = forall a . Logger a =&gt; LoggerBox a

doStuffWithLogging :: LoggerBox -&gt; IO ()
doStuffWithLogging (LoggerBox logger) = log logger &quot;test&quot; Info</code></pre>
<p>Other problems and limitations of this approach:</p>
<ul>
<li>The syntax is just awful to the point where it’s deterrent: <code>forall a . Logger a =&gt; ... a ...</code> instead of just <code>Logger</code>.</li>
<li>It allows implementing <code>FileLogger</code>, but
<ul>
<li>All subtypes need to be a new typeclass + an implementation (in OOP: just one class).</li>
<li>This cannot be used for safe downcasting of a <code>Logger</code> value to <code>FileLogger</code>, without knowing the concrete type of the <code>FileLogger</code>.</li>
</ul></li>
</ul>
<h1 id="effect-monad-approach">Effect monad approach</h1>
<p>The effect monad approach is a variation of option (2) without existentials. Instead of</p>
<pre><code>class Logger a where
    log :: a -&gt; String -&gt; Severity -&gt; IO ()</code></pre>
<p>We add the ability to log in a monad type parameter:</p>
<pre><code>class MonadLogger m where
    log :: String -&gt; Severity -&gt; m ()</code></pre>
<p>Then provide a “monad transformer” for each of the logger implementations:</p>
<pre><code>newtype SimpleLoggerT m a = SimpleLoggerT { runSimpleLoggerT :: m a }

instance MonadIO m =&gt; MonadLogger (SimpleLoggerT m) where
  log msg sev = SimpleLoggerT { runSimpleLoggerT = liftIO (logStdout msg sev) }

newtype FileLoggerT m a = FileLoggerT { runFileLoggerT :: Handle -&gt; m a }

instance MonadIO m =&gt; MonadLogger (FileLoggerT m) where
  log msg sev = FileLoggerT { runFileLoggerT = \handle -&gt; liftIO (logFile handle msg sev) }</code></pre>
<p>The database library does the same, and the app combines these together:</p>
<pre><code>newtype MyAppMonad a = ...

instance MonadLogger MyAppMonad where ...

instance MonadDb MyAppMonad where ...</code></pre>
<p>Because we have one type parameter that encapsulates all side effects (instead of one for logging, one for database operations), this avoids the issues with snowballed type parameters in the use sites.</p>
<p>The database library can also add a logger dependency without breaking the user code.</p>
<p>I think this is the best we can get in Haskell, and it’s quite similar to our OOP solution in terms of code changes needed to be done in the user code.</p>
<p>However for this to work the entire ecosystem of libraries need to do things this way. If the database library decides to use the ADT approach, we will need an “adapter”, e.g. a monad typeclass for the DB operations, with a concrete monad transformer type to call the DB library functions.</p>
<p>This is also the main problem with the composable effects libraries.</p>
<p>(There are also issues with how this kind of code performs in runtime, but that’s probably a topic for another blog post.)</p>
<h1 id="composable-effects">Composable effects</h1>
<p>Haskellers have been developing various ways of modelling side effects (such as DB operations, logging) as “effects” and various ways of composing them.</p>
<p>A simple and widespread way of doing this is via the effect monads, as we’ve seen in the previous section.</p>
<p>However these systems have a few drawbacks, compared to our OOP solution:</p>
<ul>
<li><p>Different effect libraries generally don’t work together. For example, <a href="https://hackage.haskell.org/package/mtl">mtl</a> and <a href="https://github.com/hasura/eff">eff</a> functions won’t work together without some kind of adapter turning one into the other.</p></li>
<li><p>Even if the entire Haskell ecosystem decides to use one particular effect system, things like using two different handlers for different parts of the program, such as the example of using different logger in the db library and the main app, requires type juggling. In some effect libraries this is not even possible.</p></li>
<li><p>Finally, note that the OOP code shown in this post are very basic and straightforward code that even a beginner in OOP can write. Any new person who joins the project, or any one time contributor who just wants to fix a bug and move on, will be able to work on either one of the libraries or the application code. It’s difficult to say the same with the composable effects libraries in Haskell.</p></li>
</ul>
<h1 id="conclusions">Conclusions</h1>
<p>Mainstream statically-typed OOP allows straightforward backwards compatible evolution of types, while keeping them easy to compose. I consider this to be one of the killer features of mainstream statically-typed OOP, and I believe it is an essential feature for programming with many people, over long periods of time.</p>
<p>Just like OOP, Haskell has design patterns, such as the effect monad pattern we’ve shown above. Some of these design patterns solve the problem nicely, but they need an entire ecosystem to follow the same pattern to be useful.</p>
<p>I think it would be beneficial for the functional programming community to stop dismissing OOP’s successes in the industry as an accident of history and try to understand what OOP does well.</p>
<hr />
<p>Thanks to Chris Penner and Matthías Páll Gissurarson for reviewing a draft of this blog post.</p>]]></summary>
</entry>
<entry>
    <title>My thoughts on OCaml</title>
    <link href="http://osa1.net/posts/2023-04-24-ocaml-thoughts.html" />
    <id>http://osa1.net/posts/2023-04-24-ocaml-thoughts.html</id>
    <published>2023-04-24T00:00:00Z</published>
    <updated>2023-04-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Since 2013 I’ve had the chance to use OCaml a few times in different jobs, and I got frustrated and disappointed every time I had to use it. I just don’t enjoy writing OCaml.</p>
<p>In this post I want to summarize some of the reasons why I don’t like OCaml and why I wouldn’t choose it for a new project today.</p>
<h1 id="no-standard-and-easy-way-of-implementing-interfaces">No standard and easy way of implementing interfaces</h1>
<p>To me it’s absolutely essential that the language should have some way of defining interfaces, implementing those interfaces for the types, and programming against those interfaces.</p>
<p>In Haskell, this is done with typeclasses. Rust has a similar mechanism called traits. In languages with classes this is often done with abstract classes and “implementing” those classes in new classes (e.g. <code>implements</code> in Dart).</p>
<p>In OCaml there’s no way to do this. I have to explicitly pass functions along with my values, maybe in a product type, or with a functor, or as an argument.</p>
<p>Regardless of how I work around this limitation, it’s extremely inconvenient. Things that must be trivial in any code base, such as converting a value to a string for debugging purposes, become a chore, and sometimes even impossible.</p>
<p>As far as I know, there was at least one attempt at ameliorating this with modular implicits (implicit parameter passing), but I don’t know what happened to it since 2017. It looks like it’s still not a part of the language and the standard library is not using it.</p>
<h1 id="bad-standard-library">Bad standard library</h1>
<p>OCaml’s standard library is just bizarre. It has lots of small issues, and a few larger ones. It’s really just extremely painful to use.</p>
<p>Some examples of the issues:</p>
<ul>
<li><p>Zoo of printing/debugging and conversion functions such as <code>string_of_int</code>, <code>string_of_float</code>, <code>print_char</code>, <code>Int64.of_int</code>, <code>string_of_int</code>, …</p></li>
<li><p>Overly polymorphic operators with type <code>'a -&gt; 'a -&gt; bool</code> such as <code>=</code> (called “structural equality”, throws an exception if you pass a function) and <code>&gt;</code>. Code that uses these operators will probably not work on user-defined types as expected.</p></li>
<li><p>Standard types are sometimes persistent, sometimes mutable. <code>List</code>, <code>Map</code>, and <code>Set</code> are persistent. <code>Stack</code> and <code>Hashtbl</code> are mutable.</p></li>
<li><p>Inconsistent naming:</p>
<ul>
<li>Length function for <code>Map</code> is <code>cardinal</code>, length function for <code>Hashtbl</code> is <code>length</code>.</li>
<li>The “bytes” type is <code>Bytes.t</code>, the big int type is <code>Big_int.big_int</code> (instead of <code>Big_int.t</code>). The functions in these modules are also inconsistently named. <code>Big_int</code> functions are suffixed with <code>_big_int</code>, <code>Bytes</code> module functions are not prefixed or suffixed.</li>
</ul></li>
<li><p>The regex module uses global state: <code>string_match</code> runs a regex and sets some global state. <code>matched_string</code> returns the last matched string using the global state.</p></li>
<li><p>Lack of widely used operations such as <code>popcount</code> for integer types, unicode character operations.</p></li>
<li><p>It doesn’t have proper string and character types: <code>String</code> is a byte array, <code>char</code> is a byte.</p></li>
</ul>
<p>The bad state of OCaml’s standard library also causes fragmentation in the ecosystem with two competing alternatives: <a href="https://opensource.janestreet.com/core/">Core</a> and <a href="https://github.com/ocaml-batteries-team/batteries-included">Batteries</a>.</p>
<h1 id="syntax-problems">Syntax problems</h1>
<p>OCaml doesn’t have a single-line comment syntax.</p>
<p><a href="https://v2.ocaml.org/manual/expr.html">The expression syntax</a> has just too many issues. It’s inconsistent in how it uses delimiters. <code>for</code> and <code>while</code> end with <code>end</code>, but <code>let</code>, <code>if</code>, <code>match</code>, and <code>try</code> don’t, even though the right-most non-terminal is the same in all of these productions:</p>
<pre><code>expr ::= ...
      | while &lt;expr&gt; do &lt;expr&gt; done
      | for &lt;value-name&gt; = &lt;expr&gt; ( to | downto ) &lt;expr&gt; do &lt;expr&gt; done
      | let &lt;let-binding&gt; in &lt;expr&gt;
      | if &lt;expr&gt; then &lt;expr&gt; [ else &lt;expr&gt; ]
      | match &lt;expr&gt; with (| &lt;pattern&gt; [ when &lt;expr&gt; ] -&gt; &lt;expr&gt;)+
      | try &lt;expr&gt; with (| &lt;pattern&gt; [ when &lt;expr&gt; ] -&gt; &lt;expr&gt;)+
      ...</code></pre>
<p>It has <code>for</code> and <code>while</code>, but no <code>break</code> and <code>continue</code>. So you use exceptions with a <code>try</code> inside the loop for <code>continue</code>, and outside for <code>break</code>.</p>
<p>It also has lots of ambiguities, and some of these ambiguities are resolved in an unintuitive way. In addition to making OCaml <a href="https://github.com/ocaml/ocaml/blob/063894d3fa8f63fedf6959744510e1635dccb3ca/parsing/parser.mly#L798-L837">difficult to parse correctly</a>, this can actually cause incorrect reading of the code.</p>
<p>Most common example is probably nesting <code>match</code> and <code>try</code> expressions:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="kw">match</span> e0 <span class="kw">with</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>| p1 -&gt; <span class="kw">try</span> e1 <span class="kw">with</span> p2 -&gt; e2</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>| p3 -&gt; e3</span></code></pre></div>
<p>Here <code>p3 -&gt; e3</code> is a part of the <code>try</code> expression.</p>
<p>Another example is the sequencing syntax <code>&lt;expr&gt; ; &lt;expr&gt;</code> and productions with <code>&lt;expr&gt;</code> as the right-most symbol:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="kw">let</span> test1 b =</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>  <span class="kw">if</span> b <span class="kw">then</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a>    <span class="dt">print_string</span> <span class="st">&quot;1&quot;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>  <span class="kw">else</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a>    <span class="dt">print_string</span> <span class="st">&quot;2&quot;</span>; <span class="dt">print_string</span> <span class="st">&quot;3&quot;</span></span></code></pre></div>
<p>Here <code>print_string "3"</code> is not a part of the <code>if</code> expression, so this function always prints “3”.</p>
<p>However, even though <code>match</code> also has <code>&lt;expr&gt;</code> as the right-most symbol, it has different precedence in comparison to semicolon:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="kw">let</span> test2 b =</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a>  <span class="kw">match</span> b <span class="kw">with</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a>  | <span class="kw">true</span> -&gt; <span class="dt">print_string</span> <span class="st">&quot;1&quot;</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>  | <span class="kw">false</span> -&gt; <span class="dt">print_string</span> <span class="st">&quot;2&quot;</span>; <span class="dt">print_string</span> <span class="st">&quot;3&quot;</span></span></code></pre></div>
<p>Here <code>print_string "3"</code> is a part of the <code>false -&gt; ...</code> branch.</p>
<p>Try to guess how these functions are parsed:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="co">(* Is the last print part of `else` or not? *)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a><span class="kw">let</span> test3 b =</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a>  <span class="kw">if</span> b <span class="kw">then</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a>    <span class="dt">print_string</span> <span class="st">&quot;1&quot;</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a>  <span class="kw">else</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a>    <span class="kw">let</span> x = <span class="st">&quot;2&quot;</span> <span class="kw">in</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a>    <span class="dt">print_string</span> x;</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a>    <span class="dt">print_string</span> <span class="st">&quot;3&quot;</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true"></a><span class="co">(* Is this well-typed? *)</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true"></a><span class="kw">let</span> test4 b =</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true"></a>  <span class="kw">if</span> b <span class="kw">then</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true"></a>    <span class="dv">1</span>, <span class="dv">2</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true"></a>  <span class="kw">else</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true"></a>    <span class="dv">3</span>, <span class="dv">4</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true"></a><span class="co">(* Is the type of this `(int * int) array -&gt; unit` or `int array -&gt; unit * int`? *)</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true"></a><span class="kw">let</span> test5 a = a.(<span class="dv">0</span>) &lt;- <span class="dv">1</span>, <span class="dv">2</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true"></a><span class="co">(* What if I replace `,` with `;`? Does this set the element 1 or 2? *)</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true"></a><span class="kw">let</span> test6 a = a.(<span class="dv">0</span>) &lt;- <span class="dv">1</span>; <span class="dv">2</span></span></code></pre></div>
<p>When writing OCaml you have to keep these rules in mind.</p>
<p>It also has <a href="https://en.wikipedia.org/wiki/Dangling_else">the “dangling else” problem</a>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a><span class="co">(* Is `else` part of the inner `if` or the outer? *)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a><span class="kw">if</span> e1 <span class="kw">then</span> <span class="kw">if</span> e2 <span class="kw">then</span> e3 <span class="kw">else</span> e4</span></code></pre></div>
<p>Finally, and I think this is probably the most strange thing about OCaml’s syntax and I’m not even sure what’s exactly happening here (I can’t find anything relevant in the language documentation), comments in OCaml are somehow tokenized and those tokens need to be terminated. They can be terminated inside another comment, or even outside. This is a bit difficult to explain but here’s a simple example:</p>
<pre><code>(* &quot; *)
print_string &quot;hi&quot;</code></pre>
<p>OCaml 5.0.0 rejects this program with this error:</p>
<pre><code>File &quot;./test.ml&quot;, line 2, characters 16-17:
2 | print_string &quot;hi&quot;
                    ^
  String literal begins here</code></pre>
<p>From the error message it seems like the <code>"</code> in the comment line actually starts a string literal, which is terminated in the first quote of <code>"hi"</code>. The closing double quote of <code>"hi"</code> thus starts another string literal, which is not terminated.</p>
<p>However that doesn’t explain why this works:</p>
<pre><code>(* &quot; *)
print_string &quot;hi&quot;
(* &quot; *)
print_string &quot;bye&quot;</code></pre>
<p>If my explanation of the previous version were correct this would fail with an unbound <code>hi</code> variable, but it works and prints “bye”!</p>
<h1 id="rest-of-the-package-is-also-not-that-good">Rest of the package is also not that good</h1>
<p>I’m not following developments in OCaml ecosystem too closely, but just two years ago it was common to use Makefiles to build OCaml projects. The language server barely worked on a project with less than 50 kloc. There was no standard way of doing compile-time metaprogramming and some projects even used the C preprocessor (cpp).</p>
<p>Some of these things probably improved in the meantime, but the overall package is still not good enough compared to the alternatives.</p>
<h1 id="but-at-least-its-a-functional-language">But at least it’s a functional language?</h1>
<p>Almost all modern statically typed languages have closures, higher-order functions/methods, lazy streams, and combinators that run efficiently. Persistent/immutable data structures can be implemented even in C.</p>
<p>Also, OCaml has no tracking of side-effects (like in Haskell), and the language and the standard library have lots of features and functions with mutation, such as the array update syntax, mutable record fields, <code>Hashtbl</code>, and the regex module.</p>
<p>The only thing that makes OCaml more “functional” than e.g. Dart, Java, or Rust is that it supports tail calls. While having tail calls is important for functional programming, I would happily give up on tail calls if that means not having the problems listed above.</p>
<p>Also keep in mind that when you mix imperative and functional styles tail calls become less important. For example, I don’t have to implement a stream <code>map</code> function in Dart with a tail call to map the rest of the stream, I can just use a <code>while</code> or <code>for</code> loop.</p>
<h1 id="when-should-i-use-it">When should I use it?</h1>
<p>In my opinion there is no reason to use OCaml in a new project in 2023. If you have a reason to think that OCaml is the best choice for a new project please let me know your use case, I’m genuinely curious.</p>]]></summary>
</entry>
<entry>
    <title>Fast polymorphic record access</title>
    <link href="http://osa1.net/posts/2023-01-23-fast-polymorphic-record-access.html" />
    <id>http://osa1.net/posts/2023-01-23-fast-polymorphic-record-access.html</id>
    <published>2023-01-23T00:00:00Z</published>
    <updated>2023-01-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I like <a href="https://osa1.net/posts/2021-04-10-sums-and-products.html">anonymous records</a> and row polymorphism, but until recently I didn’t know how to generate efficient code for polymorphic record access. In this blog post I will summarize the different compilations of polymorphic record accesses that I’m aware of.</p>
<p>All of the ideas shown in this post can be used to access a record field when the record’s concrete type is not known, but the type system guarantees that it has the accessed field. This includes row polymorphism and record subtyping.</p>
<p>Most of the ideas also work when the record’s type is completely unknown and it may not have the accessed field, but some of the optimizations assume accesses cannot fail. Those optimizations can only be used on statically-typed but polymorphic records.</p>
<p>In some of the examples below I will use row polymorphism.</p>
<hr />
<h1 id="row-polymorphism-and-record-subtyping-briefly">Row polymorphism and record subtyping, briefly</h1>
<p>In this blog post we are interested in a specific application of row polymorphism to records. In short, row polymorphism allows type variables denoting sets of record fields, with their types. For example:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a>f <span class="op">:</span> <span class="ot">∀</span> r <span class="op">.</span> { x <span class="op">:</span> <span class="dt">Int</span>, y <span class="op">:</span> <span class="dt">Int</span> <span class="op">|</span> r } <span class="ot">-&gt;</span> <span class="dt">Int</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>f a <span class="ot">=</span> a<span class="op">.</span>x <span class="op">+</span> a<span class="op">.</span>y</span></code></pre></div>
<p>Here the type variable <code>r</code> ranges over set of rows (or records). This function accepts any record as argument as long as the record has at least <code>x : Int</code> and <code>y : Int</code> fields.</p>
<p>The main difference between row polymorphism and record subtyping is that the type variable <code>r</code> can be used in the right-hand side of an arrow as well, allowing passing the record around without losing its concrete type. For example:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a>mapAB <span class="op">:</span> <span class="ot">∀</span> r <span class="op">.</span> { a <span class="op">:</span> <span class="dt">Int</span>, b <span class="op">:</span> <span class="dt">Int</span> <span class="op">|</span> r } <span class="ot">-&gt;</span> (<span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>) <span class="ot">-&gt;</span> { a <span class="op">:</span> <span class="dt">Int</span>, b <span class="op">:</span> <span class="dt">Int</span> <span class="op">|</span> r }</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>mapAB r f <span class="ot">=</span> { a <span class="ot">=</span> f r<span class="op">.</span>a, b <span class="ot">=</span> f r<span class="op">.</span>b, <span class="op">..</span> r }</span></code></pre></div>
<p>This function takes any record that has <code>a : Int</code> and <code>b : Int</code> fields, and returns a new record with updated <code>a</code> and <code>b</code> fields and the rest of the fields. If I pass it a record with type <code>{ a : Int, b : Int, name : String }</code> I get the same type back.</p>
<p>With subtyping, type of this function would look like:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a>mapAB <span class="op">:</span> { a <span class="op">:</span> <span class="dt">Int</span>, b <span class="op">:</span> <span class="dt">Int</span> } <span class="ot">-&gt;</span> (<span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>) <span class="ot">-&gt;</span> { a <span class="op">:</span> <span class="dt">Int</span>, b <span class="op">:</span> <span class="dt">Int</span> }</span></code></pre></div>
<p>In this version the return type just has <code>a</code> and <code>b</code> fields. Rest of the fields are lost. If I pass this a <code>{ a : Int, b : Int, name : String }</code> I get <code>{ a : Int, b : Int }</code> back. The <code>name</code> field is lost.</p>
<hr />
<p>Without subtyping, when the record type in a field access expression is known, it’s easy to generate efficient code: we use the same offsets used when compiling a record literal with the type.</p>
<p>With subtyping, and with row-polymorphism when the record type is not a concrete record type but is a record type with a row variable, type of <code>r</code> in <code>r.a</code> does not immediately give us where in the record’s payload the field <code>a</code> is.</p>
<p>Let’s look at how we might go about implementing record field access in these cases.</p>
<h1 id="records-as-maps">(0) Records as maps</h1>
<p>I don’t think this idea is used in statically-typed languages, but I wanted to include it for completeness.</p>
<p>We can implement records as maps with string keys. Field access then becomes a map lookup.</p>
<p>This is easy to implement because our language probably already has a map implementation in the standard library.</p>
<p>The disadvantages are:</p>
<ul>
<li><p>Depending on the map implementation, every field access require a <code>O(N)</code> or <code>O(log(N))</code> map lookup.</p></li>
<li><p>Map entries will be stored in a separate memory location (instead of in the record object’s payload), which will require pointer chasing to read the field value.</p></li>
<li><p>Unnecessary memory overhead caused by map fields that are not really necessary for records: such as the <code>capacity</code> and <code>size</code> fields.</p></li>
</ul>
<p>With whole-program compilation, we can improve the constant factors a bit by mapping labels (field names) in the program to unique integers. This way lookups don’t require string hashing or comparison, but this is still slow and memory-inefficient compared to other techniques we will discuss below.</p>
<h1 id="passing-accessors-as-parameters">(1) Passing accessors as parameters</h1>
<p>If you’re familiar with Haskell, this is the Haskell way of implementing row polymorphic records.</p>
<p>The idea is that when we pass a record to a row-polymorphic function, we also pass, implicitly, and as functions, the accessors that the function needs.</p>
<p>In Haskell, type of <code>mapAB</code> we’ve seen above would look like this:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a>mapAB <span class="op">:</span> <span class="ot">∀</span> r <span class="op">.</span> (<span class="dt">HasField</span> r <span class="dt">&#39;A</span> <span class="dt">Int</span>, <span class="dt">HasField</span> r <span class="dt">&#39;B</span> <span class="dt">Int</span>) <span class="ot">=&gt;</span> <span class="dt">Record</span> r <span class="ot">-&gt;</span> (<span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>) <span class="ot">-&gt;</span> <span class="dt">Record</span> r</span></code></pre></div>
<p>The runtime values for <code>HasField ...</code> constraints are the accessors. When calling this function we don’t explicitly pass these accessors, the compiler generates them. In a well-typed program, we either have these values in the call site, or we know how to generate them (e.g. the record type is concrete in the call site), so it’s possible for the compiler to generate and pass these arguments.</p>
<p>The main advantage of this approach is that it doesn’t require any language support specifically for records.</p>
<p>The main disadvantages are:</p>
<ul>
<li><p>Every field access is a function call.</p></li>
<li><p>Parameter passing per field per record does not scale well and causes messy and slow generated code. For example, suppose we want to take two records with fields <code>x : Int</code> and <code>y : Int</code>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a>f <span class="op">:</span> <span class="ot">∀</span> r <span class="op">.</span> (<span class="dt">HasField</span> r <span class="dt">&#39;X</span> <span class="dt">Int</span>, <span class="dt">HasField</span> r <span class="dt">&#39;Y</span> <span class="dt">Int</span>) <span class="ot">=&gt;</span> <span class="dt">Record</span> r <span class="ot">-&gt;</span> <span class="dt">Record</span> r <span class="ot">-&gt;</span> <span class="op">...</span></span></code></pre></div>
<p>This function takes two implicit arguments, but it has a limitation that the record arguments need to have the same record types. I can’t call this function with two different records:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a>f { x <span class="ot">=</span> <span class="dv">123</span>, y <span class="ot">=</span> <span class="dv">456</span>, a <span class="ot">=</span> <span class="st">&quot;hi&quot;</span> } { x <span class="ot">=</span> <span class="dv">0</span>, y <span class="ot">=</span> <span class="op">-</span><span class="dv">1</span>, b <span class="ot">=</span> false }</span></code></pre></div>
<p>For this to work I need two row variables:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a>f <span class="op">:</span> <span class="ot">∀</span> r1 r2 <span class="op">.</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a>    (<span class="dt">HasField</span> r1 <span class="dt">&#39;X</span> <span class="dt">Int</span>, <span class="dt">HasField</span> r1 <span class="dt">&#39;Y</span> <span class="dt">Int</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true"></a>     <span class="dt">HasField</span> r2 <span class="dt">&#39;X</span> <span class="dt">Int</span>, <span class="dt">HasField</span> r2 <span class="dt">&#39;Y</span> <span class="dt">Int</span>) <span class="ot">=&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true"></a>    <span class="dt">Record</span> r1 <span class="ot">-&gt;</span> <span class="dt">Record</span> r2 <span class="ot">-&gt;</span> <span class="op">...</span></span></code></pre></div>
<p>This version works, but it also takes 4 implicit arguments.</p></li>
</ul>
<h1 id="prerequisite-integers-for-labels">Prerequisite: integers for labels</h1>
<p>Starting with the next approach, we will require mapping labels (field names) to integers in compile-time, to be used as indices.</p>
<p>Because these integers for labels will be used in record allocation and field accesses, it is possible that a label we see later in a program will cause different code generation for a record field access that we’ve already seen.</p>
<p>We have two options:</p>
<ul>
<li><p>We can avoid this problem with a whole-program pass to collect all labels in the program.</p>
<p>This is trivial with a whole-program compiler as a front-end pass can store all labels seen in a component (library, module) somewhere and we can map those labels to integers before code generation.</p></li>
<li><p>We can have a link-time step to update record allocation and field access code with the integers for the labels.</p></li>
</ul>
<p>In the rest of the post, labels will always get integers based on their lexicographical order and we will call these integers for labels just “labels”.</p>
<p>For example, if I have labels <code>a</code>, <code>c</code>, <code>b</code>, <code>d</code> in my program, their numbers will be 1, 3, 2, 4, respectively.</p>
<h1 id="per-record-label-to-field-offset-tables">(2) Per-record label-to-field-offset tables</h1>
<p>With integers as labels we can add a table to every record (records with the same set of keys sharing the same table) mapping labels in the program to offsets in the record’s payload. For example, the table for a record with fields <code>a</code> and <code>c</code> when the program has labels <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>, looks like this:</p>
<pre><code>[ 0, _, 1, _ ]</code></pre>
<p>This table is indexed by the label and the value gives the offset in the record’s payload for the field. <code>_</code> means the record does not have the field. In a well-typed program we won’t ever see a <code>_</code> value being read from a table.</p>
<p>This approach is quite wasteful as every table will have as many entries as number of labels in the program, but we will compress these tables below to reasonable sizes.</p>
<p>We will call these tables “record offset tables” or “offset tables” in short. When compiling a record access we need to get the record’s offset table. For this we add an extra word (pointer) to record objects pointing to their offset tables. We then generate this code for a record field access:</p>
<pre><code>record[record[OFFSET_TABLE_INDEX][label]]</code></pre>
<p><code>OFFSET_TABLE_INDEX</code> is the constant for where the offset table pointer is in record objects.</p>
<p>Offset tables are generated per record shape (set of labels), so the total number of tables shouldn’t be too large.</p>
<p>Since the <code>_</code> entries won’t ever be used, we can shrink the tables with trailing <code>_</code> entries. In our example above with a record with <code>a</code> and <code>c</code> fields, the last <code>_</code> entry can be omitted:</p>
<pre><code>[ 0, _, 1 ]</code></pre>
<h1 id="making-the-tables-global">(2.1) Making the tables global</h1>
<p>Because offset tables are per-shape, and the total number of record shapes in a program should be small, if we allocate a few bits in record object headers for the “shape index” of the record, this index can be used to index a global table mapping record shapes to their offset tables.</p>
<p>Generated code for record access expressions will look like:</p>
<pre><code>record[RECORD_OFFSET_TABLES[getRecordShapeId(record)][label]]</code></pre>
<p><code>getRecordShapeId</code> will read the bits in the object header for the record shape id. Depending on the actual header layout, it will look something like:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true"></a><span class="dt">int</span> getRecordShapeId(Object* object) {</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true"></a>  <span class="cf">return</span> (object-&gt;header &amp; RECORD_ID_MASK) &gt;&gt; HEADER_BITS;</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true"></a>}</span></code></pre></div>
<p>With record shape IDs in headers and a global table mapping shape IDs to offset tables, we no longer need an extra word in record objects for the offset table pointer.</p>
<p>Here’s an example of offset tables when we have labels <code>a</code>, <code>b</code>, <code>x</code>, <code>y</code>, and two records <code>0: {a, b}</code> and <code>1: {x, y}</code>:</p>
<pre><code>RECORD_0_OFFSET_TABLE = [
  0, // label a
  1, // label b
  _, // label x
  _, // label y
];

RECORD_1_OFFSET_TABLE = [
  _, // label a
  _, // label b
  0, // label x
  1, // label y
];

RECORD_OFFSET_TABLES = [
  RECORD_0_OFFSET_TABLE, // record 0
  RECORD_1_OFFSET_TABLE, // record 1
];</code></pre>
<p>As before, the offset table for record 0 can be shrunk as:</p>
<pre><code>RECORD_0_OFFSET_TABLE = [
  0, // label a
  1, // label b
];</code></pre>
<h1 id="sharing-label-ids-and-record-shapes">(2.2) Sharing label IDs and record shapes</h1>
<p>Labels that are not used in the same record program can be given the same ID.</p>
<p>In the example above, this allows us to have a single table for both records:</p>
<pre><code>RECORD_0_1_OFFSET_TABLE = [
  0, // label a or x
  1, // label b or y
];

RECORD_OFFSET_TABLES = [
  RECORD_0_1_OFFSET_TABLE, // record 0
  RECORD_0_1_OFFSET_TABLE, // record 1
];</code></pre>
<p>The problem of assigning IDs to labels is very similar to stack allocation when spilling during register allocation. We have practically infinite amount of IDs (stack space), but we want to reuse the same ID for labels as long as they’re never used in the same record (live at the same time).</p>
<p>After sharing label IDs, some of the shapes may be identical, as in our example. We can give those shapes the same ID and avoid redundant entries in the offset tables.</p>
<p>With this, our example with two records <code>{a, b}</code> and <code>{x, y}</code> compiles to just one offset table:</p>
<pre><code>RECORD_0_1_OFFSET_TABLE = [
  0, // label a or x
  1, // label b or y
];

RECORD_OFFSET_TABLES = [
  RECORD_0_1_OFFSET_TABLE, // record 0 and 1
];</code></pre>
<h1 id="flattening-the-table">(2.3) Flattening the table</h1>
<p>Suppose we have these record shapes in a program:</p>
<ul>
<li><code>{a, b, q}</code></li>
<li><code>{x, y, q}</code></li>
</ul>
<p>The <code>RECORD_OFFSET_TABLES</code> table is currently an array of pointers, and indexing the offset table still requires pointer chasing.</p>
<p>To avoid pointer chasing we can flatten the table.</p>
<p>For our current program, the tables, without flattening, look like this:</p>
<pre><code>RECORD_0_OFFSET_TABLE = [
  0, // label a
  1, // label b
  _, // label x
  _, // label y
  2, // label q
];

RECORD_1_OFFSET_TABLE = [
  _, // label a
  _, // label b
  0, // label x
  1, // label y
  2, // label q
];

RECORD_OFFSET_TABLES = [
  RECORD_0_OFFSET_TABLE,
  RECORD_1_OFFSET_TABLE,
];</code></pre>
<p>We can flatten this as:</p>
<pre><code>RECORD_0_OFFSET_TABLE = [
  0, // label a
  1, // label b
  _, // label x
  _, // label y
  2, // label q
];

RECORD_1_OFFSET_TABLE = [
  _, // label a
  _, // label b
  0, // label x
  1, // label y
  2, // label q
];

RECORD_LABEL_OFFSETS = [
  0, // record 0, label a
  1, // record 0, label b
  _, // record 0, label x
  _, // record 0, label y
  2, // record 0, label z

  _, // record 1, label a
  _, // record 1, label b
  0, // record 1, label x
  1, // record 1, label y
  2, // record 1, label z
];</code></pre>
<p>Field indexing then becomes:</p>
<pre><code>record[RECORD_LABEL_OFFSETS[(getRecordShapeId(record) * NUM_LABELS) + label]]</code></pre>
<p>With this version we eliminate one layer of indirection.</p>
<h1 id="removing-the-constant-factor">(2.4) Removing the constant factor</h1>
<p>The idea here is not too important on its own, but it will enable further improvements.</p>
<p>The <code>NUM_LABELS</code> factor in field access code above can be eliminated by incrementing record shape IDs by <code>NUM_LABELS</code> instead of 1. In our example, instead of having record IDs 0 and 1, we will have 0 and 5 (incremented by the number of labels in the program).</p>
<p>Since there may be large number of labels in a program and we may have only a few bits to store the record IDs, an alternative would be to convert the table to label-major order like this:</p>
<pre><code>RECORD_LABEL_OFFSETS = [
  0, // label a, record 0
  _, // label a, record 1

  1, // label b, record 0
  _, // label b, record 1

  _, // label x, record 0
  1, // label x, record 1

  _, // label y, record 0
  2, // label y, record 1

  3, // label z, record 0
  3, // label z, record 1
];</code></pre>
<p>With this table, indexing code becomes:</p>
<pre><code>record[RECORD_LABEL_OFFSETS[(label * NUM_RECORDS) + getRecordShapeId(record)]]</code></pre>
<p>We can then eliminate the <code>NUM_RECORDS</code> factor the same way, by incrementing label IDs by <code>NUM_RECORDS</code> instead of 1, and index with:</p>
<pre><code>record[RECORD_LABEL_OFFSETS[label + getRecordShapeId(record)]]</code></pre>
<h1 id="compacting-the-table-further">(2.5) Compacting the table further</h1>
<p>Now that the table index of a label is <code>label + shape_id</code> and we have a single table, we can shift the entries in the table by decrementing label IDs.</p>
<p>For this it doesn’t matter whether we store in label-major or record-major order. Which one of these will generate a smaller table will probably depend on the program. As an example, suppose we store the table in label-major order, and we have these records in the program:</p>
<ul>
<li><code>0: {x, y, z, t}</code></li>
<li><code>1: {x, y}</code></li>
<li><code>2: {z, t}</code></li>
</ul>
<p>The table will look like:</p>
<pre><code>[ 0, 0, _,   // label x
  1, 1, _,   // label y
  2, _, 0,   // label z
  3, _, 1 ]  // label t</code></pre>
<p>Record IDs will be 0, 1, 2, and label IDs will be 0, 3, 6, 9.</p>
<p>We can use the unused slot for label x, record 2, by decrementing the label index for <code>y</code> by one. If we then do the same for <code>z</code>, the label IDs become 0, 2, 4, 7, and the table becomes:</p>
<pre><code>[ 0, 0,      // label x
  1, 1,      // label y
  2, _, 0,   // label z
  3, _, 1 ]  // label t</code></pre>
<p>This idea can be used to fill any gaps in previous label rows, as long as the used slots in a row fits into the gaps. For example, if we have a table like:</p>
<pre><code>[ 0, _, _, 1,  // label x
  _, 0, 1, _,  // label y
  ... ]</code></pre>
<p>We can decrement <code>y</code>’s ID to fit it into the row for label <code>x</code>:</p>
<pre><code>[ 0, 0, 1, 1,  // label x and y, interleaved
  ... ]</code></pre>
<h1 id="conclusions">Conclusions</h1>
<p>Collecting and numbering all labels in the program allows using a global table for mapping labels to offsets.</p>
<p>These offset tables can be made smaller by</p>
<ul>
<li>Giving same number to labels that don’t occur in the same record</li>
<li>Giving same ID to records that become identical after the previous step</li>
<li>Tweaking label numbers so that rows without overlapping entries can be merged into a single row</li>
</ul>
<p>The result is a very compact representation of record objects (no extra words in the header or unused space in the payload needed) and a fast polymorphic field access.</p>
<p>The offset table should also be small in practice, because different parts of the program will probably use disjoint set of names, and different labels and records will have the same IDs. In the remaining cases, tweaking label IDs to compact the table should help.</p>
<h1 id="references">References</h1>
<p>I’ve learned about the global table approach and some of the optimizations from the Dart compiler, which implements virtual calls using a “global dispatch table” (GDT), indexed by <code>classID + methodID</code> in call sites. See <a href="https://mrale.ph/dartvm/#global-dispatch-table-gdt">“Introduction to Dart VM”</a> for a description of how Dart AOT and JIT generate GDTs.</p>
<p>If you are interested in seeing some code, <a href="https://github.com/dart-lang/sdk/blob/ba8f0bd947c613013ed4659ea44da851bf35a99f/pkg/dart2wasm/lib/dispatch_table.dart#L411-L442">here</a> is where we generate the GDT in dart2wasm (Dart’s Wasm backend). The outer loop finds a selector ID (label ID in our examples) for a row (list of records in our examples, list of classes in dart2wasm). The inner loop <code>do { ... } while (!fits)</code> starts from the first row with gaps, and tries to fit the current row into the gaps. In the worst case it skips all of the rows, in which case rest of the code appends the table with the new row.</p>
<p><a href="https://github.com/dart-lang/language/blob/master/accepted/future-releases/records/records-feature-specification.md">Dart will soon have records</a>, and for the <a href="https://github.com/dart-lang/sdk/issues/50014">dart2wasm implementation of records</a> I’m thinking of using some of the ideas described in this post. Dart records do not support width subtyping (you can’t pass <code>{x, y, z}</code> where <code>{x, y}</code> is expected), but because of the <code>dynamic</code> type, we can have a dynamically typed record that we index.</p>
<hr />
<p>Thanks to <a href="https://twitter.com/josecalderon">José Manuel Calderón Trilla</a> for his feedback on a draft of this blog post.</p>]]></summary>
</entry>

</feed>
