<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>osa1.net - Posts tagged en</title>
    <link href="http://osa1.net/tags/en.xml" rel="self" />
    <link href="http://osa1.net" />
    <id>http://osa1.net/tags/en.xml</id>
    <author>
        <name>Ömer Sinan Ağacan</name>
        <email>omeragaca@gmail.com</email>
    </author>
    <updated>2016-11-30T00:00:00Z</updated>
    <entry>
    <title>My new XFCE + i3 setup</title>
    <link href="http://osa1.net/posts/2016-11-30-new-xfce-i3-setup.html" />
    <id>http://osa1.net/posts/2016-11-30-new-xfce-i3-setup.html</id>
    <published>2016-11-30T00:00:00Z</published>
    <updated>2016-11-30T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I’ve been running Linux exclusively since 6-7 years ago, and since my first days on Linux I’ve been obsessed with two things:</p>
<ul>
<li><p>I hate the mouse, and I try really hard to not use it.</p></li>
<li><p>I need a very stable system. If my distro is not stable enough, I try to bring the system to a stable state and then I never update anything. My previous setup had one year uptime and that’s because I never updated anything and it kept running without any problems <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</p></li>
</ul>
<p>Initially I was running GNOME 2, but I had to switch to KDE because the distro I was working on at the time (Pardus) was mainly a KDE distro and as far as I remember it was the only DE that was officially supported<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. It took some time but I ended up liking it quite a lot, and kept using it after I stopped working on Pardus and switched to openSUSE.</p>
<p>My KDE setup was weird. I had dozens of key bindings for window management, and I was using vim and yakuake with lots of customization and key bindings. I basically rolled my own tiling window manager using KDE settings and key bindings.</p>
<p>I tried <a href="http://xmonad.org/">XMonad</a> and <a href="https://awesome.naquadah.org/">awesomewm</a> a couple of times, but I was too lazy to configure them to a stable state where all the services (login/logout, power management, sound and brightness settings, network controllers etc.) work flawlessly.</p>
<p>Then I discovered <a href="https://i3wm.org/">i3</a>. In my first hours with it all I had to change was the <code>jkl;</code> combination for left/down/up/right: I was already an experienced vim user so I changed it to <code>hjkl</code> and that was pretty much it. I had a usable setup already.</p>
<p>The way I run it was again weird. I replaced KDE’s window manager, so all other KDE services were running. This setup had many problems, for example, neither <code>i3bar</code> nor the KDE status bar worked, so I didn’t use a status bar. KDE’s desktop was still running, so I added a status bar widget to the desktop, and I was using a spare i3 desktop when I needed to use the status bar. I had to disable some of the KDE services (like the one that detects connected monitors) because they weren’t working as expected when I replaced the window manager etc. This system worked great for about 2 years once I disabled some of the KDE services that didn’t work properly.</p>
<p>Then, 3 weeks ago, I had some free time, and decided to finally update my system. I was using openSUSE, and I wanted to stick with it, so I installed openSUSE Tumbleweed. This time instead of using a weird KDE + i3 setup I wanted a proper i3 setup. I messed with a plain i3 setup for a while, but it got tiresome real quick, so I looked at other DEs to find one that works with i3.</p>
<p>Long story short, I found out that <a href="https://www.xfce.org/">XFCE</a> and i3 work really great together. It takes 15 minutes to set up my desktop. Here’s how I do it:</p>
<ol style="list-style-type: decimal">
<li><p>Install a distro with a recent XFCE and i3. Install a full XFCE desktop and i3.</p></li>
<li><p><code>xfce4-session-settings</code> &gt; “Session”: Remove everything other than <code>Xfsettingsd</code> and <code>Power Manager</code>.</p></li>
<li><p><code>xfce4-session-settings</code> &gt; “Advanced”: Enable “Launch GNOME services on startup”.</p></li>
<li><p><code>xfce4-session-settings</code> &gt; “Application Autostart”: Add <code>i3</code> executable.</p></li>
</ol>
<p>That’s all you need to get a working XFCE + i3 setup! <code>i3-bar</code> will be used instead of XFCE panel (which you disabled already in step (2)). After this just configure XFCE and i3 as usual.</p>
<p>Here is some of the configurations I do:</p>
<ul>
<li><p>I add <code>/usr/bin/setxkbmap -option &quot;ctrl:nocaps&quot;</code> to <code>xfce4-settings-manager</code> &gt; “Application Autostart” to make caps lock an additional ctrl.</p></li>
<li><p>I install <code>feh</code> and run i3 on i3 startup to set a desktop background image (see my i3 config below).</p></li>
<li><p>I add some key bindings in <code>xfce4-keyboard-settings</code> for sound controls. Normally I add key bindings to i3 config, but it’s hard to find key names for <code>Fn + key</code> combinations and XFCE helps with that part.</p></li>
<li><p>In <code>xfce4-keyboard-settings</code> I set repeat delay 260ms and repeat speed 55 key strokes/second.</p></li>
</ul>
<p>Then I install zsh, vim etc. and generate symlinks for my <a href="https://github.com/osa1/rcbackup">configs</a>. My i3 config is <a href="https://github.com/osa1/rcbackup/blob/master/.i3/config">here</a>.</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>It probably had some security issues though…<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>There was an unofficial work on a GNOME port but it was never completed as far as I know.<a href="#fnref2">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>Papers I read in 2015-2016</title>
    <link href="http://osa1.net/posts/2016-11-15-2015-2016-papers.html" />
    <id>http://osa1.net/posts/2016-11-15-2015-2016-papers.html</id>
    <published>2016-09-11T00:00:00Z</published>
    <updated>2016-09-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>This is my last week at Indiana University. It’ll be almost two years (1 year 11 months) since I came here, and it’s time for me to move on. While cleaning my messy desk covered with papers today I thought maybe I should make list of papers that I read (or at least printed) during this two-year period, so here it is.</p>
<p>Papers are sorted by publication dates. <code>???</code> indicates that the publication date is unknown (or may not be published at all), and those are listed last. I’ve added some very brief notes below some of the papers. Only last names of authors are listed.</p>
<hr />
<ul>
<li><p>On computable numbers, with an application to Entscheidungsproblem – Turing. 1936.</p></li>
<li><p>Computing Machinery and Intelligence – Turing. 1950.</p>
<p>Defines “the imitation game” aka. “Turing test”. Tries to answer some philosophical questions. I remember finding some of the arguments pretty weak.</p></li>
<li><p>Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I – McCarthy. 1960.</p>
<p>A classic. Defines “garbage collection”, “free list” and “stack” for the first time, without actually using those words.</p></li>
<li><p>A basis for a mathematical theory of computation – McCarthy. 1963.</p>
<p>Haven’t read.</p></li>
<li><p>The Next 700 Programming Languages – Landin. 1966.</p>
<p>Classic.</p></li>
<li><p>A Nonrecursive List Compacting Algorithm – Cheney. 1970.</p>
<p>A classic. Only two pages. Algorithm can easily be generalized to collect arbitrary heap objects. Known as “Cheney’s algorithm” in GC literature.</p></li>
<li><p>Monotone Data Flow Analysis Frameworks – Kam, Ullman. 1975.</p></li>
<li><p>Global Data Flow Analysis and Iterative Algorithms – Kam, Ullman. 1976.</p></li>
<li><p>Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints – Cousot, Cousot. 1977.</p>
<p>Cousot &amp; Cousot, so avoid. Read “Principles of Program Analysis” (book) by Nielson, Nielson and Hanking.</p></li>
<li><p>A Real-Time Garbage Collector Based on the Lifetimes of Objects – Lieberman, Hewitt. 1983.</p>
<p>An early generational GC paper. Defines “scavenging” and “evacuation”, some of the terms used in GHC’s GC.</p></li>
<li><p>Generation Scavenging: A Non-disruptive High Performance Storage Reclamation Algorithm – Ungar. 1984.</p></li>
<li><p>Compiling Pattern Matching – Augustsson. 1985.</p>
<p>A very early paper on lazy pattern matching in LML. IIRC the idea is very simple and maybe even obvious, but this is a very early publication on the topic.</p></li>
<li><p>How to Replace Failure by a List of Successes - A method for exception handling, backtracking, and pattern matching in lazy functional languages – Wadler. 1985.</p>
<p>I don’t remember reading this.</p></li>
<li><p>Multilisp: A anguage for Concurrent Symbolic Computation – Halstead. 1985.</p>
<p>Haven’t read this.</p></li>
<li><p>Programming as Theory Building – Naur. 1985.</p>
<p>All I remember about this paper is that I disagreed very strongly with the points made. I see some notes on the paper about why analogies don’t work and are harmful.</p></li>
<li><p>Control Operators, the SECD-Machine, and the λ-Calculus – Felleisen, Friedman. 1986.</p></li>
<li><p>Hygienic Macro Expansion – Kohlbecker, Friedman, Felleisen, Duba. 1986.</p></li>
<li><p>No Silver Bullet - Essence and Accident in Software Engineering – Brooks. 1986.</p></li>
<li><p>ORBIT: An Optimizing Compiler for Scheme. Kranz, Kelsey, Rees, Hudak, Philbin, Adams. 1986.</p></li>
<li><p>The Concept of a Supercompiler – Turchin. 1986.</p>
<p>This is one of the earliest supercompilation papers published in English.</p>
<p>First supercompilation papers were in Russian. First supercompilation paper in English was “A supercompiler system based on the langauge Refal”, Turchin, 1979. I don’t know what happened in the 7 year period, but I think the next paper was this one.</p></li>
<li><p>Efficient Compilation of Pattern-Matching (The Implementation of Functional Programming Languages book chapter) – Wadler. 1987.</p></li>
<li><p>Re-opening Closures – Appel. 1987.</p>
<p>The idea is to optimize closures in runtime using captured variables. I’ve heard that Mu uses some variant of this idea.</p></li>
<li><p>The Concatenate Vanishes – Wadler, 1987.</p>
<p>An even earlier work than the deforestation one. Wadler shows how to “deforest” intermediate lists in some programs. I don’t remember how the idea worked, but it must be just a very simple case-of-case transformation.</p></li>
<li><p>Theorems for free! – Wadler. 1989.</p>
<p>Great paper, shows how parametricity leads to theorems.</p></li>
<li><p>Deforestation: Transforming programs to eliminate trees – Wadler. 1990.</p>
<p>I think this is another classic and coined the term “deforestation”. The paper makes a huge simplifying assumption and assumes that variables are used linearly in function bodies, which makes beta reduction safe in terms of work duplication. So not very useful for practical purposes.</p></li>
<li><p>Linear types can change the world! – Wadler. 1990.</p></li>
<li><p>Implementing Projection-based Strictness Analysis – Kubiak, Hughes, Launchbury. 1992.</p></li>
<li><p>Undecidability of Static Analysis – Landi. 1992.</p>
<p>IIRC this paper shows how interesting static analysis problems are undecidable, by means of reductions from known undecidable problems like the halting problem.</p></li>
<li><p>Unboxed objects and polymorphic typing – Leroy. 1992.</p></li>
<li><p>A Short Cut to Deforestation – Gill, Launchbury, Jones. 1993.</p>
<p>Introduces fold/build rules. Still in use today in GHC.</p></li>
<li><p>Metaobject protocols: Why we want them and what else they can do – Kiczales, Ashley, Rodriguez, Vahdat, Bobrow. 1993.</p></li>
<li><p>Occam’s Razor in Metacomputation: the Notion of a Perfect Process Tree – Glück, Klimov. 1993.</p>
<p>An even earlier paper on “perfect information propagation”. Uses “process trees” which are only used in very early supercompilation papers (including Turchin ones IIRC).</p></li>
<li><p>Syntactic Abstraction in Scheme – Dybvig, Hieb, Bruggeman. 1993.</p>
<p>Go IU!</p></li>
<li><p>What is a Purely Functional Language? – Sabry. 1993.</p></li>
<li><p>Partial Deduction and Driving are Equivalent – Glück, Sørensen. 1994.</p></li>
<li><p>Mix Ten Years Later – Jones. 1995.</p>
<p>I love Neil Jones’s partial evaluation work (and especially the book “Partial Evaluation and Automatic Program Generation” by Jones, Gomard, Sestoft).</p></li>
<li><p>The Design of a Pretty-printing Library – Hughes. 1995.</p></li>
<li><p>A Roadmap to Metacomputation by Supercompilation – Glück, Sørensen. 1996.</p>
<p>Shows how to use supercompilation for metaprogramming tasks “specialization”, “composition” and “inversion”. I don’t even remember what are the latter two though.</p></li>
<li><p>Building Domain-Specific Embedded Languages – Hudak. 1996.</p></li>
<li><p>On Perfect Supercompilation – Secher, Sørensen. 1996.</p>
<p>This paper shows how to do “negative information propagation” during “driving” (see Jones, 2000). “Negative” means “what forms a value cannot take”.</p>
<p>Now that I think about this idea again, I’m wondering in what sense “negative” information is special. Assuming the set of values of a type is finite, you can always express negative information as positive information, e.g. if the set contains <code>{X, Y, Z}</code> <code>cannot be X =&gt; is one of {Y, Z}</code>.</p></li>
<li><p>Realistic Compilation by Partial Evaluator – Sperber, Thiemann. 1996.</p>
<p>I love this paper. It inspired <a href="http://osa1.net/posts/2015-05-13-comp-through-interp.html">a project of mine</a>. I met the first author at ICFP’16 after coincidentally sitting next to him at lunch :) .</p></li>
<li><p>A transformation-based optimiser for Haskell – Jones, Santos. 1997.</p>
<p>Describes “let-no-escape” optimizations that is still in used today in GHC.</p></li>
<li><p>Improvement Theory and its Application – Sands. 1997.</p>
<p>The idea is used in Bolingbroke’s PhD thesis, that’s why I printed this, but I haven’t read it yet.</p></li>
<li><p>MetaML and Multi-Stage Programming with Explicit Annotations – Taha, Sheard. 1997.</p>
<p>Introduction to MetaML.</p></li>
<li><p>Definitional Interpreters for Higher-Order Programming Languages – Reynolds. 1998.</p>
<p>Classic.</p></li>
<li><p>Growing a Language – Steele. 1998.</p>
<p>Watch his talk with the same title instead, it’s awesome.</p></li>
<li><p>Positive supercompilation for a higher-order call-by-value language – Jonsson, Nordlander. 1998.</p>
<p>Funny how the pages are full of notes, yet I don’t remember anything about this paper.</p></li>
<li><p>Type Inference with Constrained Types – Odersky, Sulzmann, Wehr. 1998.</p></li>
<li><p>On the Power of Homeomorphic Embedding for Online Termination – Leuschel, 1998.</p></li>
<li><p>A semantics for imprecise exceptions – Jones, Reid, Hoare, Marlow, Henderson. 1999.</p></li>
<li><p>Call-By-Push-Value: A Subsuming Paradigm (extended abstract) – Levy. 1999.</p>
<p>Another paper that I just couldn’t finish.</p></li>
<li><p>Introduction to Supercompilation – Sørensen, Glück. 1999.</p>
<p>This is a really good introduction. It uses “process trees” which help a lot when trying to understand the idea for the first time. I made a presentation here at IU using process trees in this paper.</p></li>
<li><p>Linear Scan Register Allocation – Poletto, Sarkar. 1999.</p>
<p>Very famous algorithm, used in many JIT compilers. I think GHC also has a variant of this (see <code>compiler/nativeGen/RegAlloc/Linear</code> directory).</p></li>
<li><p>Partial Evaluation and Automatic Program Generation – Jones, Gomard, Sestoft. 1999.</p>
<p>I really like this book. I tried to implement every language in this book, but it became tiresome real quick. Best introduction to partial evaluation.</p></li>
<li><p>Secrets of the Glasgow Haskell Compiler inliner – Jones, Marlow. 1999.</p></li>
<li><p>The STG runtime system (revised) – Jones, Marlow. 1999.</p></li>
<li><p>Compiling Embedded Languages – Elliott, Finne, de Moor. 2000.</p></li>
<li><p>Type-Preserving Garbage Collectors – Wang, Appel. 2001.</p>
<p>Haven’t read this.</p></li>
<li><p>The Essence of Program Transformation by Partial Evaluation and Driving – Jones. 2000.</p>
<p>This paper defines the concept of “driving” which IIRC is also used in some early (before Mitchell and Bolingbroke papers) supercompilation papers.</p></li>
<li><p>Composable and Compilable Macros - When Want it When? – Flatt. 2002.</p></li>
<li><p>Template Meta-programming for Haskell – Sheard, Jones. 2002.</p></li>
<li><p>A Functional Correspondence between Evaluators and Abstract Machines – Ager, Biernacki, Danvy, Midtgaard. 2003.</p></li>
<li><p>From Interpreter to Compiler and Virtual Machine: A Functional Derivation – Ager, Biernacki, Danvy, Midtgaard. 2003.</p></li>
<li><p>Garbage-First Garbage Collection – Detlefts, Flood, Heller, Printezis. 2004.</p></li>
<li><p>Self-Adjusting Computation (PhD thesis) – Acar. 2005.</p>
<p>I started reading this a couple of time, failed every time. I was looking for some “automated” way of getting incremental compilation out of compiler passes that don’t take incremental compilation into account.</p></li>
<li><p>Gaussian Elimination: a case study in efficient genericity with MetaOCaml – Carette. 2005.</p></li>
<li><p>Fast and Loose Reasoning is Morally Correct – Danielsson, Hughes, Hansson, Gibbons. 2006.</p></li>
<li><p>Haskell Is Not Not ML – Rudiak-Gould, Mycroft, Jones. 2006.</p>
<p>I remember trying to read this paper many times, but I couldn’t succeed. I was thinking about an intermediate language that support both lazy and strict programs equally well.</p></li>
<li><p>Out of the Tar Pit – Moseley, Marks. 2006.</p>
<p>Defines “essential complexity” and “accidental complexity”.</p></li>
<li><p>The Development of Chez Scheme – Dybvig. 2006.</p>
<p>Chez in <a href="https://github.com/cisco/ChezScheme">now open source</a>. The runtime performance of Chez programs is good, but the compiler was a huge disappointment for me. Unreadable, undocumented mess, and the passes I was expecting to see is not there (sub-0CFA).</p></li>
<li><p>Call-pattern Specialisation for Haskell Programs – Jones. 2007.</p></li>
<li><p>Faster Laziness Using Dynamic Pointer Tagging – Marlow, Yakushev, Jones. 2007.</p>
<p>The idea is very simple and very effective. It’s in use in GHC today, and it’s saving us a lot of jumps. One of the reasons why unpacking sum types are not as useful as one might expect.</p>
<p>Over the summer 2016 one of the projects I worked on was to improve this in some cases. The problem was that in some cases (when strict fields are involved) GHC is currently not tagging some pointers even though in theory it could and that’d save us some instructions in the binaries. Unfortunately the rabbit hole goes quite deep and I had to drop it to focus on unboxed sums.</p></li>
<li><p>System F with Type Equality Coercions – Sulzmann, Chakravarty, Jones, Donnelly. 2007.</p></li>
<li><p>Generational Real-Time Garbage Collection - A Three-Part Invention for Young Objects – Frampton, Bacon, Cheng, Grove. 2007.</p>
<p>Haven’t read yet.</p></li>
<li><p>Bitcoin: A Peer-to-Peer Electronic Cash System – Satoshi Nakamoto. 2008.</p></li>
<li><p>Computation and State Machines – Lamport. 2008.</p></li>
<li><p>Finally Tagless, Partially Evaluate - Tagless Staged Interpreters for Simpler Typed Languages – Carette, Kiselyov, Shan. 2009.</p></li>
<li><p>Idempotent Work Stealing – Michael, Vechev, Saraswat. 2009.</p>
<p>This idea is used in LVish.</p></li>
<li><p>Positive Supercompilation for a Higher Order Call-By-Value Language – Jonsson, Nordlander. 2009.</p>
<p>An attempt at supercompiling a call-by-value language.</p></li>
<li><p>Supercompiler HOSC 1.0: under the hood – Klyuchnikov, 2009.</p>
<p>The author’s another paper (also listed here) is my favorite introduction to supercompilation.</p></li>
<li><p>Tracing the Meta-Level: PyPy’s Tracing JIT Compiler – Bolz, Cuni, Fijalkowski, Rigo. 2009.</p>
<p>Everything done by RPython/PyPy team is great.</p></li>
<li><p>Types are calling conventions – Bolingbroke, Jones. 2009.</p>
<p>Yet another great Bolingbroke work. I worked on a variant of this during the summer of 2016.</p></li>
<li><p>Abstracting Abstract Machines – Horn, Might. 2010.</p>
<p>I was told that this is very cool work, but I haven’t read it yet.</p></li>
<li><p>A Play on Regular Expressions – Fischer, Huch, Wilke. 2010.</p></li>
<li><p>Lightweight Modular Staging: A Pragmatic Approach to Runtime Code Generation and Compiled DSLs – Rompf, Odersky. 2010.</p>
<p>Scala LMS paper.</p></li>
<li><p>Proving the Equivalence of Higher-Order Terms by Means of Supercompilation – Klyuchnikov, Romanenko. 2010.</p></li>
<li><p>Rethinking Supercompilation – Mitchell. 2010.</p>
<p>I remember that I really liked this paper at the time. Unlike most other papers, this paper can be implemented in a couple of hours, and it works good enough. IIRC the main novelty here was the tag-bag based termination criterion, which was later developed further by Bolingbroke in first “Supercompilation by evaluation” and then in his PhD thesis.</p></li>
<li><p>Scrapping your Inefficient Engine: Using Partial Evaluation to Improve Domain-Specific Language Implementation – Brady, Hammond. 2010.</p>
<p>Introduces Idris’s partial evaluator.</p></li>
<li><p>Supercompilation by Evaluation – Bolingbroke, Jones. 2010.</p>
<p>Best supercompilation paper at the time. The record was later broken again by the author of this paper in his PhD thesis (also listed here). The author is amazing and I was depressed for a very long time after reading his papers (another notable one is “Termination Combinators Forever” which is also listed here). I’ll never be this good as a researcher.</p></li>
<li><p>Ur: Statically-Typed Metaprogramming with Type-Level Record Computation – Chilpala. 2010.</p></li>
<li><p>C4: The Continuously Concurrent Compacting Collector – Tene, Iyengar, Wolf. 2011.</p>
<p>Haven’t read yet.</p></li>
<li><p>Flow-Sensitive Type Recovery in Linear-Log Time – Adams, Keep, Midtgaard, Might, Chauhan, Dybvig. 2011.</p>
<p>Sub-0CFA for type inference. Not used in current Chez implementation as far as I can see. Goal is to eliminate runtime type checks.</p></li>
<li><p>How To Write Shared Libraries – Drepper. 2011.</p></li>
<li><p>Practical aspects of evidence-based compilation in System FC – Vytiniotis, Jones. 2011.</p>
<p>IIRC this stuff was introduced with GHC 7.2. For some reason that I can’t recall, it’s sometimes useful to return coercions in functions. This paper is about that. I don’t remember much although the paper has some notes on it.</p></li>
<li><p>Termination Combinators Forever – Bolingbroke, Jones, Vytiniotis. 2011.</p>
<p>Shows how to build online termination checkers using some primitives and combinators. Checkers are correct by construction. The implementation is used in the author’s implementation of his PhD thesis.</p></li>
<li><p>Challenges for a Trace-Based Just-In-Time Compiler for Haskell – Schilling. 2012.</p>
<p>Read his PhD thesis instead.</p></li>
<li><p>Chaperones and Impersonators: Run-time Support for Reasonable Interposition – Strickland, Tobin-Hochstadt, Findler, Flatt. 2012.</p>
<p>I have a big “NO” marked on the paper in red.</p></li>
<li><p>Explicitly Heterogeneous Metaprogramming with MetaHaskell – Mainland. 2012.</p></li>
<li><p>Self-Optimizing AST Interpreters – Würthinger, Wöß, Stadler, Duboscq, Simon, Wimmer. 2012.</p></li>
<li><p>The HERMIT in the Machine - A Plugin for the Interactive Transformation of GHC Core Language Programs – Farmer, Gill, Komp, Sculthorpe. 2012.</p></li>
<li><p>Call-by-need supercompilation (PhD thesis) – Bolingbroke. 2013.</p></li>
<li><p>Forge: Generating a High Performance DSL Implementation from a Declarative Specification – Sujeeth, Gibbons, Brown, Lee, Rompf, Odersky, Olukotun. 2013.</p>
<p>After having played with LMS and Delite a little bit, I have nothing good to say about this work. Things may be improved since then though.</p></li>
<li><p>Hybrid Partial Evaluation – Shali, Cook. 2013.</p>
<p>Cook has an introductory blog post / web page about partial evaluation which is pretty good.</p></li>
<li><p>Optimizing Data Structures in High-Level Programs – Rompf, Sujeeth, Amin, Brown, Jovanovic, Lee, Jonnalagedda, Olukotun, Odersky. 2013.</p>
<p>A Scala LMS paper. All I remember about these papers is that I didn’t like them.</p></li>
<li><p>One VM to Rule Them All – Würthinger, Wimmer, Wöß, Stadler, Duboscq, Humer, Richards, Simon, Wolczko. 2013.</p>
<p>Has 9 authors.</p></li>
<li><p>Simple and Efficient Construction of Static Single Assignment Form – Braun, Buchwalk, Hack, Leißa, Malloc, Zwinkau. 2013.</p>
<p>I think the algorithm was already known in the compilers community, but this paper publishes it first and benchmarks it.</p></li>
<li><p>Supercompiling Erlang (MSc thesis) – Weinholt. 2013.</p></li>
<li><p>Terra: A Multi-Stage Language for High-Performance Computing – DeVito, Hegarty, Aiken, Hanrahan, Vitek. 2013.</p>
<p>Terra is awesome. I talked a little bit about it in my blog posts <a href="http://osa1.net/posts/2015-05-17-staging-is-not-just-codegen.html">1</a>, <a href="http://osa1.net/posts/2015-08-09-sufficiently-smart-compiler.html">2</a>.</p></li>
<li><p>Trace-based Just-in-time Compilation for Lazy Functional Programming Languages (PhD thesis) – Schilling, 2013.</p>
<p>Two good theses published in 2013, Bolingbroke and this one. Too bad neither of them were pursued further.</p>
<p>IIRC the JIT introduction in this thesis is very easy to read, doesn’t assume a lot of background.</p></li>
<li><p>Combinators for Impure yet Hygienic Code Generation – Kameyama, Kiselyov, Shan. 2014.</p></li>
<li><p>Compiling a Reflective Language using MetaOCaml – Asai. 2014.</p>
<p>I love everything related with MetaOCaml.</p></li>
<li><p>Freeze After Writing - Quasi-Deterministic Parallel Programming with LVars – Kuper, Turon, Krishnaswami, Newton. 2014.</p></li>
<li><p>Macros that Work Together - Compile-Time Bindings, Partial Expression, and Definition Contexts – Flatt, Culpepper, Darais, Findler. 2014.</p></li>
<li><p>Modular, Higher-Order Cardinality Analysis in Theory and Practice – Sergey, Vytiniotis, Jones. 2014.</p>
<p>This is still in use in GHC today. Cardinality analysis is done as a part of demand analysis (lattice is extended to handle cardinalities).</p></li>
<li><p>Optimizing SYB Is Easy! – Adams, Farmer, Magalhaes. 2014.</p></li>
<li><p>Safe Zero-cost Coercions for Haskell (extended edition) – Breitner, Eisenberg, Jones, Weirich. 2014.</p>
<p>Another paper full of notes yet I don’t remember anything.</p></li>
<li><p>Supercompilation: Ideas and Methods – Klyuchnikov, Krustev. 2014.</p>
<p>Published in “The Monad.Reader” issue 23, this is without a doubt the best introduction to supercompilation. It’s very well written, provides great bibliography for further reading, and comes with a simple implementation. Great stuff, although the language is too simple to be useful.</p></li>
<li><p>Taming the Parallel Effect Zoo – Kuper, Todd, Tobin-Hochstadt, Newton. 2014.</p></li>
<li><p>The Kansas University Rewrite Engine - A Haskell-Embedded Strategic Programming Language with Custom Closed Universes – Sculthorpe, Frisby, Gill. 2014.</p>
<p>This is about KURE, rewrite engine that powers HERMIT. I remember that at the time I decided to implement my own rewrite combinators than fighting HERMIT API to do whatever I wanted to do.</p></li>
<li><p>Go 1.5 concurrent garbage collector pacing – Celements. 2015.</p></li>
<li><p>Static Program Analysis (lecture notes) – Møller, Schwartzbach. 2015.</p>
<p><a href="https://cs.au.dk/~amoeller/spa/" class="uri">https://cs.au.dk/~amoeller/spa/</a></p></li>
<li><p>Static Single Assignment Book (in-progress book) – “Lots of authors”. 2015 (ongoing)</p>
<p>I’m still reading this.</p></li>
<li><p>Shallow Embedding of DSLs via Online Partial Evaluation – Leißa, Boesche, Hack, Membarth, Slusallek. 2015.</p></li>
<li><p>The Design of Terra: Harnessing the Best Features of High-Level and Low-Level Languages – DeVito, Hanrahan. 2015.</p></li>
<li><p>Improving Implicit Parallelism – Trilla, Runciman. 2015.</p></li>
<li><p>K-Java: A Complete Semantics of Java – Bogdanas, Rosu. 2015.</p></li>
<li><p>Zero-Overhead Metaprogramming – Marr, Seaton, Ducasse. 2015.</p>
<p>Related with JITs, partial evaluation, and metaobject protocols. I don’t remember reading this.</p></li>
<li><p>GADTs Meet Their Match: Pattern-Matching Warnings That Account for GADTs, Guards, and Laziness – Karachalias, Schrivers, Vytiniotis, Jones. 2016.</p></li>
<li><p>Staging Generic Programming – Yallop. 2016.</p></li>
<li><p>State Machines All The Way Down - An Architecture for Dependently Typed Applications – Brady. 2016.</p></li>
</ul>
<hr />
<ul>
<li><p>Common Subexpression Elimination in a Lazy Functional Language – Chitil. ???</p>
<p>Shows how CSE can lead to more memory residency and is not always beneficial.</p></li>
<li><p>Constructed Product Result Analysis for Haskell – Baker-Finch, Glynn, Jones. ???</p>
<p>This is still a part of GHC, done during demand analysis. We recently extended this to work on sum types.</p></li>
<li><p>Demand analysis (draft, not published) – Jones, Sestoft, Hughes</p>
<p>I hate this paper because it wasted so much of my time. GHC wiki links to that, even though this is not relevant to the implementation. Read Sergey et al. instead.</p></li>
<li><p>Lecture Notes: Control Flow Analysis for Functional Languages (lecture notes) – Aldrich. ???</p></li>
<li><p>Supercompiling with Staging – Inoue. ???</p>
<p>Shows how to use MetaOCaml’s staging operators to do supercompilation-like transformations.</p></li>
<li><p>Space and Time Efficient Supercompilation (PhD thesis) – Jonsson. ???.</p></li>
<li><p>The Design and Implementation of BER MetaOCaml – Kiselyov. ???</p></li>
<li><p>The Next Stage of Staging – Inoue, Kiselyov, Kameyama. ???</p></li>
<li><p>Two Techniques for Compiling Lazy Pattern Matching – Maranget. ???</p></li>
<li><p>Warnings for pattern matching – Maranget. ???</p></li>
</ul>]]></summary>
</entry>
<entry>
    <title>More Rust problems (and a sketch of a solution)</title>
    <link href="http://osa1.net/posts/2016-09-11-more-rust-problems.html" />
    <id>http://osa1.net/posts/2016-09-11-more-rust-problems.html</id>
    <published>2016-09-11T00:00:00Z</published>
    <updated>2016-09-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>It’s a nice coincidence that after a good productive weekend of Rust hacking I saw <a href="https://hackernoon.com/why-im-dropping-rust-fd1c32986c88">this blog post</a> about why the author is dropping Rust. I’ve been doing a lot of Rust programming lately (I have at least 3 programs –not libraries– that I’m hoping to publish in the near future), and I’m surprised to see that no one mentioned in the discussion threads about this blog post what IMHO is one of the most annoying problems with Rust.</p>
<p>Borrow checker rejects some programs that are perfectly valid in other languages, and by itself this isn’t a problem. Similar things happen in all languages <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. One of the first problems I encountered after started to write Rust was the OP’s second problem, namely, cyclic data structures (or graphs, but more specifically, widgets with parent/child relations). However, there is at least one pretty good solution for this, and all you need is to think harder and experiment with alternative designs. I’m actually very happy with my solution to this (which is also discovered independently by many people, for an example, see <a href="https://crates.io/crates/petgraph">petgraph</a>).</p>
<p>However, there are problems that basically can’t be solved in Rust without paying some runtime costs or using bad practices. See my <a href="">previous blog post</a> for some examples. In this post I’m going to show another, and more annoying, problem.</p>
<h1 id="self-borrows-all-of-its-fields"><code>self</code> borrows all of its fields</h1>
<p>This is a problem that happened in pretty much every single Rust program I’ve ever written. In a method, you can’t borrow some fields, and call another <code>&amp;mut self</code> method. This is because methods borrow the whole <code>self</code>, so you get an error saying that you can’t borrow <code>self</code> twice.</p>
<p>As an example, imagine writing a compiler. For some reason you want to collect all the variables defined in a scope, and then generate fresh variables for those. You may do something like this:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> FreshGen { <span class="co">/* abstract */</span> }

<span class="kw">struct</span> Var { <span class="co">/* abstract */</span> }

<span class="kw">impl</span> FreshGen {
    <span class="kw">fn</span> fresh(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; Var {
        <span class="pp">unimplemented!</span>()
    }
}

<span class="kw">struct</span> Compiler {
    fresh_gen: FreshGen,
    vars_in_scope: <span class="dt">Vec</span>&lt;Var&gt;,
}

<span class="kw">impl</span> Compiler {
    <span class="kw">fn</span> fresh(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; Var {
        <span class="kw">self</span>.fresh_gen.fresh()
    }

    <span class="kw">fn</span> gen_locals(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
        <span class="kw">let</span> <span class="kw">mut</span> fresh_vars = <span class="pp">vec!</span>[];
        <span class="kw">for</span> var <span class="kw">in</span> <span class="kw">self</span>.vars_in_scope.iter() {
            fresh_vars.push(<span class="kw">self</span>.fresh());
        }
        <span class="co">// use fresh_vars</span>
    }
}</code></pre></div>
<p>Can you see any problems here? When I compile this with nightly 11/9/2016, I get this annoying error message:</p>
<pre><code>error[E0502]: cannot borrow `*self` as mutable because `self.vars_in_scope` is also borrowed as immutable
  --&gt; &lt;anon&gt;:24:29
   |
23 |         for var in self.vars_in_scope.iter() {
   |                    ------------------ immutable borrow occurs here
24 |             fresh_vars.push(self.fresh());
   |                             ^^^^ mutable borrow occurs here
25 |         }
   |         - immutable borrow ends here</code></pre>
<p>So basically, <code>self.vars_in_scope</code> is borrowed from <code>self</code>, and then <code>self.fresh()</code> is called while <code>vars_in_scope</code> is still borrowed. Even though <code>self.fresh()</code> doesn’t have anything to do with <code>self.vars_in_scope</code>, this is not allowed because the compiler simply doesn’t care about what pieces of <code>self</code> methods actually borrow. For me this is probably the #1 most annoying problem with Rust.</p>
<p>Now, I believe this problem is solvable. I imagine an algorithm like this:</p>
<p>It works in two steps.</p>
<ol style="list-style-type: decimal">
<li><p>We generate, for every method, borrow sets. A borrow set is a set of fields that are, at some point in the method, borrowed from <code>self</code>.</p></li>
<li><p>For every method call statement in every method, we look at intersections of currently borrowed fields and the borrow set of callee (i.e. (1) for the method being called).</p></li>
</ol>
<p>(1) works like this:</p>
<pre><code>workset = set of all methods
caller-graph = graph of all methods, with edges from callees to callers

# initially none of methods borrow any fields
for method in methods:
    method.borrows = empty set

while workset is not empty:
    work = workset.pop()
    for statement in work.statements:
        for field in self.borrowed_at(statement):
            if not work.borrows.contains(field):
                work.borrows.insert(field)
                for caller in caller-graph[work]:
                    workset.insert(caller)</code></pre>
<p>For a statement that has a method call, <code>borrowed_at()</code> returns the borrow set of the method being called. So when we update borrow set of a method, we add its callers to the workset and <code>borrowed_at()</code> will return more variables next time, propagating the information in the graph from callees to callers.</p>
<p>Now, for the second step, we first need to generate “live ranges” of borrowed fields. Assume that they’re generated.</p>
<pre><code>for method in methods:
    for borrowed_field in method.borrows():
        for field_live_range in borrowed_field.live_ranges():
            # for methods called in the range
            for method in method_calls(field_live_range):
                if method.borrows().contains(borrowed_field):
                    error(&quot;can&#39;t borrow twice&quot;)</code></pre>
<p>I sketched this in 30 minutes so I don’t expect this to work perfectly. Also, 4-level nested for loops look scary! But this is just to give an idea of how this might be solved.</p>
<p>In the example I showed above, borrow set of <code>fresh</code> would be <code>{fresh_gen}</code>, and borrow set of <code>gen_locals</code> would be <code>{vars_in_scope, fresh_gen}</code>. Now we look at live ranges of variables borrowed from <code>self</code> in <code>gen_locals</code>.</p>
<ul>
<li><code>vars_in_scope</code> lives between lines 2-4 in the method.</li>
<li><code>fresh_gen</code> lives in line 3 in the method.</li>
</ul>
<p>Since each variable has only one live range here, clearly there won’t be any intersections. So this would pass the borrow checker.</p>
<p>If <code>fresh</code> was also borrowing <code>vars_in_scope</code>, we’d get an error because <code>vars_in_scope</code> would now have two “live ranges”: between lines 2-4 as before, and in line 3. Since those intersect, we get an error.</p>
<p>(Again, this is a very quick sketch, so let me know if I’m missing something.)</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I’m hoping to write more about this later. For now, think Haskell’s type system that separates pure functions from effectful ones as an example.<a href="#fnref1">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>I'm available for job offers</title>
    <link href="http://osa1.net/posts/2016-09-05-available-for-offers.html" />
    <id>http://osa1.net/posts/2016-09-05-available-for-offers.html</id>
    <published>2016-09-05T00:00:00Z</published>
    <updated>2016-09-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>After two years as a PhD student at Indiana University, I finally decided to move to the industry, and I’m currently available for job offers.</p>
<p>For the most part I really enjoyed my time here at Indiana University. I still think that IU is the ideal place for someone like me to pursue a PhD. We have a great <a href="http://wonks.github.io/">programming languages group</a>, and the group I work more closely (with <a href="http://www.cs.indiana.edu/~rrnewton/homepage.html">my advisor</a>) is doing lots of hacking, on GHC (we have two core GHC developers in our group!), various Haskell libraries like <a href="https://github.com/iu-parfunc/lvars">lvish</a>, and <a href="http://www.cs.indiana.edu/~rrnewton/papers/pldi16-crossmod.pdf">runtime binary instrumentation tools</a>, which I really enjoy.</p>
<p>But publications are still a big part of the life as a PhD student, and I really, really disliked everything about publishing a paper. I’ve never wanted to have great publications, I’m more interested in learning about programming languages, compilers, and related tools, and contributing to projects that I believe are contributing to the community (which is one of my motivations when contributing to GHC). I want to have a deep understanding of fundamentals of programming languages and compilers, but I also want to develop as a programmer and software engineer.</p>
<p>Graduate school just didn’t let me do these as much as I’d like, and instead forced me to write papers. After about a year it started to become clear to me that academia is not the right place for me because I will probably never enjoy writing papers or grant proposals. So I realized that the long road to PhD in the US (about 6 years usually, followed by more years as postdoc) will be mostly a waste of time, and I won’t be as successful as I want because I don’t enjoy publishing papers.</p>
<p>Sure, I can be a PL researcher/developer in the industry after a PhD. But I believe if I can find a somewhat related job right now, in a few years I can be a PL researcher/developer, without wasting my 3-4 years suffering while trying to publish papers. If I can’t find such a job, well, I think I’ll still be happier because at least I’ll be programming and be much more productive.</p>
<p>So I decided that it’s best for me to do the switch as soon as possible.</p>
<p>If you’re interested, send me an email and let’s have a chat.</p>]]></summary>
</entry>
<entry>
    <title>Add a flag to your compiler to print errors in reversed order</title>
    <link href="http://osa1.net/posts/2016-09-04-reverse-error-messages.html" />
    <id>http://osa1.net/posts/2016-09-04-reverse-error-messages.html</id>
    <published>2016-09-04T00:00:00Z</published>
    <updated>2016-09-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>About a year ago <a href="https://ghc.haskell.org/trac/ghc/ticket/10848">I opened a feature request</a> for printing error messages in reversed order in GHC. By default most compilers print error messages by sorting them by the line number that they’re originated from. This is good when you get one or two error messages because in that case messages usually fit in the screen. But when you’re middle of a big refactoring (even if it’s just renaming a type) usually what happens is, you make your changes, reload/recompile the code, scroll up for 5 seconds to find the first error, fix it, and repeat.</p>
<p>The reason you scroll up is because most of the time declarations come before uses, and fixing a declaration makes error messages originated from use sites go away.</p>
<p>With a flag that reverses the error message order this becomes much simpler because you don’t need to scroll every time you reload/recompile. So if you’re developing a compiler, please consider adding this to your compiler.</p>
<p>(If you’re a GHC user, this is available with <code>-freverse-errors</code> flag)</p>]]></summary>
</entry>
<entry>
    <title>IORef and STRef under the hood</title>
    <link href="http://osa1.net/posts/2016-07-25-IORef-STRef-exposed.html" />
    <id>http://osa1.net/posts/2016-07-25-IORef-STRef-exposed.html</id>
    <published>2016-07-25T00:00:00Z</published>
    <updated>2016-07-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In this post we’ll take a look at internals of GHC’s mutable variables, and how they’re used by <a href="http://hackage.haskell.org/package/base-4.9.0.0/docs/Data-IORef.html"><code>IORef</code></a> and <a href="http://hackage.haskell.org/package/base-4.9.0.0/docs/Data-STRef.html"><code>STRef</code></a>. The code is copied from GHC, with minor changes for clarity.</p>
<hr />
<pre><code>λ&gt; :m + Data.IORef
λ&gt; :info IORef
newtype IORef a
  = GHC.IORef.IORef (GHC.STRef.STRef GHC.Prim.RealWorld a)
        -- Defined in ‘GHC.IORef’
instance Eq (IORef a) -- Defined in ‘GHC.IORef’</code></pre>
<p><code>GHC.IORef</code> is defined in <code>libraries/base/GHC/IORef.hs</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | A mutable variable in the &#39;IO&#39; monad</span>
<span class="kw">newtype</span> <span class="dt">IORef</span> a <span class="fu">=</span> <span class="dt">IORef</span> (<span class="dt">STRef</span> <span class="dt">RealWorld</span> a)</code></pre></div>
<p>We’ll look at 3 operations: read, write, and atomic modify.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | Read the value of an &#39;IORef&#39;</span>
<span class="ot">readIORef   ::</span> <span class="dt">IORef</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> a
readIORef  (<span class="dt">IORef</span> var) <span class="fu">=</span> stToIO (readSTRef var)

<span class="co">-- | Write a new value into an &#39;IORef&#39;</span>
<span class="ot">writeIORef  ::</span> <span class="dt">IORef</span> a <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
writeIORef (<span class="dt">IORef</span> var) v <span class="fu">=</span> stToIO (writeSTRef var v)

<span class="ot">atomicModifyIORef ::</span> <span class="dt">IORef</span> a <span class="ot">-&gt;</span> (a <span class="ot">-&gt;</span> (a,b)) <span class="ot">-&gt;</span> <span class="dt">IO</span> b
atomicModifyIORef (<span class="dt">IORef</span> (<span class="dt">STRef</span> r<span class="fu">#</span>)) f <span class="fu">=</span> <span class="dt">IO</span> <span class="fu">$</span> \s <span class="ot">-&gt;</span> atomicModifyMutVar<span class="fu">#</span> r<span class="fu">#</span> f s</code></pre></div>
<p><code>STRef</code> is defined in <code>libraries/base/GHC/STRef.hs</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | A value of type `STRef s a` is a mutable variable in state thread `s`,</span>
<span class="co">-- containing a value of type `a`</span>
<span class="kw">data</span> <span class="dt">STRef</span> s a <span class="fu">=</span> <span class="dt">STRef</span> (<span class="dt">MutVar</span><span class="fu">#</span> s a)

<span class="co">-- | Read the value of an &#39;STRef&#39;</span>
<span class="ot">readSTRef ::</span> <span class="dt">STRef</span> s a <span class="ot">-&gt;</span> <span class="dt">ST</span> s a
readSTRef (<span class="dt">STRef</span> var<span class="fu">#</span>) <span class="fu">=</span> <span class="dt">ST</span> <span class="fu">$</span> \s1<span class="fu">#</span> <span class="ot">-&gt;</span> readMutVar<span class="fu">#</span> var<span class="fu">#</span> s1<span class="fu">#</span>

<span class="co">-- | Write a new value into an &#39;STRef&#39;</span>
<span class="ot">writeSTRef ::</span> <span class="dt">STRef</span> s a <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> <span class="dt">ST</span> s ()
writeSTRef (<span class="dt">STRef</span> var<span class="fu">#</span>) val <span class="fu">=</span> <span class="dt">ST</span> <span class="fu">$</span> \s1<span class="fu">#</span> <span class="ot">-&gt;</span>
    <span class="kw">case</span> writeMutVar<span class="fu">#</span> var<span class="fu">#</span> val s1<span class="fu">#</span> <span class="kw">of</span>
      s2<span class="fu">#</span> <span class="ot">-&gt;</span> (<span class="fu">#</span> s2<span class="fu">#</span>, () <span class="fu">#</span>)</code></pre></div>
<p>Note that there’s no <code>atomicModifySTRef</code>, because that only makes sense in IO context. So <code>atomicModifyIORef</code> directly calls the primop.</p>
<p>In summary:</p>
<ul>
<li>IORef: <code>MutVar#</code>, wrapped with <code>STRef</code>. When we unpack an <code>IORef</code> in data constructor fields, internally we store a <code>MutVar#</code>.</li>
<li>writeIORef, writeSTRef: <code>writeMutVar#</code></li>
<li>readIORef, readSTRef: <code>readMutVar#</code></li>
<li>atomicModifyIORef: <code>atomicModifyMutVar#</code></li>
</ul>
<h1 id="readmutvar">readMutVar#</h1>
<p>Primop definition:</p>
<pre><code>primop  ReadMutVarOp &quot;readMutVar#&quot; GenPrimOp
   MutVar# s a -&gt; State# s -&gt; (# State# s, a #)
   {Read contents of {\tt MutVar\#}. Result is not yet evaluated.}
   with
   has_side_effects = True
   can_fail         = True</code></pre>
<p>Code generation is handled by <code>StgCmmPrim.emitPrimOp</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">emitPrimOp ::</span> <span class="dt">DynFlags</span>
           <span class="ot">-&gt;</span> [<span class="dt">LocalReg</span>]        <span class="co">-- where to put the results</span>
           <span class="ot">-&gt;</span> <span class="dt">PrimOp</span>            <span class="co">-- the op</span>
           <span class="ot">-&gt;</span> [<span class="dt">CmmExpr</span>]         <span class="co">-- arguments</span>
           <span class="ot">-&gt;</span> <span class="dt">FCode</span> ()

<span class="fu">...</span>

emitPrimOp dflags [res] <span class="dt">ReadMutVarOp</span> [mutv]
   <span class="fu">=</span> emitAssign (<span class="dt">CmmLocal</span> res) (cmmLoadIndexW dflags mutv (fixedHdrSizeW dflags) (gcWord dflags))</code></pre></div>
<p>This is just relative addressing, base is the <code>MutVar#</code> we’re reading, and we skip the closure header to read the contents.</p>
<h1 id="writemutvar">writeMutVar#</h1>
<p>Primop definition:</p>
<pre><code>primop  WriteMutVarOp &quot;writeMutVar#&quot;  GenPrimOp
   MutVar# s a -&gt; a -&gt; State# s -&gt; State# s
   {Write contents of {\tt MutVar\#}.}
   with
   has_side_effects = True
   code_size        = { primOpCodeSizeForeignCall }
                         -- for the write barrier
   can_fail         = True</code></pre>
<p>Code generation is again implemented in <code>emitPrimOp</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">emitPrimOp dflags [] <span class="dt">WriteMutVarOp</span> [mutv,var]
   <span class="fu">=</span> <span class="kw">do</span> emitStore (cmmOffsetW dflags mutv (fixedHdrSizeW dflags)) var
        emitCCall [<span class="co">{-no results-}</span>]
                  (<span class="dt">CmmLit</span> (<span class="dt">CmmLabel</span> mkDirty_MUT_VAR_Label))
                  [(<span class="dt">CmmReg</span> (<span class="dt">CmmGlobal</span> <span class="dt">BaseReg</span>), <span class="dt">AddrHint</span>), (mutv,<span class="dt">AddrHint</span>)]</code></pre></div>
<p>This is more involved than <code>readMutVar#</code>. First, we write the variable to the <code>MutVar#</code> in the first line (<code>emitStore</code>). Then, we call a function, specified by the variable <code>mkDirty_MUT_VAR_Label</code>, passing two arguments: a global called <code>BaseReg</code>, and the <code>MutVar#</code>. <code>mkDirty_MUT_VAR_Label</code> just holds the name of this function: (defined in <code>rts/sm/Storage.c</code>)</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/*</span>
<span class="co">   This is the write barrier for MUT_VARs, a.k.a. IORefs.  A</span>
<span class="co">   MUT_VAR_CLEAN object is not on the mutable list; a MUT_VAR_DIRTY</span>
<span class="co">   is.  When written to, a MUT_VAR_CLEAN turns into a MUT_VAR_DIRTY</span>
<span class="co">   and is put on the mutable list.</span>
<span class="co">*/</span>
<span class="dt">void</span> dirty_MUT_VAR(StgRegTable *reg, StgClosure *p)
{
    Capability *cap = regTableToCapability(reg);
    <span class="cf">if</span> (p-&gt;header.info == &amp;stg_MUT_VAR_CLEAN_info) {
        p-&gt;header.info = &amp;stg_MUT_VAR_DIRTY_info;
        recordClosureMutated(cap,p);
    }
}</code></pre></div>
<p>Remember that for the first argument we passed something called <code>BaseReg</code>, and for the second argument we passed the <code>MutVar#</code>.</p>
<p>This function gets a <code>Capability</code> from the register table, and if the <code>MutVar#</code> is “clean”, it marks it as “dirty” and records in the capability that it’s now mutated.</p>
<p><code>Capability</code> lacks documentation, but it’s not too important, so we just skip that and look at <code>recordClsoureMutated</code>.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="dt">void</span> recordClosureMutated(Capability *cap, StgClosure *p)
{
    bdescr *bd = Bdescr((StgPtr)p);
    <span class="cf">if</span> (bd-&gt;gen_no != <span class="dv">0</span>) recordMutableCap(p,cap,bd-&gt;gen_no);
}</code></pre></div>
<p><code>p</code> is our <code>MutVar#</code> here. <code>bdescr</code> stands for “block descriptor”. GHC RTS allocates memory in blocks, and every block belongs to a generation. First generation is special in that if a <code>MutVar#</code> is in the first generation, it can’t point to a younger generation, as the first generation is already the youngest generation. This is from <code>includes/rts/storage/GC.h</code>:</p>
<pre><code>- generation 0 is the allocation area.  It is given a fixed set of blocks
  during initialisation, and these blocks normally stay in G0S0.  In parallel
  execution, each Capability has its own nursery.</code></pre>
<p>This code basically checks if the <code>MutVar#</code> belongs to first generation (generation 0). If that’s not the case, we record the <code>MutVar#</code> in the generation’s “mut list”:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="dt">void</span> recordMutableCap(<span class="dt">const</span> StgClosure *p, Capability *cap, <span class="dt">uint32_t</span> gen)
{
    bdescr* bd = cap-&gt;mut_lists[gen];
    <span class="cf">if</span> (bd-&gt;free &gt;= bd-&gt;start + BLOCK_SIZE_W) {
        bdescr *new_bd = allocBlockOnNode_lock(cap-&gt;node);
        new_bd-&gt;link = bd;
        bd = new_bd;
        cap-&gt;mut_lists[gen] = bd;
    }
    *bd-&gt;free++ = (StgWord)p;
}</code></pre></div>
<p>Garbage collector then checks that list when collecting younger generations, to avoid collecting young objects kept alive by older generations (i.e. pointers from older generations to younger generations, see <code>scavenge_capability_mut_lists</code> in <code>rts/sm/Scav.c</code>).</p>
<p>We saw in <code>dirty_MUT_VAR</code> that the <code>MutVar#</code> is marked as “dirty” when it’s mutated. When is it marked as “clean” again?</p>
<p>When a <code>MutVar#</code> is copied during GC, the object pointed by it is also copied to the same generation, and then the <code>MutVar#</code> becomes clean again, because it no longer points to a younger generation. This is the related code:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="dt">static</span> <span class="dt">void</span>
scavenge_block(bdescr *bd)
{
    ...
    <span class="cf">case</span> MUT_VAR_DIRTY:
        gct-&gt;eager_promotion = rtsFalse;
        evacuate(&amp;((StgMutVar *)p)-&gt;var);
        gct-&gt;eager_promotion = saved_eager_promotion;
        <span class="cf">if</span> (gct-&gt;failed_to_evac) {
            ((StgClosure *)q)-&gt;header.info = &amp;stg_MUT_VAR_DIRTY_info;
        } <span class="cf">else</span> {
            ((StgClosure *)q)-&gt;header.info = &amp;stg_MUT_VAR_CLEAN_info;
        }
        p += sizeofW(StgMutVar);
        <span class="cf">break</span>;
    ...
}</code></pre></div>
<h1 id="atomicmodifymutvar">atomicModifyMutVar#</h1>
<p>Primop definition:</p>
<pre><code>primop  AtomicModifyMutVarOp &quot;atomicModifyMutVar#&quot; GenPrimOp
   MutVar# s a -&gt; (a -&gt; b) -&gt; State# s -&gt; (# State# s, c #)
   with
   out_of_line      = True
   has_side_effects = True
   can_fail         = True</code></pre>
<p><code>out_of_line = True</code> basically tells code generator that this primop is implemented as a function. Code generator then just generates a function call:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">cgOpApp ::</span> <span class="dt">StgOp</span>        <span class="co">-- The op</span>
        <span class="ot">-&gt;</span> [<span class="dt">StgArg</span>]     <span class="co">-- Arguments</span>
        <span class="ot">-&gt;</span> <span class="dt">Type</span>         <span class="co">-- Result type (always an unboxed tuple)</span>
        <span class="ot">-&gt;</span> <span class="dt">FCode</span> <span class="dt">ReturnKind</span>

<span class="fu">...</span>

cgOpApp (<span class="dt">StgPrimOp</span> primop) args res_ty <span class="fu">=</span> <span class="kw">do</span>
    dflags <span class="ot">&lt;-</span> getDynFlags
    cmm_args <span class="ot">&lt;-</span> getNonVoidArgAmodes args
    <span class="kw">case</span> shouldInlinePrimOp dflags primop cmm_args <span class="kw">of</span>
        <span class="dt">Nothing</span> <span class="ot">-&gt;</span> <span class="kw">do</span>  <span class="co">-- out-of-line</span>
          <span class="kw">let</span> fun <span class="fu">=</span> <span class="dt">CmmLit</span> (<span class="dt">CmmLabel</span> (mkRtsPrimOpLabel primop))
          emitCall (<span class="dt">NativeNodeCall</span>, <span class="dt">NativeReturn</span>) fun cmm_args
        <span class="fu">...</span></code></pre></div>
<p>The primop is implemented in Cmm, in <code>rts/PrimOps.cmm</code>. The code is a mess, but here’s the important part:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">stg_atomicModifyMutVarzh ( gcptr mv, gcptr f )
{
  ...
  retry:
    x = StgMutVar_var(mv);
    StgThunk_payload(z,<span class="dv">1</span>) = x;
<span class="pp">#ifdef THREADED_RTS</span>
    (h) = ccall cas(mv + SIZEOF_StgHeader + OFFSET_StgMutVar_var, x, y);
    <span class="cf">if</span> (h != x) { <span class="cf">goto</span> retry; }
<span class="pp">#else</span>
    StgMutVar_var(mv) = y;
<span class="pp">#endif</span>

    <span class="cf">if</span> (GET_INFO(mv) == stg_MUT_VAR_CLEAN_info) {
        ccall dirty_MUT_VAR(BaseReg <span class="st">&quot;ptr&quot;</span>, mv <span class="st">&quot;ptr&quot;</span>);
    }

    <span class="cf">return</span> (r);
}</code></pre></div>
<p>It’s basically a compare-and-swap loop, and in the end it marks the <code>MutVar#</code> as “dirty”, using the same <code>dirty_MUT_VAR</code> function used by the code generated for <code>writeMutVar#</code>.</p>
<h1 id="the-mutvar-struct">The <code>MutVar#</code> struct</h1>
<p>As the last thing, we look at the definition of <code>MutVar#</code>: (in <code>includes/rts/storage/Closures.h</code>)</p>
<pre><code>typedef struct {
    StgHeader   header;
    StgClosure *var;
} StgMutVar;</code></pre>
<p>Nothing interesting here. See <a href="https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects?redirectedfrom=Commentary/Rts/HeapObjects">this Wiki page</a> for GHC’s heap object layout. In our case, payload contains a single closure.</p>
<hr />
<p>This concludes our <code>MutVar#</code> (which is used under the hood for <code>IORef</code> and <code>STRef</code>) tour. I guess lessons here are:</p>
<ol style="list-style-type: decimal">
<li><p><code>readIORef</code> is fast, but <code>writeIORef</code> is one function call in the best case. In the worst case, it does an expensive allocation (this is not just a heap pointer bump). If you have a tight loop with some state variables, prefer parameter passing instead.</p></li>
<li><p>Unpacking an <code>IORef</code> in a data constructor field does not really make the constructor mutable. Instead, it inlines the <code>MutVar#</code>, which has a mutable pointer field.</p></li>
</ol>
<p>If you think about it a little bit, you may realize that optimizing (2) is actually quite tricky. Imagine having something like this:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">D</span> <span class="fu">=</span> <span class="dt">D</span> {<span class="ot"> f1 ::</span> <span class="ot">{-# UNPACK #-}</span> <span class="fu">!</span>(<span class="dt">IORef</span> <span class="dt">Int</span>)
           ,<span class="ot"> f2 ::</span> <span class="dt">Int</span>
           }

<span class="ot">bumpf1 ::</span> <span class="dt">D</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
bumpf1 (<span class="dt">D</span> f1 _) <span class="fu">=</span> modifyIORef f1 (<span class="fu">+</span> <span class="dv">1</span>)

<span class="ot">bumpf2 ::</span> <span class="dt">D</span> <span class="ot">-&gt;</span> <span class="dt">D</span>
bumpf2 (<span class="dt">D</span> f1 f2) <span class="fu">=</span> <span class="dt">D</span> f1 (f2 <span class="fu">+</span> <span class="dv">1</span>)</code></pre></div>
<p>You’d expect this to print <code>True</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">do</span> ref <span class="ot">&lt;-</span> newIORef <span class="dv">0</span>
   <span class="kw">let</span> d1 <span class="fu">=</span> <span class="dt">D</span> ref <span class="dv">0</span>
       d2 <span class="fu">=</span> bumpD2 d1
   bumpf1 d1
   rv1 <span class="ot">&lt;-</span> readIORef (f1 d1)
   rv2 <span class="ot">&lt;-</span> readIORef (f1 d2)
   print (rv1 <span class="fu">==</span> rv2)</code></pre></div>
<p>If <code>D</code> becomes mutable after the <code>UNPACK</code>, this code doesn’t work anymore, because we lose sharing after the functional update in line <code>bumpD2 d1</code>.</p>
<p>See also <a href="https://ghc.haskell.org/trac/ghc/ticket/7662#comment:3">this discussion</a> for how other compilers improve this.</p>]]></summary>
</entry>
<entry>
    <title>Unboxed sums FAQ</title>
    <link href="http://osa1.net/posts/2016-07-22-unboxed-sums-faq.html" />
    <id>http://osa1.net/posts/2016-07-22-unboxed-sums-faq.html</id>
    <published>2016-07-22T00:00:00Z</published>
    <updated>2016-07-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>The unboxed sums patch that implements unlifted, unboxed sum types (as described in <a href="https://ghc.haskell.org/trac/ghc/wiki/UnpackedSumTypes">this Wiki page</a>) was merged yesterday, and a <a href="https://www.reddit.com/r/haskell/comments/4txuo7/unboxed_sum_types_with_unpack_support_will_be_in/">/r/haskell discussion</a> emerged shortly after. As the implementor, I tried to answer questions there, but to keep answers more organized I wanted to write a blog post about it.</p>
<p>The reason I’m not writing this to the Wiki page is because this is about current plans and status of the feature. The wiki page may be updated in the future as the feature evolves and/or may be edited by others. This page reflects the current status as of today, future plans, and my own ideas.</p>
<hr />
<h2 id="syntax-is-awful-why">Syntax is awful, why?</h2>
<p>This feature is designed to complement the similar feature for product types (tuples), called <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#unboxed-tuples">“unboxed tuples”</a>. The syntax is thus chosen to reflect this idea. Instead of commas in the unboxed tuple syntax, we used bars (similar to how bars used in sum type declarations). The syntax looks bad for several reasons:</p>
<ul>
<li><p>Type argument of an alternative have to be a single type. If we want multiple types in an alternative, we have to use an unboxed tuple. For example, unboxed sum version of the type <code>data T = T1 Int | T2 String Bool</code> is <code>(# Int | (# String, Bool #) #)</code>. That’s a lot of parens and hashes.</p></li>
<li><p>Similarly, for nullary alternatives (alternatives/constructors with no arguments) we have to use empty unboxed tuples. So a bool-like type looks like <code>(# (# #) | (# #) #)</code>.</p></li>
<li><p>Data constructors use the same syntax, except we have to put spaces between bars. For example, if you have a type with 10 alternatives, you do something like <code>(# | | | | value | | | | | #)</code>. Space between bars is optional in the type syntax, but not optional in the term syntax. The reason is because otherwise we’d have to steal some existing syntax. For example, <code>(# ||| a #)</code> can be parsed as singleton unboxed tuple of <code>Control.Arrow.|||</code> applied to an argument, or an unboxed sum with 4 alternatives.</p></li>
</ul>
<p>Note that the original Wiki page for unboxed sums included a “design questions” section that discussed some alterantive syntax (see <a href="https://ghc.haskell.org/trac/ghc/wiki/UnpackedSumTypes?version=32">this version</a>). Nobody made any progress to flesh out the ideas, and I updated the Wiki page to reflect the implementation. So it was known that the syntax is not good, but it just wasn’t a major concern.</p>
<p>Answer to the second question is also an answer to this question.</p>
<h2 id="how-is-this-supposed-to-be-used-by-users">How is this supposed to be used by users?</h2>
<p>We’re not expecting users to use this type extensively. It’ll mostly be used by the compiler, for optimizations. In fact, we could have skipped the front-end syntax entirely, and it’d be OK for the most part. If you haven’t used unboxed tuples before, you probably won’t be using unboxed sums.</p>
<p>The only place you may want to use this syntax is when you’re writing a high-performance library or program, and you have a sum type that’s used strictly and can take advantage of removing a level of indirection.</p>
<h2 id="how-is-this-used-by-the-compiler">How is this used by the compiler?</h2>
<p>A detailed answer would take too long, but here’s a summary:</p>
<ul>
<li><p><a href="research.microsoft.com/en-us/um/people/simonpj/Papers/cpr/cpr.ps.gz">Constructed product analysis</a> can now be used for returning sums efficiently. Note that this feature was left as “future work” in the paper (which is from 2004. See section 3.2). The high-level idea is that if a function returns a value that <em>it constructs</em>, then instead of boxing the components of the value and returning a boxed object, it can just return the components instead. In the case where the function result is directly scrutinized (i.e. case expressions), this usually reduces allocations. In other cases, it moves the allocation from the callee to the call site, which in turn leads to stack allocation is some cases (when the object doesn’t escape from the scope).</p>
<p>For product types, unboxed tuples are used for returning the value without heap allocation. For sum types, we use unboxed sums.</p></li>
<li><p>Result of strictness (or “demand”) analysis can now be used to pass sums efficiently. As a result worker/wrapper transformations can now be done for functions that take sum arguments. See <a href="https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/Demand">this Wiki page for demand analysis</a> and <a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/usage-types/cardinality-popl14.pdf">this 2014 paper</a>.</p></li>
<li><p><code>{-# UNPACK #-}</code> pragmas now work on sum types, using unboxed sums under the hood.</p></li>
</ul>
<p>Note that none of these need a concrete syntax for unboxed sums.</p>
<hr />
<p>Hopefully this clarifies some questions and concerns, especially about the syntax. We have plenty of time until the first RC for 8.2 (<a href="https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-8.2.1">mid-February 2017</a>), so it’s certainly possible to improve the syntax, and I’ll be working on that part once I’m done with the optimizations.</p>]]></summary>
</entry>
<entry>
    <title>On matching bang patterns</title>
    <link href="http://osa1.net/posts/2016-06-27-matching-bang-pattern.html" />
    <id>http://osa1.net/posts/2016-06-27-matching-bang-pattern.html</id>
    <published>2016-06-27T00:00:00Z</published>
    <updated>2016-06-27T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I thought a bang pattern is all about <code>seq</code>. That may actually be true, but when that <code>seq</code> is happening may not be obvious. Even after ~5 years of Haskell I was initially very confused by this, and in fact at first I thought it was a bug:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">T</span> <span class="fu">=</span> <span class="dt">A</span> <span class="fu">|</span> <span class="dt">B</span> <span class="fu">|</span> <span class="dt">C</span>

<span class="ot">fn5 ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> [<span class="dt">T</span>] <span class="ot">-&gt;</span> <span class="dt">Int</span>
fn5  i []       <span class="fu">=</span> i
fn5  i (<span class="dt">A</span> <span class="fu">:</span> ts) <span class="fu">=</span> fn5 (i <span class="fu">+</span> <span class="dv">1</span>) ts
fn5 <span class="fu">!</span>i (<span class="dt">B</span> <span class="fu">:</span> ts) <span class="fu">=</span> fn5 (i <span class="fu">+</span> <span class="dv">2</span>) ts
fn5  i (<span class="dt">C</span> <span class="fu">:</span> ts) <span class="fu">=</span> fn5 <span class="dv">0</span> ts</code></pre></div>
<p>The question is, given these definitions, what does this evaluate to, and why:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">fn5 undefined [<span class="dt">C</span>]</code></pre></div>
<p>This question is basically a <code>BangPatterns</code> question. The key point is that a bang pattern <em>first evaluates the value</em> to match, then looks at the pattern. This is from GHC 8.0.1 user manual, <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#bang-patterns-informal">section 9.28.1</a>:</p>
<blockquote>
<p>Matching an expression e against a pattern !p is done by first evaluating e (to WHNF) and then matching the result against p.</p>
</blockquote>
<p>My initial thought was that this example would not crash because the pattern <code>i</code> always matches, and since second argument is only matched by last case of this definition, which doesn’t evaluate <code>i</code>, <code>i</code> would not get evaluated.</p>
<p>Or in other words, I thought all this bang pattern does is to add a <code>seq</code>, <em>to the RHS</em>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">fn5 i (<span class="dt">B</span> <span class="fu">:</span> ts) <span class="fu">=</span> i <span class="ot">`seq`</span> fn5 (i <span class="fu">+</span> <span class="dv">2</span>) ts</code></pre></div>
<p>which is not what it really does!</p>
<hr />
<p>Before bang patterns, I think this pattern was considered as the standard way of forcing a function argument (mostly used for accumulator arguments):</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">f acc _ <span class="fu">|</span> acc <span class="ot">`seq`</span> <span class="dt">False</span> <span class="fu">=</span> undefined
f acc arg <span class="fu">=</span> <span class="fu">...</span></code></pre></div>
<p>The guard in first equation always fails, but it forces the <code>acc</code> by the time it fails. While this looks bad<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, it compiles to nice code after a case-of-case transformation, and it evaluates <code>acc</code> as first thing to do whenever it’s applied to two arguments.</p>
<p>Now, with <code>BangPatterns</code>, we get to do this:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">f <span class="fu">!</span>acc arg <span class="fu">=</span> <span class="fu">...</span></code></pre></div>
<p>Which is good when we have one equation only, but when we have multiple equations like in <code>fn5</code> above, we need add bang patterns to every equation, or we risk having bugs<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>.</p>
<p>So in short, we don’t have a good solution for saying a function is strict on some arguments, without risking bugs (by trying to add minimum number of bangs) or adding a lot of them.</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I don’t like seeing <code>undefined</code>s like this, because I reserve them for code that’s not yet implemented but needs to be implemented. Using <code>undefined</code> as a proxy is also not OK these days, as we have <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#visible-type-application">visible type applications in GHC 8.0.1</a> and <a href="http://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Proxy.html"><code>Proxy</code> in base</a> since <code>base-4.7</code>.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>I don’t mean semantic bugs, rather, unexpected memory usage etc. caused by not forcing thunks on time.<a href="#fnref2">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>How I solved the Synacor Challenge</title>
    <link href="http://osa1.net/posts/2016-06-19-solving-synacor-challenge.html" />
    <id>http://osa1.net/posts/2016-06-19-solving-synacor-challenge.html</id>
    <published>2016-06-19T00:00:00Z</published>
    <updated>2016-06-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>It took 4 attempts at various coffee shops in Cambridge/UK (where I’m spending this summer – more on this later) but I finally solved the <a href="https://challenge.synacor.com/">Synacor Challenge</a>. Here’s how I did it.</p>
<p>WARNING: This post spoils everything! Do not read further if you’re interested in solving it yourself. It’s a lot of fun, so I highly recommend that.</p>
<h1 id="first-attempt">First attempt</h1>
<p>Initial VM implementation took about an hour. It worked well until I was eaten by a grue. At that point I realized that I need a save/load system.</p>
<p>The game looks like a classic text-based adventure where you interact by typing commands. So I thought saving the commands should be enough for “save game”. To load, VM would just load the input from the save file to its input buffer (which is used when <code>in</code> instruction is executed). Indeed it works nicely.</p>
<p>The game is very easy until you make it to the “office”. IIRC, you collect 6 out of 8 codes until that point. At the office you learn about the teleporter, which is the first real challenge in the game…</p>
<h1 id="second-attempt">Second attempt</h1>
<p>At this point I implemented about 20 debugger commands, for things like stepping, breaking at an instruction, breaking at an address, breaking on a specific register read, setting the instruction pointer etc. Just by using these commands I was able to teleport to the right place. However, the code I found there did not really work. It turns out the code is generated dynamically, based on the value in R8. Which is kind of expected, otherwise we could find all the codes just by looking at strings in the binary.</p>
<p>So at this point I realize I need a disassembler…</p>
<h1 id="third-attempt">Third attempt</h1>
<p>The disassembler was trivial to implement. I implement it as a part of VM because 1) in theory the program can generate code in runtime (although I don’t think this is the case in practice) 2) code and data is in the same address space and instruction boundaries are not clearly known. I guess I could do something like: Start with address 0, at each jump disassemble the jump target etc. but I’m not sure if that works as some jump targets are generated dynamically.</p>
<p>Anyway, the debugger has a disassembler now, and I start disassembling functions.</p>
<p>When I step instruction by instruction after using the teleporter, I see that it’s checking R8, if it’s not 0, then calling a function which is the “confimation process” that’s supposed to take 1 billion years. The function has very complex control flow so I try to avoid actually debugging it.</p>
<p>I look at the code that this function returns to. It’s checking if R1 (which has the return value) is 6. So I think, why not just set R1 6 and return from the function? Indeed, it works, but not really how I expected. I already knew that the code I’m searching is generated dynamically, but it’s actually generated using R8, and only when R1 is 6. So as it turns out, I need to guess a value of R8 that makes the validation function return 6. Just making the function return 6 doesn’t really work.</p>
<p>However, I said “it kinda worked”. Because the teleporter actually teleports me to the right place. It’s just that the generated code is not valid.</p>
<h1 id="fourth-attempt">Fourth attempt</h1>
<p>Before disassembling the verification function, I decide to solve the rest of the challenge. I realize that we’re now in a maze, 4x4. Each tile in the maze has either a number, or an operation (<code>+</code>, <code>-</code>, <code>*</code>). There’s an orb in the south-west corner, and there’s a door in the north-east corner. “30” is written on the door, and “22” is printed on the Orb. It’s easy to see what’s going on. Two things to realize are that every time we return to the first tile things get reset, and the goal tile can be visited only once (the orb disappears on visit).</p>
<p>I implement a program that does breadth-first search on this state space, see <code>maze.rs</code>. It then prints directions. When we follow those directions we find the final code and the challenge is completed.</p>
<p>However, since I by-passed the previous challenge, I need to solve that now.</p>
<p>This is the most fun part, it involves lots of debugging, and some programming. Here’s the disassembly of the verification function:</p>
<pre><code>                                         -- fn(reg0 = 4, reg1 = 1, reg7 = our value) {
[6027] Jt [Reg(0), Num(6035)]            --   if reg0 == 0 {
[6030] Add [Reg(0), Reg(1), Num(1)]      --     reg0 = reg1 + 1;
[6034] Ret []                            --     return; }
[6035] Jt [Reg(1), Num(6048)]            --   if reg1 == 0 {
[6038] Add [Reg(0), Reg(0), Num(32767)]  --     reg0 -= 1;
[6042] Set [Reg(1), Reg(7)]              --     reg1 = reg7;
[6045] Call [Num(6027)] ------ loop      --     fn();
[6047] Ret []                            --     return; }
[6048] Push [Reg(0)]                     --   push(reg0);
[6050] Add [Reg(1), Reg(1), Num(32767)]  --   reg1 -= 1;
[6054] Call [Num(6027)] ------ loop      --   fn();
[6056] Set [Reg(1), Reg(0)]              --   reg1 = reg0;
[6059] Pop [Reg(0)]                      --   reg0 = pop();
[6061] Add [Reg(0), Reg(0), Num(32767)]  --   reg0 -= 1;
[6065] Call [Num(6027)] ------ loop      --   fn();
[6067] Ret [] -- end of function at 6027 --   return;
                                         -- }</code></pre>
<p>I added next to each instruction how they would look like in a C-like language. It’s hard to understand what’s going on. So to experiment with it I implement it in Rust. Since registers are shared in each call, I use shared state in my initial implementation:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="at">#[</span>inline<span class="at">]</span>
<span class="kw">fn</span> add(i1 : <span class="dt">u16</span>, i2 : <span class="dt">u16</span>) -&gt; <span class="dt">u16</span> {
    (i1 + i2) % <span class="dv">32768</span>
}

<span class="at">#[</span>derive<span class="at">(</span><span class="bu">Debug</span><span class="at">)]</span>
<span class="kw">struct</span> FnState {
    reg0  : <span class="dt">u16</span>,
    reg1  : <span class="dt">u16</span>,
    reg7  : <span class="dt">u16</span>,
    stack : <span class="dt">Vec</span>&lt;<span class="dt">u16</span>&gt;,
}

<span class="kw">impl</span> FnState {
    <span class="kw">fn</span> init(reg0 : <span class="dt">u16</span>, reg1 : <span class="dt">u16</span>, reg7 : <span class="dt">u16</span>) -&gt; FnState {
        FnState {
            reg0: reg0,
            reg1: reg1,
            reg7: reg7,
            stack: <span class="dt">Vec</span>::new(),
        }
    }

    <span class="kw">fn</span> f(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
        <span class="kw">if</span> <span class="kw">self</span>.reg0 == <span class="dv">0</span> {
            <span class="kw">self</span>.reg0 = add(<span class="kw">self</span>.reg1, <span class="dv">1</span>);
            <span class="kw">return</span>;
        }
        <span class="kw">if</span> <span class="kw">self</span>.reg1 == <span class="dv">0</span> {
            <span class="co">// self.reg0 = add(self.reg0, 32767);</span>
            <span class="kw">self</span>.reg0 -= <span class="dv">1</span>;
            <span class="kw">self</span>.reg1 = <span class="kw">self</span>.reg7;
            <span class="kw">self</span>.f();
            <span class="kw">return</span>;
        }
        <span class="kw">self</span>.stack.push(<span class="kw">self</span>.reg0);
        <span class="co">// self.reg1 = add(self.reg1, 32767);</span>
        <span class="kw">self</span>.reg1 -= <span class="dv">1</span>;
        <span class="kw">self</span>.f();
        <span class="kw">self</span>.reg1 = <span class="kw">self</span>.reg0;
        <span class="kw">self</span>.reg0 = <span class="kw">self</span>.stack.pop().unwrap();
        <span class="co">// self.reg0 = add(self.reg0, 32767);</span>
        <span class="kw">self</span>.reg0 -= <span class="dv">1</span>;
        <span class="kw">self</span>.f();
        <span class="kw">return</span>;
    }
}</code></pre></div>
<p>Now, this function grows really fast. Even for very small inputs it takes minutes to compute. I try to think some well-known functions that grow very fast. Ackermann comes to my mind and I check the Wiki page. Indeed, this looks quite similar, but the third argument makes it different than Ackermann. In any case, it doesn’t really matter for the solution.</p>
<p>So the problem is coming up with a <code>reg7</code> in this code so that <code>f(4, 1, reg7)</code> returns <code>6</code>. For that I need to implement a search but this is basically impossible with this slow function. I start simplifying the function a little bit. My first attempt:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span> FnState {
    <span class="kw">fn</span> f(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
        <span class="co">// When reg0 hits zero, restart it from reg1 + 1</span>
        <span class="kw">if</span> <span class="kw">self</span>.reg0 == <span class="dv">0</span> {
            <span class="kw">self</span>.reg0 = add(<span class="kw">self</span>.reg1, <span class="dv">1</span>);
            <span class="kw">return</span>;
        }

        <span class="co">// When reg1 hits zero, decrement reg0, restart reg1 from reg7</span>
        <span class="kw">if</span> <span class="kw">self</span>.reg1 == <span class="dv">0</span> {
            <span class="kw">self</span>.reg0 -= <span class="dv">1</span>;
            <span class="kw">self</span>.reg1 = <span class="kw">self</span>.reg7;
            <span class="kw">self</span>.f();
            <span class="kw">return</span>;
        }

        <span class="kw">let</span> save_reg0 = <span class="kw">self</span>.reg0;

        <span class="kw">self</span>.reg1 -= <span class="dv">1</span>;
        <span class="kw">self</span>.f();
        <span class="kw">self</span>.reg1 = <span class="kw">self</span>.reg0;

        <span class="kw">self</span>.reg0 = save_reg0;
        <span class="kw">self</span>.reg0 -= <span class="dv">1</span>;

        <span class="kw">self</span>.f();
        <span class="kw">return</span>;
    }
}</code></pre></div>
<p>This version doesn’t use an explicit stack, instead uses a temporary in the call frame. This works because in the original version each push corresponds to a pop done in the same call frame.</p>
<p>It’s still too complicated. I keep simplifying.</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> f(<span class="kw">mut</span> reg0 : <span class="dt">u16</span>, <span class="kw">mut</span> reg1 : <span class="dt">u16</span>, <span class="kw">mut</span> reg7 : <span class="dt">u16</span>) -&gt; (<span class="dt">u16</span>, <span class="dt">u16</span>) {
    <span class="kw">if</span> reg0 == <span class="dv">0</span> {
        reg0 = add(reg1, <span class="dv">1</span>);
        <span class="kw">return</span> (reg0, reg1);
    }

    <span class="kw">if</span> reg1 == <span class="dv">0</span> {
        reg0 -= <span class="dv">1</span>;
        reg1 = reg7;
        <span class="kw">return</span> f(reg0, reg1, reg7);
    }

    <span class="kw">let</span> save_reg0 = reg0;
    reg1 -= <span class="dv">1</span>;

    <span class="kw">let</span> (reg0_, reg1_) = f(reg0, reg1, reg7);
    reg0 = reg0_;
    reg1 = reg1_;

    reg1 = reg0;

    reg0 = save_reg0;
    reg0 -= <span class="dv">1</span>;

    <span class="kw">return</span> f(reg0, reg1, reg7);
}</code></pre></div>
<p>This version doesn’t have any shared mutable state. At this point I realize that it may be possible to remove internal mutable state too:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> f(reg0 : <span class="dt">u16</span>, reg1 : <span class="dt">u16</span>, reg7 : <span class="dt">u16</span>) -&gt; (<span class="dt">u16</span>, <span class="dt">u16</span>) {
    <span class="kw">if</span> reg0 == <span class="dv">0</span> {
        <span class="kw">return</span> (add(reg1, <span class="dv">1</span>), reg1);
    }

    <span class="kw">if</span> reg1 == <span class="dv">0</span> {
        <span class="kw">return</span> f(reg0 - <span class="dv">1</span>, reg7, reg7);
    }

    <span class="kw">let</span> (reg1, _) = f(reg0, reg1 - <span class="dv">1</span>, reg7);

    <span class="kw">return</span> f(reg0 - <span class="dv">1</span>, reg1, reg7);
}</code></pre></div>
<p>Now, this is a function I can read and understand. One advantage of this version is that this could be easily memoized:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> f_memo(reg0 : <span class="dt">u16</span>, reg1 : <span class="dt">u16</span>, reg7 : <span class="dt">u16</span>, memo : &amp;<span class="kw">mut</span> HashMap&lt;(<span class="dt">u16</span>, <span class="dt">u16</span>), (<span class="dt">u16</span>, <span class="dt">u16</span>)&gt;) -&gt; (<span class="dt">u16</span>, <span class="dt">u16</span>) {
    <span class="kw">if</span> <span class="kw">let</span> <span class="cn">Some</span>(ret) = memo.get(&amp;(reg0, reg1)) {
        <span class="kw">return</span> *ret;
    }

    <span class="kw">if</span> reg0 == <span class="dv">0</span> {
        <span class="kw">let</span> ret = (add(reg1, <span class="dv">1</span>), reg1);
        memo.insert((reg0, reg1), ret);
        <span class="kw">return</span> ret;
    }

    <span class="kw">if</span> reg1 == <span class="dv">0</span> {
        <span class="kw">let</span> ret = f_memo(reg0 - <span class="dv">1</span>, reg7, reg7, memo);
        memo.insert((reg0, reg1), ret);
        <span class="kw">return</span> ret;
    }

    <span class="co">// careful there</span>
    <span class="kw">let</span> (reg1_new, _) = f_memo(reg0, reg1 - <span class="dv">1</span>, reg7, memo);

    <span class="kw">let</span> ret = f_memo(reg0 - <span class="dv">1</span>, reg1_new, reg7, memo);
    memo.insert((reg0, reg1), ret);
    <span class="kw">return</span> ret;
}</code></pre></div>
<p>This version is super fast when compared to the original version. I feel like I can just search the whole space in a few hours. I start the search and as it searches through the search space I start wondering about how to further improve it. I think, why not split search space into pieces and search in parallel?</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> search(start_range : <span class="dt">u16</span>, end_range : <span class="dt">u16</span>) -&gt; <span class="dt">Option</span>&lt;<span class="dt">u16</span>&gt; {
    <span class="kw">for</span> i <span class="kw">in</span> start_range .. end_range {
        <span class="co">// println!(&quot;i = {}&quot;, i);</span>
        <span class="kw">let</span> <span class="kw">mut</span> tbl = HashMap::new();
        <span class="kw">let</span> ret = f_memo(<span class="dv">4</span>, <span class="dv">1</span>, i, &amp;<span class="kw">mut</span> tbl);
        <span class="kw">if</span> ret.<span class="dv">0</span> == <span class="dv">6</span> {
            <span class="pp">println!</span>(<span class="st">&quot;Found an answer: {:?} {}&quot;</span>, ret, i);
            <span class="kw">return</span> <span class="cn">Some</span>(i);
        }
    }

    <span class="cn">None</span>
}

<span class="kw">fn</span> search_in_parallel(n : <span class="dt">i32</span>) {
    <span class="kw">let</span> increment = <span class="dt">u16</span>::MAX / (n <span class="kw">as</span> <span class="dt">u16</span>);
    <span class="kw">let</span> <span class="kw">mut</span> threads = <span class="dt">Vec</span>::with_capacity(n <span class="kw">as</span> <span class="dt">usize</span>);

    <span class="kw">for</span> i <span class="kw">in</span> <span class="dv">0</span> .. n {
        <span class="kw">let</span> range_start = increment * (i <span class="kw">as</span> <span class="dt">u16</span>);
        <span class="kw">let</span> range_end   = increment * ((i <span class="kw">as</span> <span class="dt">u16</span>) + <span class="dv">1</span>) + <span class="dv">1</span>;
        threads.push(thread::Builder::new().stack_size(<span class="dv">1000000000</span>).spawn(<span class="kw">move</span> || {
            search(range_start, range_end)
        }).unwrap());
    }

    <span class="kw">for</span> thread <span class="kw">in</span> threads {
        thread.join();
    }
}

<span class="kw">fn</span> main() {
    search_in_parallel(<span class="dv">8</span>);
}</code></pre></div>
<p>This parallel search takes a couple of seconds until it prints:</p>
<pre><code>Found an answer: (6, 5) 25734</code></pre>
<p>So <code>25734</code> returns 6! This is the R8 value we were looking for.</p>
<p>I modify my VM to return when this function is called (I know it lives in address <code>6027</code> so I just check instruction pointer in the main loop) and drop to debugger prompt. In the debugger, I set R1 (return value register) 6, and set R8 25734, and continue running the program.</p>
<p>It works perfectly, with a working code printed to the screen!</p>
<h1 id="code-and-conclusion">Code and conclusion</h1>
<p>Overall I enjoyed this a lot. My favorite part was definitely debugging the verification function. I don’t really enjoy text adventures but that’s really a very small part of the challenge, so it wasn’t a big deal.</p>
<p><a href="https://github.com/osa1/synacor-challenge">My code is on Github</a>. I didn’t organize the code at all, so you can see my inline notes, logs, and commented out code with their improved/changed versions, and have a feeling of how I developed my solutions. In the repo you’ll also see the original binary and challenge spec. I pushed those in case the original challenge page disappears in the future.</p>
<p>The Rust compiler I used was <code>rustc 1.11.0-nightly (0554abac6 2016-06-10)</code>.</p>
<p>If you know similar challenges let me know in the comment section below. One challenge that looks similar is ICFP’06 programming contest <a href="http://www.boundvariable.org/">“The Cult of the Bound Variable”</a>, which I always wanted to solve but never really got a chance. Maybe I should try it next.</p>]]></summary>
</entry>
<entry>
    <title>Rust borrow checker woes</title>
    <link href="http://osa1.net/posts/2016-03-28-rust-brwchk-woes.html" />
    <id>http://osa1.net/posts/2016-03-28-rust-brwchk-woes.html</id>
    <published>2016-03-28T00:00:00Z</published>
    <updated>2016-03-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I’ve been doing some Rust hacking in my free time, and unfortunately while it’s way, way better than how it was when I first tried it (around 0.4 or 0.6 IIRC), it still has some problems that encourage redundant runtime operations or bad programming practices. In this post I’ll give three examples that are all caused by dumb borrow checker. As you’ll see, in all cases the cost is either bad programming practices or runtime costs (which is really ironic, given that one of the design goals of Rust is performance).</p>
<h1 id="no-local-reasoning-about-borrowing-rules-of-constructors">1. No local reasoning about borrowing rules of constructors</h1>
<p>It’s types that borrow, not values, and that makes sense. If you have an <code>Option&lt;&amp;'a T&gt;</code> where <code>'a</code> is coming from some other variable <code>x</code>, 1) <code>x</code> needs to live longer than this <code>Option</code> value 2) you can’t borrow <code>x</code> mutably while keeping the <code>Option</code> in scope (or the other way around, you can’t borrow <code>Option</code> mutably while keeping <code>x</code> in scope).</p>
<p>This makes sense because in compile time, given an <code>Option&lt;&amp;'a T&gt;</code>, you can’t make any assumptions on <code>Option</code>’s actual value. Since <code>Some</code> constructor of the <code>Option</code> type will borrow the <code>T</code> here, you just have to assume that values of this type always borrow <code>T</code> (and that’s why we have <code>&amp;'a</code> in the type).</p>
<p>The problem is that it’s sometimes possible to do some local reasoning, and not doing that is too restrictive. Suppose you have this:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> ListOfThings {
    list : <span class="dt">Vec</span>&lt;Thing&gt;,
}

<span class="kw">struct</span> Thing {
    name : <span class="dt">String</span>,
    <span class="co">// other fields here -- this is expensive to copy!</span>
}

<span class="kw">impl</span> Thing {
    <span class="kw">fn</span> do_something(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {}
}

<span class="kw">impl</span> ListOfThings {
    <span class="kw">fn</span> do_something(&amp;<span class="kw">mut</span> <span class="kw">self</span>, name : &amp;<span class="dt">str</span>) {
        <span class="kw">match</span> <span class="kw">self</span>.find_thing_mut(name) {
            <span class="cn">None</span> =&gt; {
                <span class="kw">self</span>.init_thing(name.to_owned());
                <span class="kw">self</span>.do_something(name)
            },
            <span class="cn">Some</span>(t) =&gt; {
                t.do_something()
            },
        }
    }

    <span class="kw">fn</span> find_thing_mut&lt;<span class="ot">&#39;a</span>&gt;(&amp;<span class="ot">&#39;a</span> <span class="kw">mut</span> <span class="kw">self</span>, name : &amp;<span class="dt">str</span>) -&gt; <span class="dt">Option</span>&lt;&amp;<span class="ot">&#39;a</span> <span class="kw">mut</span> Thing&gt; {
        <span class="kw">self</span>.list.iter_mut().find(|t| t.name.as_str() == name)
    }

    <span class="kw">fn</span> init_thing(&amp;<span class="kw">mut</span> <span class="kw">self</span>, name : <span class="dt">String</span>) {
        <span class="kw">self</span>.list.push(Thing { name: name })
    }
}</code></pre></div>
<p>The important part is this expression:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">match</span> <span class="kw">self</span>.find_thing_mut(name) {
    <span class="cn">None</span> =&gt; {
        <span class="kw">self</span>.init_thing(name.to_owned());
        <span class="kw">self</span>.do_something(name)
    },
    <span class="cn">Some</span>(t) =&gt; {
        t.do_something()
    },
}</code></pre></div>
<p>The error we get is:</p>
<pre><code>&lt;anon&gt;:18:17: 18:21 error: cannot borrow `*self` as mutable more than once at a time [E0499]
&lt;anon&gt;:18                 self.init_thing(name.to_owned());
                          ^~~~
&lt;anon&gt;:18:17: 18:21 help: see the detailed explanation for E0499
&lt;anon&gt;:16:15: 16:19 note: previous borrow of `*self` occurs here; the mutable
                          borrow prevents subsequent moves, borrows, or
                          modification of `*self` until the borrow ends
&lt;anon&gt;:16         match self.find_thing_mut(name) {
                        ^~~~
&lt;anon&gt;:24:10: 24:10 note: previous borrow ends here
&lt;anon&gt;:16         match self.find_thing_mut(name) {
...
&lt;anon&gt;:24         }
                  ^
&lt;anon&gt;:19:17: 19:21 error: cannot borrow `*self` as mutable more than once at a time [E0499]
&lt;anon&gt;:19                 self.do_something(name)
                          ^~~~
&lt;anon&gt;:19:17: 19:21 help: see the detailed explanation for E0499
&lt;anon&gt;:16:15: 16:19 note: previous borrow of `*self` occurs here; the mutable
                          borrow prevents subsequent moves, borrows, or
                          modification of `*self` until the borrow ends
&lt;anon&gt;:16         match self.find_thing_mut(name) {
                        ^~~~
&lt;anon&gt;:24:10: 24:10 note: previous borrow ends here
&lt;anon&gt;:16         match self.find_thing_mut(name) {
...
&lt;anon&gt;:24         }
                  ^</code></pre>
<p><code>find_thing_mut()</code> really needs to return a ref, because <code>Thing</code> is expensive to copy. The problem is since <code>None</code> has type <code>Option&lt;&amp;'a mut Thing&gt;</code> where <code>a</code> is the lifetime of <code>self</code>, we can’t call a <code>&amp;mut self</code> when that <code>None</code> is in scope. This is annoying and could be improved by doing some local reasoning. In our case, since we know that <code>None</code> can’t borrow anything (it doesn’t have any references), we could refine our information about currently borrwed values, and let this compile.</p>
<p>There are a couple of solutions. One half-solution is to use something like standard <a href="http://doc.rust-lang.org/nightly/std/collections/struct.HashMap.html#method.entry"><code>HashMap</code>’s <code>entry()</code></a>. Imagine doing something like:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::collections::hash_map::HashMap;

<span class="kw">struct</span> ListOfThings {
    list : HashMap&lt;<span class="dt">String</span>, Thing&gt;,
}

<span class="kw">struct</span> Thing {
    field1 : <span class="dt">i32</span>,
    <span class="co">// other fields here -- this is expensive to copy!</span>
}

<span class="kw">impl</span> Thing {
    <span class="kw">fn</span> do_something(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {}
}

<span class="kw">impl</span> ListOfThings {
    <span class="kw">fn</span> do_something(&amp;<span class="kw">mut</span> <span class="kw">self</span>, name : &amp;<span class="dt">str</span>) {
        <span class="kw">match</span> <span class="kw">self</span>.list.get_mut(name) {
            <span class="cn">None</span> =&gt; {
                <span class="kw">self</span>.list.insert(name.to_owned(), Thing { field1: <span class="dv">123</span> });
            },
            <span class="cn">Some</span>(t) =&gt; {
                t.do_something();
            }
        }
    }
}</code></pre></div>
<p>The error we get:</p>
<pre><code>&lt;anon&gt;:20:17: 20:26 error: cannot borrow `self.list` as mutable more than once at a time [E0499]
&lt;anon&gt;:20                 self.list.insert(name.to_owned(), Thing { field1: 123 });
                          ^~~~~~~~~
&lt;anon&gt;:20:17: 20:26 help: see the detailed explanation for E0499
&lt;anon&gt;:18:15: 18:24 note: previous borrow of `self.list` occurs here; the
                          mutable borrow prevents subsequent moves, borrows, or
                          modification of `self.list` until the borrow ends
&lt;anon&gt;:18         match self.list.get_mut(name) {
                        ^~~~~~~~~
&lt;anon&gt;:25:10: 25:10 note: previous borrow ends here
&lt;anon&gt;:18         match self.list.get_mut(name) {
...
&lt;anon&gt;:25         }
                  ^</code></pre>
<p>This is exactly the same error we got before. The solution is to use <a href="http://doc.rust-lang.org/nightly/std/collections/struct.HashMap.html#method.entry">the <code>Entry</code> API</a>:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::collections::hash_map::{HashMap, Entry};

<span class="kw">struct</span> ListOfThings {
    list : HashMap&lt;<span class="dt">String</span>, Thing&gt;,
}

<span class="kw">struct</span> Thing {
    field1 : <span class="dt">i32</span>,
    <span class="co">// other fields here -- this is expensive to copy!</span>
}

<span class="kw">impl</span> Thing {
    <span class="kw">fn</span> do_something(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {}
}

<span class="kw">impl</span> ListOfThings {
    <span class="kw">fn</span> do_something(&amp;<span class="kw">mut</span> <span class="kw">self</span>, name : &amp;<span class="dt">str</span>) {
        <span class="kw">match</span> <span class="kw">self</span>.list.entry(name.to_owned()) {
            Entry::Vacant(ve) =&gt; {
                ve.insert(Thing { field1: <span class="dv">123</span> });
            },
            Entry::Occupied(<span class="kw">mut</span> oe) =&gt; {
                oe.get_mut().do_something();
            }
        }
    }
}</code></pre></div>
<p>Some things to note here:</p>
<ol style="list-style-type: decimal">
<li><p>We had to give ownership of the key to the lookup function (<code>HashMap::entry()</code>). This potentially means copying a value just to lookup. Ideally we’d only need to do this when inserting to the map. <code>HashMap::get()</code> doesn’t have this problem.</p></li>
<li><p>I said “half-solution” because this doesn’t really make the original code working. See how I removed a line in the first case in my <code>HashMap</code>-based implementation. If I change the first case to this:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust">        <span class="kw">match</span> <span class="kw">self</span>.list.entry(name.to_owned()) {
            Entry::Vacant(ve) =&gt; {
                ve.insert(Thing { field1: <span class="dv">123</span> });
                <span class="kw">self</span>.do_something(name)
            },</code></pre></div>
<p>It’d still fail as <code>Entry</code> keeps a reference to <code>self</code>. Of course you could always do things like:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust">        <span class="kw">match</span> <span class="kw">self</span>.list.entry(name.to_owned()) {
            Entry::Vacant(ve) =&gt; {
                <span class="kw">let</span> <span class="kw">mut</span> thing = Thing { field1 : <span class="dv">123</span> };
                thing.do_something();
                ve.insert(thing);
            },</code></pre></div>
<p>Which works, but that’s quite different from our original program. Note that if we still had a method like <code>init_thing()</code> and has to pass <code>Entry</code> to that, it’d still fail with same error message. So yeah, not quite a solution.</p></li>
</ol>
<p>The solution I use is this:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span> ListOfThings {
    <span class="kw">fn</span> do_something(&amp;<span class="kw">mut</span> <span class="kw">self</span>, name : &amp;<span class="dt">str</span>) {
        <span class="kw">let</span> thing : <span class="dt">Option</span>&lt;*<span class="kw">mut</span> Thing&gt; = <span class="kw">self</span>.find_thing_mut(name).map(|t| (t <span class="kw">as</span> *<span class="kw">mut</span> _));
        <span class="kw">match</span> thing {
            <span class="cn">None</span> =&gt; {
                <span class="kw">self</span>.init_thing(name.to_owned());
                <span class="kw">self</span>.do_something(name)
            },
            <span class="cn">Some</span>(t) =&gt; {
                <span class="kw">unsafe</span> { (*t).do_something() }
            },
        }
    }
}</code></pre></div>
<p>(missing parts are the same as the original code),</p>
<p>I basically work around the borrow checker by using a raw pointer and an <code>unsafe</code> block, and hope that my <code>.map()</code> will be compiled as a no-op.</p>
<h1 id="references-to-self-in-method-values">2. References to self in method values</h1>
<p>A code like this fails if the method is mutable in self: <code>self.f(self.x)</code>. As a running example:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Widget {
    pos_x : <span class="dt">i32</span>,
    pos_y : <span class="dt">i32</span>,
}

<span class="kw">impl</span> Widget {
    <span class="kw">pub</span> <span class="kw">fn</span> draw(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
        <span class="kw">self</span>.draw_at(<span class="kw">self</span>.pos_x, <span class="kw">self</span>.pos_y);
    }

    <span class="kw">pub</span> <span class="kw">fn</span> draw_at(&amp;<span class="kw">mut</span> <span class="kw">self</span>, pos_x : <span class="dt">i32</span>, pos_y : <span class="dt">i32</span>) {}
}</code></pre></div>
<p>These are the errors:</p>
<pre><code>&lt;anon&gt;:8:22: 8:32 error: cannot use `self.pos_x` because it was mutably borrowed [E0503]
&lt;anon&gt;:8         self.draw_at(self.pos_x, self.pos_y);
                              ^~~~~~~~~~
&lt;anon&gt;:8:9: 8:13 note: borrow of `*self` occurs here
&lt;anon&gt;:8         self.draw_at(self.pos_x, self.pos_y);
                 ^~~~
&lt;anon&gt;:8:34: 8:44 error: cannot use `self.pos_y` because it was mutably borrowed [E0503]
&lt;anon&gt;:8         self.draw_at(self.pos_x, self.pos_y);
                                          ^~~~~~~~~~
&lt;anon&gt;:8:9: 8:13 note: borrow of `*self` occurs here
&lt;anon&gt;:8         self.draw_at(self.pos_x, self.pos_y);
                 ^~~~</code></pre>
<p>Basically the method itself (<code>self.draw_at</code>) borrows <code>self</code> mutably, and since arguments are evaluated <em>after</em> the function in a function application, we get this borrow checker error. The solution is simple in this case:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> pos_x = <span class="kw">self</span>.pos_x;
<span class="kw">let</span> pos_y = <span class="kw">self</span>.pos_y;
<span class="kw">self</span>.draw_at(pos_x, pos_y);</code></pre></div>
<h1 id="variables-that-live-across-loops">3. Variables that live across loops</h1>
<p>Suppose you have a loop that internally calls some <code>&amp;mut self</code> methods, and when it returns, it returns something with a reference to <code>&amp;self</code>. Something like:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">pub</span> <span class="kw">struct</span> TUI {
    field1: <span class="dt">i32</span>,
}

<span class="kw">pub</span> <span class="kw">enum</span> TUIRet&lt;<span class="ot">&#39;a</span>&gt; {
    Abort,
    KeyHandled,
    Input(&amp;<span class="ot">&#39;a</span> <span class="dt">str</span>),
}

<span class="kw">impl</span> TUI {
    <span class="kw">pub</span> <span class="kw">fn</span> idle_loop&lt;<span class="ot">&#39;a</span>&gt;(&amp;<span class="ot">&#39;a</span> <span class="kw">mut</span> <span class="kw">self</span>) -&gt; TUIRet&lt;<span class="ot">&#39;a</span>&gt; {
        <span class="kw">loop</span> {
            <span class="kw">self</span>.draw();

            <span class="kw">match</span> <span class="kw">self</span>.keypressed() {
                ret @ TUIRet::Abort =&gt; { <span class="kw">return</span> ret; },
                ret @ TUIRet::Input(_) =&gt; { <span class="kw">return</span> ret; },
                _ =&gt; {},
            }
        }
    }

    <span class="kw">pub</span> <span class="kw">fn</span> keypressed(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; TUIRet {
        <span class="pp">panic!</span>()
    }

    <span class="kw">pub</span> <span class="kw">fn</span> draw(&amp;<span class="kw">self</span>) {}
}</code></pre></div>
<p>Can you see what could go wrong here? Here’s the error:</p>
<pre><code>&lt;anon&gt;:18:13: 18:17 error: cannot borrow `*self` as immutable because it is also borrowed as mutable [E0502]
&lt;anon&gt;:18             self.draw();
                      ^~~~
&lt;anon&gt;:20:19: 20:23 note: previous borrow of `*self` occurs here; the mutable
                          borrow prevents subsequent moves, borrows, or
                          modification of `*self` until the borrow ends
&lt;anon&gt;:20             match self.keypressed() {
                            ^~~~
&lt;anon&gt;:26:6: 26:6 note: previous borrow ends here
&lt;anon&gt;:16     pub fn idle_loop&lt;&#39;a&gt;(&amp;&#39;a mut self) -&gt; TUIRet&lt;&#39;a&gt; {
...
&lt;anon&gt;:26     }
              ^
&lt;anon&gt;:20:19: 20:23 error: cannot borrow `*self` as mutable more than once at a time [E0499]
&lt;anon&gt;:20             match self.keypressed() {
                            ^~~~
&lt;anon&gt;:20:19: 20:23 help: see the detailed explanation for E0499
&lt;anon&gt;:20:19: 20:23 note: previous borrow of `*self` occurs here; the mutable
                          borrow prevents subsequent moves, borrows, or
                          modification of `*self` until the borrow ends
&lt;anon&gt;:20             match self.keypressed() {
                            ^~~~
&lt;anon&gt;:26:6: 26:6 note: previous borrow ends here
&lt;anon&gt;:16     pub fn idle_loop&lt;&#39;a&gt;(&amp;&#39;a mut self) -&gt; TUIRet&lt;&#39;a&gt; {
...
&lt;anon&gt;:26     }
              ^</code></pre>
<p>This is probably the worst of all. The weird part is that this works:</p>
<div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust">    <span class="kw">pub</span> <span class="kw">fn</span> idle_loop&lt;<span class="ot">&#39;a</span>&gt;(&amp;<span class="ot">&#39;a</span> <span class="kw">mut</span> <span class="kw">self</span>) -&gt; TUIRet&lt;<span class="ot">&#39;a</span>&gt; {
        <span class="kw">loop</span> {
            <span class="kw">self</span>.draw();
            <span class="kw">return</span> <span class="kw">self</span>.keypressed();
        }
    }</code></pre></div>
<p>Only solution I could find here was to remove the references to <code>self</code>, by just copying the value to <code>Input</code>. This unfortunately means more redundant copying.</p>]]></summary>
</entry>

</feed>
