<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>osa1.net - Posts tagged en</title>
    <link href="http://osa1.net/tags/en.xml" rel="self" />
    <link href="http://osa1.net" />
    <id>http://osa1.net/tags/en.xml</id>
    <author>
        <name>Ömer Sinan Ağacan</name>
        <email>omeragaca@gmail.com</email>
    </author>
    <updated>2018-03-16T00:00:00Z</updated>
    <entry>
    <title>Three runtime optimizations done by GHC's GC</title>
    <link href="http://osa1.net/posts/2018-03-16-gc-optimizations.html" />
    <id>http://osa1.net/posts/2018-03-16-gc-optimizations.html</id>
    <published>2018-03-16T00:00:00Z</published>
    <updated>2018-03-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>While working on GHC’s GC code I realized that it does some runtime optimizations. One of those I already knew from another language, but the other two were quite interesting to me because they’re related with laziness. I wouldn’t think consequences of laziness reach this far into the runtime system. It turns out it does; disabling those optimizations make programs run significantly slower.</p>
<p>Because I almost read the whole code line by line, I believe this list is exhaustive. The code is taken from the source code but significantly simplified.</p>
<p>If you’re not familiar with GHC’s heap object layout and info tables etc., I suggest reading <a href="https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects">the wiki page</a> before moving on the rest of the post.</p>
<h1 id="replacing-small-int-and-char-closures-with-statically-initialized-shared-closures">1. Replacing small Int and Char closures with statically initialized, shared closures</h1>
<p><code>Int</code> and <code>Char</code> closures have one non-pointer field for the actual integer and character values, as can be seen in GHCi:</p>
<pre><code>λ&gt; :info Int
data Int = GHC.Types.I# GHC.Prim.Int#     -- Defined in ‘GHC.Types’
λ&gt; :info Char
data Char = GHC.Types.C# GHC.Prim.Char#   -- Defined in ‘GHC.Types’</code></pre>
<p>The corresponding closure type for closures with one non-pointer and no pointers is <a href="https://github.com/ghc/ghc/blob/cb6d8589c83247ec96d5faa82df3e93f419bbfe0/includes/rts/storage/ClosureTypes.h#L25"><code>CONSTR_0_1</code></a>. The garbage collector <a href="https://github.com/ghc/ghc/blob/cb6d8589c83247ec96d5faa82df3e93f419bbfe0/rts/sm/Evac.c#L656">needs to check closure type before copying an object</a> to decide how many bytes to copy (and also to decide what pointers to follow and copy the pointed object, but this happens in a later stage). When it finds a <code>CONSTR_0_1</code> it checks if it’s actually an <code>Int</code> or <code>Char</code> closure, if it is, it checks if the payload (the actual <code>Int</code> and <code>Char</code> values) is within a range. If it is then we know that we have statically-allocated <code>Int</code> or <code>Char</code> closure what is identical to the one we’re copying, so we return address to the statically allocated one rather than copying the closure and returning the new address of the copied closure. This way we avoid having multiple closures for <code>1 :: Int</code>, for example. The code (simplified, some comments by me):</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="kw">case</span> CONSTR_0_1:
{
    <span class="co">// Constructor with one non-pointer field. Read the field.</span>
    StgWord w = (StgWord)q-&gt;payload[<span class="dv">0</span>];

    <span class="kw">if</span> (<span class="co">// is it a Char?</span>
        info == Czh_con_info &amp;&amp;
        <span class="co">// is the value in range?</span>
        (StgChar)w &lt;= MAX_CHARLIKE)
    {
        <span class="co">// return address to statically allocated Char closure</span>
        *p =  TAG_CLOSURE(tag, (StgClosure *)CHARLIKE_CLOSURE((StgChar)w));
    }
    <span class="kw">else</span> <span class="kw">if</span> (<span class="co">// is it an Int?</span>
             info == Izh_con_info &amp;&amp;
             <span class="co">// is the value in range?</span>
             (StgInt)w &gt;= MIN_INTLIKE &amp;&amp; (StgInt)w &lt;= MAX_INTLIKE)
    {
        <span class="co">// return address to statically allocated Int closure</span>
        *p = TAG_CLOSURE(tag, (StgClosure *)INTLIKE_CLOSURE((StgInt)w));
    }
    <span class="co">// otherwise copy the object</span>
    <span class="kw">else</span>
    {
        copy_tag_nolock(p,info,q,sizeofW(StgHeader)+<span class="dv">1</span>,gen_no,tag);
    }
    <span class="kw">return</span>;
}</code></pre>
<p>What are the ranges here? Looking at the <a href="https://github.com/ghc/ghc/blob/cb6d8589c83247ec96d5faa82df3e93f419bbfe0/rts/StgMiscClosures.cmm#L679-L974">definition</a>, we see that integers in range [-16, 16] and the whole ASCII character set is covered.</p>
<p>Here’s a small program that shows the effect of this optimization:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">module</span> <span class="dt">Main</span> <span class="kw">where</span>

<span class="kw">import </span><span class="dt">GHC.Stats</span>
<span class="kw">import </span><span class="dt">System.Mem</span> (performMajorGC)

<span class="ot">seqIntList ::</span> [<span class="dt">Int</span>] <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> a
seqIntList []       a <span class="fu">=</span> a
seqIntList (i <span class="fu">:</span> is) a <span class="fu">=</span> i <span class="ot">`seq`</span> is <span class="ot">`seqIntList`</span> a

<span class="ot">main ::</span> <span class="dt">IO</span> ()
main <span class="fu">=</span> <span class="kw">do</span>
    <span class="kw">let</span> lst <span class="fu">=</span> [ <span class="dv">0</span> <span class="fu">..</span> <span class="dv">15</span> ]
    <span class="co">-- let lst = [ 17 .. 32 ] -- enable this on the second run</span>

    <span class="co">-- evaluate the list</span>
    lst <span class="ot">`seqIntList`</span> return ()

    <span class="co">-- collect any thunks, do the optimization if possible, update stats</span>
    performMajorGC

    rts_stats <span class="ot">&lt;-</span> getRTSStats
    putStrLn (<span class="st">&quot;Live data: &quot;</span> <span class="fu">++</span> show (gcdetails_live_bytes (gc rts_stats)) <span class="fu">++</span> <span class="st">&quot; bytes&quot;</span>)

    <span class="co">-- to make sure our list won&#39;t be collected</span>
    lst <span class="ot">`seqIntList`</span> return ()</code></pre>
<p>Run it with:</p>
<pre><code>ghc eq.hs -rtsopts -O0 &amp;&amp; ./eq +RTS -T</code></pre>
<p>On the second run, disable the first list and enable the second one. You’ll see this output:</p>
<pre><code>$ ghc eq.hs -rtsopts -O0 &amp;&amp; ./eq +RTS -T
[1 of 1] Compiling Main             ( eq.hs, eq.o )
Linking eq ...
Live data: 2224 bytes

$ ghc eq.hs -rtsopts -O0 &amp;&amp; ./eq +RTS -T
[1 of 1] Compiling Main             ( eq.hs, eq.o )
Linking eq ...
Live data: 2480 bytes</code></pre>
<p>So second program has 256 bytes more live data. Let’s check if that makes sense. The first program doesn’t have any heap-allocated <code>Int</code> closures, because all of the <code>Int</code> in the program are within the range of statically allocated <code>Int</code> closures. Second one has 16 <code>Int</code> closures. An <code>Int</code> closure is two words: a pointer to the <code>I#</code> info table, and an actual integer value in the payload, so that’s 16 bytes. 16 (number of <code>Int</code> closures) * 16 (<code>Int</code> closure size) = 256.</p>
<p>I know at least one another language, Python, does this as well:</p>
<pre><code>Python 3.5.2 (default, Nov 23 2017, 16:37:01)
[GCC 5.4.0 20160609] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; x = 1
&gt;&gt;&gt; y = 1
&gt;&gt;&gt; x is y
True
&gt;&gt;&gt; x = 100000000000
&gt;&gt;&gt; y = 100000000000
&gt;&gt;&gt; x is y
False</code></pre>
<p>Although I’m not sure if it does this during garbage collection.</p>
<h1 id="shorting-out-indirections">2. Shorting out indirections</h1>
<p>This is related with how lazy evaluation is implemented so we’ll first take a look at the generated code for a simple thunk update. When we compile the following program: (to keep things simple we disable optimizations)</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">fib ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>
fib <span class="dv">0</span> <span class="fu">=</span> <span class="dv">0</span>
fib <span class="dv">1</span> <span class="fu">=</span> <span class="dv">1</span>
fib n <span class="fu">=</span> fib (n<span class="fu">-</span><span class="dv">1</span>) <span class="fu">+</span> fib (n<span class="fu">-</span><span class="dv">2</span>)

<span class="ot">main ::</span> <span class="dt">IO</span> ()
main <span class="fu">=</span> <span class="kw">do</span>
    i <span class="ot">&lt;-</span> readLn
    print (fib i)</code></pre>
<p>in STG level we get this function:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">sat_s31Q <span class="fu">=</span>
    \r [i_s31O]
        <span class="kw">let</span> { sat_s31P <span class="fu">=</span> \u [] fib_rqh i_s31O;
        } <span class="kw">in</span>  print <span class="fu">$</span>fShowInt sat_s31P;</code></pre>
<p>Here <code>fib_rqh</code> is the <code>fib</code> function, and <code>sat_s31P</code> is the thunk for <code>fib i</code>. First let’s take a look at how this thunk is evaluated in the use site: (Cmm syntax)</p>
<pre><code>I64[Sp - 16] = stg_upd_frame_info;
P64[Sp - 8] = _s31P::P64;
_s31O::P64 = P64[_s31P::P64 + 16];
R2 = _s31O::P64;
Sp = Sp - 16;
call fib_rqh_info(R2) args: 24, res: 0, upd: 24;</code></pre>
<p>So we push the thunk (<code>_s31P</code>), then <code>stg_upd_frame_info</code> to the stack, and jump to the code for the <code>fib</code> function, passing the argument in <code>R2</code>.</p>
<p>I won’t show the code (because it’s large and complex), but the code for <code>fib</code> puts the return value in <code>R1</code>, pops the stack, and jump to the code for the popped stack frame, which is <code>stg_upd_frame_info</code>.</p>
<p>At this point we have the return value of <code>fib</code> in <code>R1</code>, and thunk to update at the bottom of the stack.</p>
<p>The code for <code>stg_upd_frame_info</code> is as follows: (simplified, see the original version <a href="https://github.com/ghc/ghc/blob/cb6d8589c83247ec96d5faa82df3e93f419bbfe0/rts/Updates.cmm#L28-L38">here</a>)</p>
<pre><code>INFO_TABLE_RET ( stg_upd_frame, // label
                 UPDATE_FRAME,  // frame type
                 w_ info_ptr,   // info ptr
                 p_ updatee )   // thunk to update at the bottom of the stack
    return (P_ ret) // in R1 we expect the value to update the thunk with
{
    StgInd_indirectee(updatee) = ret;       // (1)
    SET_INFO(updatee, stg_BLACKHOLE_info);  // (2)
    ...
    return (ret);
}</code></pre>
<p>This basically replaces the thunk’s (<code>_s31P</code>) info table pointer with <code>stg_BLACKHOLE_info</code> in line (2) (effectively making the thunk an indirection), and writes pointer to the evaluated object to the payload in line (1).</p>
<p>Now any code that uses this value needs to follow the pointer written to what was originally a thunk in line (1). This is done by the <a href="https://github.com/ghc/ghc/blob/cb6d8589c83247ec96d5faa82df3e93f419bbfe0/rts/StgMiscClosures.cmm#L295">entry code of <code>stg_BLACKHOLE_info</code></a>.</p>
<p>Now, because the GC copies objects from one heap to another, and updates any references to these moved objects in thread stacks (and in other roots), we can follow any indirections when copying blackhole objects, and replace references in thread stacks to the blackhole object with a reference to the object pointed to by the blackhole object. <a href="https://github.com/ghc/ghc/blob/cb6d8589c83247ec96d5faa82df3e93f419bbfe0/rts/sm/Evac.c#L732-L755">The code</a>:</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="kw">case</span> BLACKHOLE:
{
    StgClosure *r;
    <span class="dt">const</span> StgInfoTable *i;
    r = ((StgInd*)q)-&gt;indirectee;
    <span class="kw">if</span> (GET_CLOSURE_TAG(r) == <span class="dv">0</span>) {
        i = r-&gt;header.info;
        <span class="kw">if</span> (IS_FORWARDING_PTR(i)) {
            r = (StgClosure *)UN_FORWARDING_PTR(i);
            i = r-&gt;header.info;
        }
        <span class="kw">if</span> (i == &amp;stg_TSO_info
            || i == &amp;stg_WHITEHOLE_info
            || i == &amp;stg_BLOCKING_QUEUE_CLEAN_info
            || i == &amp;stg_BLOCKING_QUEUE_DIRTY_info) {
            copy(p,info,q,sizeofW(StgInd),gen_no);
            <span class="kw">return</span>;
        }
        ASSERT(i != &amp;stg_IND_info);
    }
    q = r;
    *p = r;
    <span class="kw">goto</span> loop;
}</code></pre>
<p>I don’t understand all the details in this code, but I think the important bits are the <code>q-&gt;indirectee</code> line which follows the pointer written in line (1) above, and <code>goto loop</code> which makes the garbage collector copy and return the object pointed by the blackhole.</p>
<p>After this we no longer have to follow a pointer to our evaluated thunk. Instead references to the thunk become references to the evaluated object.</p>
<h1 id="selector-thunk-evaluation">3. Selector thunk evaluation</h1>
<p>A selector thunk is a thunk of this form: (<a href="https://github.com/ghc/ghc/blob/cb6d8589c83247ec96d5faa82df3e93f419bbfe0/compiler/codeGen/StgCmmBind.hs#L267-L297">code</a>)</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">case</span> x <span class="kw">of</span>
  <span class="dt">C</span> x1 <span class="fu">...</span> xn <span class="ot">-&gt;</span> xm</code></pre>
<p>where <code>1 &lt;= m &lt;= n</code>, and <code>x</code> is a variable. The problem with such a thunk is that it keeps all of the fields of <code>x</code> live until the selector thunk is evaluated, even when <code>x</code> is evaluated by some other code. As an example where this happens, suppose we have this record:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">R</span> <span class="fu">=</span> <span class="dt">R</span> { _<span class="ot">i1 ::</span> <span class="dt">Int</span>, _<span class="ot">i2 ::</span> <span class="dt">Int</span>, <span class="fu">...</span> other fields <span class="fu">...</span> }</code></pre>
<p>then in a function we take <code>R</code> as parameter, and use the fields:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">f ::</span> <span class="dt">R</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>
f r <span class="fu">=</span> _i1 r <span class="fu">+</span> _i2 r</code></pre>
<p>Here <code>_i1 r</code> and <code>_i2 r</code> are selector thunks. Now suppose that the parameter to this function was already evaluated before the function is called. In this case the thunk that holds the this function application will keep all of <code>r</code> live even though only <code>_i1</code> and <code>_i2</code> are needed.</p>
<p>It turns out this problem was known since around 1985. To my knowledge, Wadler was the first one to suggest solving these kind of “leaks” in the garbage collector <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. The idea is that while the GC copies these thunks it checks if the “selectee” is already evaluated. If so the GC evaluates the selector thunk during copying, and copies the evaluated form. Because selectors thunks are so simple (the exact shape of a selector thunk is well specified and it can’t do anything other than accessing a field) evaluation of these are just a matter of indexing the selectee’s payload. The function that does this is <a href="https://github.com/ghc/ghc/blob/cb6d8589c83247ec96d5faa82df3e93f419bbfe0/rts/sm/Evac.c#L1002">here</a>. The whole story is complicated because of concurrency concerns (e.g. another GC thread can also evaluate the thunk at the same time), but the actual optimization starts around line 1104 by looking at info table at the selectee. If it’s a constructor, then we access to the field and return it. Otherwise it’s a thunk and we copy it as usual.</p>
<h1 id="conclusion">Conclusion</h1>
<p>In each cycle a copying garbage collector copies live data in a heap to another heap and abandons the old heap. It turns out this kind of garbage collection is really convenient for implementing optimizations described above. The code that traverses all live data, copies it, and updates the roots is already there. Doing updates on objects while copying is just a matter of adding a few more lines in the copying function.</p>
<p>In a non-copying collector this is much trickier, because the collector doesn’t actually need to update roots or the data. For example, to implement optimizations (2) in a mark-sweep collector we have to somehow keep track of the location where we found the pointer to the object we’re currently marking. Then, if the object became an indirection, we have to update the source location and should not mark the indirection object, because some other object may have a reference to it, and we have to update that reference too. In short, it’s certainly possible, but much trickier. Mark phase gets more complicated.</p>
<p>In summary,</p>
<ul>
<li><p>Generational copying collectors are known to be a good fit for functional languages. It turns out if your language is also lazy they’re even better fit.</p></li>
<li><p>Laziness have far-reaching consequences. The optimizations (2) and (3) are really essential to get good performance out of lazy programs (try commenting out those lines in the GC!), and they require support from the GC.</p></li>
</ul>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>“Fixing some space leaks with a garbage collector”, Wadler, 1987.<a href="#fnref1">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>Fuzzy module loading in GHCi</title>
    <link href="http://osa1.net/posts/2017-10-26-ghc-fuzzy-module-loading.html" />
    <id>http://osa1.net/posts/2017-10-26-ghc-fuzzy-module-loading.html</id>
    <published>2017-10-26T00:00:00Z</published>
    <updated>2017-10-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p><a href="https://downloads.haskell.org/~ghc/8.2.1/docs/html/users_guide/ghci.html#ghci-cmd-:def">A GHCi macro</a> is just a function of type <code>String -&gt; IO String</code>. The argument is parameter of the macro, and return value is evaluated by GHCi as a command.</p>
<p>Using this and the <a href="http://hackage.haskell.org/package/process"><code>process</code></a> library we can implement a fuzzy module loader that works inside ghci:</p>
<div class="figure">
<img src="/images/fuzzy_ghci_load.gif" />

</div>
<p>(sorry for the gif quality)</p>
<p>Here I’m using <a href="https://github.com/junegunn/fzf">fzf</a> as the fuzzy file finder. Code for defining the macro:</p>
<pre><code>import System.IO (withFile, IOMode (WriteMode))
import System.Process (runProcess, waitForProcess)

:{
let loadFuzzy _ = do
      let f = &quot;/tmp/fzf_out&quot;
      withFile f WriteMode $ \h -&gt; do
        p &lt;- runProcess &quot;fzf&quot; [] Nothing Nothing Nothing (Just h) Nothing
        _ &lt;- waitForProcess p
        out &lt;- readFile f
        return (&quot;:load &quot; ++ init out)
:}

:def l loadFuzzy</code></pre>
<p>Add this code to your global ghci config file (<code>~/.ghci</code>) or your project-wide <code>.ghci</code> (at the project root).</p>
<p>Only problem here is the <code>process</code> dependency: when you use <code>stack repl</code> or <code>cabal repl</code>, <code>process</code> won’t be importable in GHCi unless the project you’re loading into GHCi already has it as a dependency. One solution is to pass <code>-package process</code> to <code>cabal repl</code> or <code>--ghci-options=&quot;-package process&quot;</code> to <code>stack repl</code>. Because <code>process</code> is distributed with GHC this will always work.</p>]]></summary>
</entry>
<entry>
    <title>A parallel scheduler in 50 lines of Haskell</title>
    <link href="http://osa1.net/posts/2017-10-16-a-parallel-scheduler.html" />
    <id>http://osa1.net/posts/2017-10-16-a-parallel-scheduler.html</id>
    <published>2017-10-16T00:00:00Z</published>
    <updated>2017-10-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Here’s a problem:</p>
<ul>
<li>You have N resources.</li>
<li>You have M tasks.</li>
<li>Each task requires exclusive access to a subset of the resources.</li>
<li>Tasks can be run in parallel.</li>
</ul>
<p>Implement a scheduler that runs these tasks in parallel, utilizing available resources as much as possible.</p>
<p>The code I’ll show here piggybacks on GHC RTS for scheduling. But for that we first have to implement our resources and tasks in a way that exposes necessary information to GHC’s scheduler. The idea is simple and fun to implement, but I can’t recommended using it in production :-) Scheduling is a hard problem, with many variations, and I’ve only recently started reading about it. This solution is a fun one than anything else.</p>
<hr />
<p>The idea is simple; we implement resources as <code>MVar</code>s and tasks as threads. Threads (tasks) take the <code>MVar</code>s before performing the operation. Because threads are scheduled by GHC RTS, GHC handles scheduling of our tasks. Because of fairness properties of <code>MVar</code>s, our threads are scheduled “fairly”, e.g. all tasks eventually finish even when we have infinitely many tasks.</p>
<p>A resource is an abstract object with a lock and unique identifier:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Resource</span> <span class="fu">=</span> <span class="dt">Resource</span>
  { _<span class="ot">resourceName ::</span> <span class="dt">T.Text</span>
  , _<span class="ot">resourceId   ::</span> <span class="dt">Unique</span>
  , _<span class="ot">resourceLock ::</span> <span class="dt">MVar</span> ()
  }

<span class="kw">instance</span> <span class="dt">Show</span> <span class="dt">Resource</span> <span class="kw">where</span>
  show <span class="fu">=</span> T.unpack <span class="fu">.</span> _resourceName</code></pre>
<p><code>_resourceName</code> is just a string to be used for tracing program execution.</p>
<p>A <code>Unique</code> is an integer that can be used in at most one resource:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">Unique</span> <span class="fu">=</span> <span class="dt">Unique</span> <span class="dt">Int</span>
  <span class="kw">deriving</span> (<span class="dt">Eq</span>, <span class="dt">Ord</span>)</code></pre>
<p>Using <code>Unique</code> we can define a total order for <code>Resource</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Eq</span> <span class="dt">Resource</span> <span class="kw">where</span>
  (<span class="fu">==</span>) <span class="fu">=</span> (<span class="fu">==</span>) <span class="ot">`on`</span> _resourceId

<span class="kw">instance</span> <span class="dt">Ord</span> <span class="dt">Resource</span> <span class="kw">where</span>
  compare <span class="fu">=</span> comparing _resourceId</code></pre>
<p>A task that requires exclusive access to a subset of all resources can be implemented using <code>withResources</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">withResources ::</span> (<span class="dt">MonadLogger</span> m, <span class="dt">MonadBaseControl</span> <span class="dt">IO</span> m) <span class="ot">=&gt;</span> <span class="dt">S.Set</span> <span class="dt">Resource</span> <span class="ot">-&gt;</span> m () <span class="ot">-&gt;</span> m ()
withResources locks a <span class="fu">=</span> acquire_locks (S.toList locks)
  <span class="kw">where</span>
    acquire_locks ls <span class="fu">=</span> <span class="kw">case</span> ls <span class="kw">of</span>
      [] <span class="ot">-&gt;</span>
        a
      l <span class="fu">:</span> ls&#39; <span class="ot">-&gt;</span> <span class="kw">do</span>
        logDebug (<span class="st">&quot;taking lock &quot;</span> <span class="fu">&lt;&gt;</span> (_resourceName l))
        withMVar (_resourceLock l) <span class="fu">$</span> \() <span class="ot">-&gt;</span>
          acquire_locks ls&#39;</code></pre>
<p>Note that when all tasks are implemented using this function a deadlock won’t occur: resources are ordered, and <code>S.toList</code> generates a sorted list, which in turn causes <code>acquire_locks</code> to take locks in order, effectively implementing <a href="https://en.wikipedia.org/wiki/Dining_philosophers_problem">Dijkstra’s resource hierarchy solution to the dining philosophers problem</a>.</p>
<p>Here are three task generators:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">Task</span> <span class="fu">=</span> <span class="dt">Task</span>
  {<span class="ot"> runTask ::</span> forall m <span class="fu">.</span> (<span class="dt">MonadLogger</span> m, <span class="dt">MonadBaseControl</span> <span class="dt">IO</span> m) <span class="ot">=&gt;</span> m () }

<span class="ot">mkFastTask ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">S.Set</span> <span class="dt">Resource</span> <span class="ot">-&gt;</span> <span class="dt">Task</span>
mkFastTask i res <span class="fu">=</span>
    <span class="dt">Task</span> <span class="fu">$</span> withResources res <span class="fu">$</span> <span class="kw">do</span>
      logDebug (<span class="st">&quot;Performing &quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i))
      threadDelay (<span class="dv">500</span><span class="ot"> ::</span> <span class="dt">Milliseconds</span>)
      logDebug (<span class="st">&quot;Fast task done (&quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i) <span class="fu">&lt;&gt;</span> <span class="st">&quot;)&quot;</span>)

<span class="ot">mkSlowTask ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">S.Set</span> <span class="dt">Resource</span> <span class="ot">-&gt;</span> <span class="dt">Task</span>
mkSlowTask i res <span class="fu">=</span>
    <span class="dt">Task</span> <span class="fu">$</span> withResources res <span class="fu">$</span> <span class="kw">do</span>
      logDebug (<span class="st">&quot;Performing &quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i))
      threadDelay (<span class="dv">3</span><span class="ot"> ::</span> <span class="dt">Seconds</span>)
      logDebug (<span class="st">&quot;Slow task done (&quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i) <span class="fu">&lt;&gt;</span> <span class="st">&quot;)&quot;</span>)

<span class="ot">mkCrashingTask ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">S.Set</span> <span class="dt">Resource</span> <span class="ot">-&gt;</span> <span class="dt">Task</span>
mkCrashingTask i res <span class="fu">=</span>
    <span class="dt">Task</span> <span class="fu">$</span> withResources res <span class="fu">$</span> <span class="kw">do</span>
      logDebug (<span class="st">&quot;Performing &quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i))
      error <span class="st">&quot;task failed&quot;</span></code></pre>
<p>Integer arguments are just for tracing task execution in program output. <code>mkFastTask</code> generates a task that takes 500 milliseconds to run. <code>mkSlowTask</code> generates a task that takes 3 seconds. <code>mkCrashingTask</code> makes a task that throws an exception, demonstrating that we release resources properly on exceptions.</p>
<p>Finally, the scheduler just spawns tasks using <code>forkIO</code> or <code>async</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">schedule ::</span> (<span class="dt">MonadLogger</span> m, <span class="dt">MonadBaseControl</span> <span class="dt">IO</span> m, <span class="dt">Forall</span> (<span class="dt">Pure</span> m)) <span class="ot">=&gt;</span> [<span class="dt">Task</span>] <span class="ot">-&gt;</span> m ()
schedule tasks <span class="fu">=</span> <span class="kw">do</span>
    thrs <span class="ot">&lt;-</span> forM tasks <span class="fu">$</span> \(<span class="dt">Task</span> task) <span class="ot">-&gt;</span>
              async (task <span class="ot">`catch`</span> (\(<span class="ot">e ::</span> <span class="dt">SomeException</span>) <span class="ot">-&gt;</span> logDebug <span class="st">&quot;Task failed&quot;</span>))
    forM_ thrs wait</code></pre>
<p>Here’s an example run</p>
<pre><code>taking lock resource5
Performing 0
taking lock resource0
Performing 1
taking lock resource2
taking lock resource6
taking lock resource7
Performing 2
Task failed
taking lock resource6
Performing 3
taking lock resource8
Performing 4
taking lock resource1
taking lock resource2
Performing 5
Task failed
taking lock resource2
taking lock resource3
taking lock resource8
taking lock resource0
taking lock resource3
taking lock resource4
Performing 9
Fast task done (3)
Fast task done (9)
Fast task done (0)
Slow task done (1)
taking lock resource4
taking lock resource8
Slow task done (4)
Performing 6
Fast task done (6)
taking lock resource7
Performing 8
Task failed
Performing 7
Slow task done (7)</code></pre>
<p>The whole code that randomly generates resources and tasks and then runs them is <a href="https://gist.github.com/osa1/e7416f6a0f299f88f275bb8d56a31da3">here</a>. It uses quite a lot of dependencies because it was extracted from a larger program, and I’m too lazy to make it smaller and simpler. I provided a <code>stack.yaml</code> so hopefully it’s still not too hard to run.</p>]]></summary>
</entry>
<entry>
    <title>More Rust woes</title>
    <link href="http://osa1.net/posts/2017-10-08-more-rust-woes.html" />
    <id>http://osa1.net/posts/2017-10-08-more-rust-woes.html</id>
    <published>2017-10-08T00:00:00Z</published>
    <updated>2017-10-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In the third part of the series (<a href="http://osa1.net/posts/2016-03-28-rust-brwchk-woes.html">1</a>, <a href="http://osa1.net/posts/2016-09-11-more-rust-problems.html">2</a>) we’re going to look at two curious cases, first one related with “drop checker” and the second one with “borrow checker”.</p>
<p>(examples below are tested with <code>rustc 1.22.0-nightly (05f8ddc46 2017-10-07)</code>)</p>
<h1 id="redundant-semicolon-fixes-borrow-or-drop-checker">1. Redundant semicolon fixes borrow (or drop) checker</h1>
<p>It turns out if you’re getting a weird borrow checker error about something not living long enough to be dropped you can sometimes fix it by adding more semicolons.</p>
<p>The error message itself is weird because intuitively you’d think that for something to be dropped it should first become dead, but the error message says something like “<code>x</code> dropped here while still borrowed”. Because the variable is not dropped explicitly by the user, this error message is actually complaining about compiler’s behavior not being consistent in itself.</p>
<p>Here’s an example:</p>
<pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::sync::Arc;
<span class="kw">use</span> std::sync::Mutex;

<span class="kw">fn</span> main() {
    <span class="kw">let</span> s: Arc&lt;Mutex&lt;<span class="kw">i32</span>&gt;&gt; = Arc::new(Mutex::new(<span class="dv">0</span>));
    <span class="kw">match</span> s.lock().unwrap() {
        _ =&gt; {}
    }
}</code></pre>
<p>This fails to compile with:</p>
<pre><code>error[E0597]: `s` does not live long enough
 --&gt; src/main.rs:9:1
  |
6 |     match s.lock().unwrap() {
  |           - borrow occurs here
...
9 | }
  | ^ `s` dropped here while still borrowed
  |
  = note: values in a scope are dropped in the opposite order they are created</code></pre>
<p>Solution? Add more semicolons! In this example, just put a semicolon after the match expression and it compiles fine.</p>
<p>Here’s <a href="https://github.com/rust-lang/rust/issues/21114#issuecomment-312447832">one more example</a>. It turns out questions about this error message are regularly asked on the IRC channel.</p>
<p><a href="https://github.com/rust-lang/rust/issues/21114">#21114</a> reported this issue on Jan 14, 2015, but no progress has been made towards a solution so far. It’s not clear if non-lexical lifetimes will help solving this.</p>
<h1 id="match-expression-keeps-values-alive-longer-than-necessary">2. <code>match</code> expression keeps values alive longer than necessary</h1>
<p>This problem is kind of special. All other problems mentioned in this series were about borrow checker being too strict. This one is different: it causes runtime bugs.</p>
<p><code>match</code> expression keeps the value to be examined (sometimes called <code>scrutinee</code> in Haskell land) alive longer than necessary. Because alive values are not dropped, if you rely on dynamic borrow checks in the scrutinee and in the branches, your checks fail. Here’s an example:</p>
<pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::sync::Arc;
<span class="kw">use</span> std::sync::Mutex;

<span class="kw">struct</span> S(<span class="kw">i32</span>);

<span class="kw">impl</span> S {
    <span class="kw">pub</span> <span class="kw">fn</span> get_int(&amp;<span class="kw">self</span>) -&gt; <span class="kw">i32</span> {
        <span class="kw">self</span>.<span class="dv">0</span>
    }

    <span class="kw">pub</span> <span class="kw">fn</span> set_int(&amp;<span class="kw">mut</span> <span class="kw">self</span>, i: <span class="kw">i32</span>) {
        <span class="kw">self</span>.<span class="dv">0</span> = i;
    }
}

<span class="kw">fn</span> main() {
    <span class="kw">let</span> s = Arc::new(Mutex::new(S(<span class="dv">0</span>)));
    <span class="kw">match</span> s.lock().unwrap().get_int() {
        i =&gt; {
            s.lock().unwrap().set_int(i);
        }
    };
}</code></pre>
<p>(notice how I use a redundant semicolon after the match expression, to fix #1)</p>
<p>Even though <code>get_int()</code> returns in <code>i32</code> as a value, not a reference, the <code>MutexGuard</code> returned by <code>Mutex::lock()</code> is kept alive in the branches of this <code>match</code> expression, so the second <code>Mutex::lock()</code> call causes a deadlock. Solution? Use a <code>let</code> expression:</p>
<pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> x = s.lock().unwrap().get_x();
<span class="kw">match</span> x { ... }</code></pre>
<p>This problem makes <code>match &lt;expr&gt; { ... }</code> less useful than <code>let x = &lt;expr&gt;; match x { ... }</code>.</p>
<p><a href="https://github.com/rust-lang/rust/issues/38355">#38355</a> reported this issue on Dec 14, 2016, but no progress towards a solution has been made so far.</p>]]></summary>
</entry>
<entry>
    <title>Enable these two flags in GHC 8.2</title>
    <link href="http://osa1.net/posts/2017-07-15-two-flags.html" />
    <id>http://osa1.net/posts/2017-07-15-two-flags.html</id>
    <published>2017-07-15T00:00:00Z</published>
    <updated>2017-07-15T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>As usual, the next major GHC release will be <a href="https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-8.2.1#Releasehighlights">pretty great</a>. It’ll come with a bunch of new features that I can’t wait to start using, and I’ve contributed to three of the new features<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, but what excites me the most is not any of these features. I’m most excited about the improved <code>-Werror</code> flag.</p>
<p>The summary is that with GHC 8.2 we’ll be able to promote some warnings into errors, without making <em>all warnings</em> errors (which is how <code>-Werror</code> worked pre-8.2). With this we can finally fix some of the Haskell 2010 warts.</p>
<hr />
<p>By the beginning of this year I moved from academia to industry. I was writing Haskell in academia, and I’m still writing Haskell, but the environment, tasks, and constraints are quite different, so the way I write Haskell changed quite a lot during this transition.</p>
<p>What I realized that some of the problems with Haskell 2010 are actually worse than I had previously thought.</p>
<h2 id="problem-1-initializing-records-without-initializing-all-of-its-fields">Problem 1: Initializing records without initializing all of its fields</h2>
<p><a href="https://www.haskell.org/onlinereport/haskell2010/haskellch3.html#x8-520003.15.2">Haskell 2010</a> says that when initializing records using labels, fields not mentioned are initialized as bottoms.</p>
<p>I just can’t fathom how Haskell 2010 people thought this is a good idea. In Haskell we constantly rely on compile-time errors to refactor our code. A common workflow is this: you update your data types, and follow the type errors to adapt your code to the changes. Quite often your program works as expected after this. I did this countless times during my career as a Haskell programmer, and I’m trying to improve GHC to <a href="https://github.com/ghc-proposals/ghc-proposals/pull/43">make this workflow even more efficient</a>.</p>
<p>The problem is this “feature” breaks this workflow, because adding a new field to a type no longer generates a compile error. It generates a warning, but that’s not good enough because (1) not all projects have <code>-Wall</code> enabled (2) not all projects are warning-free, which means new warnings sometimes go unnoticed (this happens in our code base all the time).</p>
<p>Indeed, even very experienced Haskellers release buggy code because of this. For example, warp-3.2.10 added a new field (<code>connFree</code>) to one of its types (<code>Connection</code>), and for some reason only the minor version was bumped (3.2.9 to 3.2.10, which is probably wrong according to <a href="https://pvp.haskell.org/">PVP</a> because the type was exported). The problem was warp-tls-3.2.2 had 3.3 as warp upper bound, so it compiled fine against warp-3.2.10, even though it didn’t initialize the field. This caused bugs in our system, which we thankfully discovered in our test environment rather than on production. The fix was <a href="https://github.com/yesodweb/wai/commit/b63ec0e865cf91af4143416adaf430969ba0ebb5#diff-44ce89cb2a54be5e525d74b83901f561R348">easy</a>, but the damage was done (the buggy warp-tls-3.2.2 is still on Hackage).</p>
<h2 id="problem-2-non-exhaustive-pattern-matching">Problem 2: Non-exhaustive pattern matching</h2>
<p>While I can’t find any mention to exhaustiveness of pattern matching in Haskell 2010, it clearly covers the case where patterns do not cover all values when defining <a href="https://www.haskell.org/onlinereport/haskell2010/haskellch3.html#x8-610003.17.3">formal semantics of pattern matching</a> (see case (b)). You only realize that this is a bad idea when (1) your code is not warning-free so new warnings sometimes go unnoticed and (2) you can’t promote individual warnings to errors. This again breaks the workflow I mentioned above, and makes code reviews much harder.</p>
<hr />
<p>The solution that GHC 8.2 brings is we can now make these two warnings errors, using <code>-Werror=missing-fields -Werror=incomplete-patterns</code>. There’s still one problem though, the error message is not good enough. Suppose we had this code:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">module</span> <span class="dt">Lib</span> <span class="kw">where</span>

<span class="kw">data</span> <span class="dt">Rec</span> <span class="fu">=</span> <span class="dt">Rec</span> {<span class="ot"> f1 ::</span> <span class="dt">Int</span>,<span class="ot"> f2 ::</span> <span class="dt">Int</span> }

<span class="kw">data</span> <span class="dt">S</span> <span class="fu">=</span> <span class="dt">C1</span> <span class="dt">Int</span> <span class="fu">|</span> <span class="dt">C2</span> <span class="dt">Int</span>

<span class="co">-- incomplete pattern</span>
sInt s <span class="fu">=</span> <span class="kw">case</span> s <span class="kw">of</span>
           <span class="dt">C1</span> i <span class="ot">-&gt;</span> i

<span class="co">-- missing field</span>
initRec <span class="fu">=</span> <span class="dt">Rec</span> { f1 <span class="fu">=</span> <span class="dv">1</span> }</code></pre>
<p>Compile this with <code>ghc -Wall</code> and you get:</p>
<pre><code>[1 of 1] Compiling Lib              ( test.hs, test.o )

test.hs:11:1: warning: [-Wmissing-signatures]
    Top-level binding with no type signature: sInt :: S -&gt; Int
   |
11 | sInt s = case s of
   | ^^^^

test.hs:11:10: warning: [-Wincomplete-patterns]
    Pattern match(es) are non-exhaustive
    In a case alternative: Patterns not matched: (C2 _)
   |
11 | sInt s = case s of
   |          ^^^^^^^^^...

test.hs:15:1: warning: [-Wmissing-signatures]
    Top-level binding with no type signature: initRec :: Rec
   |
15 | initRec = Rec { f1 = 1 }
   | ^^^^^^^

test.hs:15:11: warning: [-Wmissing-fields]
    • Fields of ‘Rec’ not initialised: f2
    • In the expression: Rec {f1 = 1}
      In an equation for ‘initRec’: initRec = Rec {f1 = 1}
   |
15 | initRec = Rec { f1 = 1 }
   |           ^^^^^^^^^^^^^^</code></pre>
<p>We only care about missing fields and incomplete patterns, so with GHC 8.2 we compile this with <code>ghc -Wall -Werror=missing-fields -Werror=incomplete-patterns</code>, which generates the same warnings, but the process exits with non-zero, and prints these extra lines:</p>
<pre><code>&lt;no location info&gt;: error:
Failing due to -Werror.</code></pre>
<p>This is not too useful, because if you get dozens of warnings there’s basically no way of knowing which of those warnings caused this error. One alternative is to disable <code>-Wall</code> and only use <code>-Werror</code>s. That way you know that the warnings you’re seeing are actually errors.</p>
<p>Still, this is not entirely satisfactory, because even though we don’t cause our build to fail when we have warnings, they’re still sometimes useful to see (for example, name shadowing warnings often catches accidental loops). So to improve this I recently <a href="https://phabricator.haskell.org/D3709">submitted a patch</a>, which is merged, but unfortunately won’t make it to GHC 8.2 (hopefully we’ll see it in GHC 8.4). With that patch when you have both <code>-Wall</code> and some <code>-Werror</code>s, you see this instead:</p>
<pre><code>[1 of 1] Compiling Lib              ( test.hs, test.o )

test.hs:11:1: warning: [-Wmissing-signatures]
    Top-level binding with no type signature: sInt :: S -&gt; Int
   |
11 | sInt s = case s of
   | ^^^^

test.hs:11:10: error: [-Wincomplete-patterns, -Werror=incomplete-patterns]
    Pattern match(es) are non-exhaustive
    In a case alternative: Patterns not matched: (C2 _)
   |
11 | sInt s = case s of
   |          ^^^^^^^^^...

test.hs:15:1: warning: [-Wmissing-signatures]
    Top-level binding with no type signature: initRec :: Rec
   |
15 | initRec = Rec { f1 = 1 }
   | ^^^^^^^

test.hs:15:11: error: [-Wmissing-fields, -Werror=missing-fields]
    • Fields of ‘Rec’ not initialised: f2
    • In the expression: Rec {f1 = 1}
      In an equation for ‘initRec’: initRec = Rec {f1 = 1}
   |
15 | initRec = Rec { f1 = 1 }
   |           ^^^^^^^^^^^^^^</code></pre>
<p>Much better!</p>
<p>This is probably not as exciting to many people as, say, new features like compact regions or join points, but I think this will significantly improve “refactor types, folow type error, repeat” style workflows and make code reviews much easier.</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I discovered and reported <a href="https://ghc.haskell.org/trac/ghc/ticket/10598">#10598</a> two years ago, which led to <code>-XDerivingStrategies</code> work, I was involved in the <a href="http://ezyang.com/papers/ezyang15-cnf.pdf">Compact regions paper</a>, and I implemented <a href="https://phabricator.haskell.org/D2259">unboxed sums</a> during my time at MSR Cambridge last summer.<a href="#fnref1">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>My new XFCE + i3 setup</title>
    <link href="http://osa1.net/posts/2016-11-30-new-xfce-i3-setup.html" />
    <id>http://osa1.net/posts/2016-11-30-new-xfce-i3-setup.html</id>
    <published>2016-11-30T00:00:00Z</published>
    <updated>2016-11-30T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I’ve been running Linux exclusively since 6-7 years ago, and since my first days on Linux I’ve been obsessed with two things:</p>
<ul>
<li><p>I hate the mouse, and I try really hard to not use it.</p></li>
<li><p>I need a very stable system. If my distro is not stable enough, I try to bring the system to a stable state and then I never update anything. My previous setup had one year uptime and that’s because I never updated anything and it kept running without any problems <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</p></li>
</ul>
<p>Initially I was running GNOME 2, but I had to switch to KDE because the distro I was working on at the time (Pardus) was mainly a KDE distro and as far as I remember it was the only DE that was officially supported<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. It took some time but I ended up liking it quite a lot, and kept using it after I stopped working on Pardus and switched to openSUSE.</p>
<p>My KDE setup was weird. I had dozens of key bindings for window management, and I was using vim and yakuake with lots of customization and key bindings. I basically rolled my own tiling window manager using KDE settings and key bindings.</p>
<p>I tried <a href="http://xmonad.org/">XMonad</a> and <a href="https://awesome.naquadah.org/">awesomewm</a> a couple of times, but I was too lazy to configure them to a stable state where all the services (login/logout, power management, sound and brightness settings, network controllers etc.) work flawlessly.</p>
<p>Then I discovered <a href="https://i3wm.org/">i3</a>. In my first hours with it all I had to change was the <code>jkl;</code> combination for left/down/up/right: I was already an experienced vim user so I changed it to <code>hjkl</code> and that was pretty much it. I had a usable setup already.</p>
<p>The way I run it was again weird. I replaced KDE’s window manager, so all other KDE services were running. This setup had many problems, for example, neither <code>i3bar</code> nor the KDE status bar worked, so I didn’t use a status bar. KDE’s desktop was still running, so I added a status bar widget to the desktop, and I was using a spare i3 desktop when I needed to use the status bar. I had to disable some of the KDE services (like the one that detects connected monitors) because they weren’t working as expected when I replaced the window manager etc. This system worked great for about 2 years once I disabled some of the KDE services that didn’t work properly.</p>
<p>Then, 3 weeks ago, I had some free time, and decided to finally update my system. I was using openSUSE, and I wanted to stick with it, so I installed openSUSE Tumbleweed. This time instead of using a weird KDE + i3 setup I wanted a proper i3 setup. I messed with a plain i3 setup for a while, but it got tiresome real quick, so I looked at other DEs to find one that works with i3.</p>
<p>Long story short, I found out that <a href="https://www.xfce.org/">XFCE</a> and i3 work really great together. It takes 15 minutes to set up my desktop. Here’s how I do it:</p>
<ol style="list-style-type: decimal">
<li><p>Install a distro with a recent XFCE and i3. Install a full XFCE desktop and i3.</p></li>
<li><p><code>xfce4-session-settings</code> &gt; “Session”: Remove everything other than <code>Xfsettingsd</code> and <code>Power Manager</code>.</p></li>
<li><p><code>xfce4-session-settings</code> &gt; “Advanced”: Enable “Launch GNOME services on startup”.</p></li>
<li><p><code>xfce4-session-settings</code> &gt; “Application Autostart”: Add <code>i3</code> executable.</p></li>
</ol>
<p>That’s all you need to get a working XFCE + i3 setup! <code>i3-bar</code> will be used instead of XFCE panel (which you disabled already in step (2)). After this just configure XFCE and i3 as usual.</p>
<p>Here is some of the configurations I do:</p>
<ul>
<li><p>I add <code>/usr/bin/setxkbmap -option &quot;ctrl:nocaps&quot;</code> to <code>xfce4-settings-manager</code> &gt; “Application Autostart” to make caps lock an additional ctrl.</p></li>
<li><p>I install <code>feh</code> and run it on i3 startup to set a desktop background image (see my i3 config below).</p></li>
<li><p>I add some key bindings in <code>xfce4-keyboard-settings</code> for sound controls. Normally I add key bindings to i3 config, but it’s hard to find key names for <code>Fn + key</code> combinations and XFCE helps with that part.</p></li>
<li><p>In <code>xfce4-keyboard-settings</code> I set repeat delay 260ms and repeat speed 55 key strokes/second.</p></li>
</ul>
<p>Then I install zsh, vim etc. and generate symlinks for my <a href="https://github.com/osa1/rcbackup">configs</a>. My i3 config is <a href="https://github.com/osa1/rcbackup/blob/master/.i3/config">here</a>.</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>It probably had some security issues though…<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>There was an unofficial work on a GNOME port but it was never completed as far as I know.<a href="#fnref2">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>Papers I read in 2015-2016</title>
    <link href="http://osa1.net/posts/2016-11-15-2015-2016-papers.html" />
    <id>http://osa1.net/posts/2016-11-15-2015-2016-papers.html</id>
    <published>2016-11-15T00:00:00Z</published>
    <updated>2016-11-15T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>This is my last week at Indiana University. It’ll be almost two years (1 year 11 months) since I came here, and it’s time for me to move on. While cleaning my messy desk covered with papers today I thought maybe I should make list of papers that I read (or at least printed) during this two-year period, so here it is.</p>
<p>Papers are sorted by publication dates. <code>???</code> indicates that the publication date is unknown (or may not be published at all), and those are listed last. I’ve added some very brief notes below some of the papers. Only last names of authors are listed.</p>
<hr />
<ul>
<li><p>On computable numbers, with an application to Entscheidungsproblem – Turing. 1936.</p></li>
<li><p>Computing Machinery and Intelligence – Turing. 1950.</p>
<p>Defines “the imitation game” aka. “Turing test”. Tries to answer some philosophical questions. I remember finding some of the arguments pretty weak.</p></li>
<li><p>Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I – McCarthy. 1960.</p>
<p>A classic. Defines “garbage collection”, “free list” and “stack” for the first time, without actually using those words.</p></li>
<li><p>A basis for a mathematical theory of computation – McCarthy. 1963.</p>
<p>Haven’t read.</p></li>
<li><p>The Next 700 Programming Languages – Landin. 1966.</p>
<p>Classic.</p></li>
<li><p>A Nonrecursive List Compacting Algorithm – Cheney. 1970.</p>
<p>A classic. Only two pages. Algorithm can easily be generalized to collect arbitrary heap objects. Known as “Cheney’s algorithm” in GC literature.</p></li>
<li><p>Monotone Data Flow Analysis Frameworks – Kam, Ullman. 1975.</p></li>
<li><p>Global Data Flow Analysis and Iterative Algorithms – Kam, Ullman. 1976.</p></li>
<li><p>Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints – Cousot, Cousot. 1977.</p>
<p>Cousot &amp; Cousot, so avoid. Read “Principles of Program Analysis” (book) by Nielson, Nielson and Hanking.</p></li>
<li><p>A Real-Time Garbage Collector Based on the Lifetimes of Objects – Lieberman, Hewitt. 1983.</p>
<p>An early generational GC paper. Defines “scavenging” and “evacuation”, some of the terms used in GHC’s GC.</p></li>
<li><p>Generation Scavenging: A Non-disruptive High Performance Storage Reclamation Algorithm – Ungar. 1984.</p></li>
<li><p>Compiling Pattern Matching – Augustsson. 1985.</p>
<p>A very early paper on lazy pattern matching in LML. IIRC the idea is very simple and maybe even obvious, but this is a very early publication on the topic.</p></li>
<li><p>How to Replace Failure by a List of Successes - A method for exception handling, backtracking, and pattern matching in lazy functional languages – Wadler. 1985.</p>
<p>I don’t remember reading this.</p></li>
<li><p>Multilisp: A anguage for Concurrent Symbolic Computation – Halstead. 1985.</p>
<p>Haven’t read this.</p></li>
<li><p>Programming as Theory Building – Naur. 1985.</p>
<p>All I remember about this paper is that I disagreed very strongly with the points made. I see some notes on the paper about why analogies don’t work and are harmful.</p></li>
<li><p>Control Operators, the SECD-Machine, and the λ-Calculus – Felleisen, Friedman. 1986.</p></li>
<li><p>Hygienic Macro Expansion – Kohlbecker, Friedman, Felleisen, Duba. 1986.</p></li>
<li><p>No Silver Bullet - Essence and Accident in Software Engineering – Brooks. 1986.</p></li>
<li><p>ORBIT: An Optimizing Compiler for Scheme. Kranz, Kelsey, Rees, Hudak, Philbin, Adams. 1986.</p></li>
<li><p>The Concept of a Supercompiler – Turchin. 1986.</p>
<p>This is one of the earliest supercompilation papers published in English.</p>
<p>First supercompilation papers were in Russian. First supercompilation paper in English was “A supercompiler system based on the langauge Refal”, Turchin, 1979. I don’t know what happened in the 7 year period, but I think the next paper was this one.</p></li>
<li><p>Efficient Compilation of Pattern-Matching (The Implementation of Functional Programming Languages book chapter) – Wadler. 1987.</p></li>
<li><p>Re-opening Closures – Appel. 1987.</p>
<p>The idea is to optimize closures in runtime using captured variables. I’ve heard that Mu uses some variant of this idea.</p></li>
<li><p>The Concatenate Vanishes – Wadler, 1987.</p>
<p>An even earlier work than the deforestation one. Wadler shows how to “deforest” intermediate lists in some programs. I don’t remember how the idea worked, but it must be just a very simple case-of-case transformation.</p></li>
<li><p>Theorems for free! – Wadler. 1989.</p>
<p>Great paper, shows how parametricity leads to theorems.</p></li>
<li><p>Deforestation: Transforming programs to eliminate trees – Wadler. 1990.</p>
<p>I think this is another classic and coined the term “deforestation”. The paper makes a huge simplifying assumption and assumes that variables are used linearly in function bodies, which makes beta reduction safe in terms of work duplication. So not very useful for practical purposes.</p></li>
<li><p>Linear types can change the world! – Wadler. 1990.</p></li>
<li><p>Implementing Projection-based Strictness Analysis – Kubiak, Hughes, Launchbury. 1992.</p></li>
<li><p>Undecidability of Static Analysis – Landi. 1992.</p>
<p>IIRC this paper shows how interesting static analysis problems are undecidable, by means of reductions from known undecidable problems like the halting problem.</p></li>
<li><p>Unboxed objects and polymorphic typing – Leroy. 1992.</p></li>
<li><p>A Short Cut to Deforestation – Gill, Launchbury, Jones. 1993.</p>
<p>Introduces fold/build rules. Still in use today in GHC.</p></li>
<li><p>Metaobject protocols: Why we want them and what else they can do – Kiczales, Ashley, Rodriguez, Vahdat, Bobrow. 1993.</p></li>
<li><p>Occam’s Razor in Metacomputation: the Notion of a Perfect Process Tree – Glück, Klimov. 1993.</p>
<p>An even earlier paper on “perfect information propagation”. Uses “process trees” which are only used in very early supercompilation papers (including Turchin ones IIRC).</p></li>
<li><p>Syntactic Abstraction in Scheme – Dybvig, Hieb, Bruggeman. 1993.</p>
<p>Go IU!</p></li>
<li><p>What is a Purely Functional Language? – Sabry. 1993.</p></li>
<li><p>Partial Deduction and Driving are Equivalent – Glück, Sørensen. 1994.</p></li>
<li><p>Mix Ten Years Later – Jones. 1995.</p>
<p>I love Neil Jones’s partial evaluation work (and especially the book “Partial Evaluation and Automatic Program Generation” by Jones, Gomard, Sestoft).</p></li>
<li><p>The Design of a Pretty-printing Library – Hughes. 1995.</p></li>
<li><p>A Roadmap to Metacomputation by Supercompilation – Glück, Sørensen. 1996.</p>
<p>Shows how to use supercompilation for metaprogramming tasks “specialization”, “composition” and “inversion”. I don’t even remember what are the latter two though.</p></li>
<li><p>Building Domain-Specific Embedded Languages – Hudak. 1996.</p></li>
<li><p>On Perfect Supercompilation – Secher, Sørensen. 1996.</p>
<p>This paper shows how to do “negative information propagation” during “driving” (see Jones, 2000). “Negative” means “what forms a value cannot take”.</p>
<p>Now that I think about this idea again, I’m wondering in what sense “negative” information is special. Assuming the set of values of a type is finite, you can always express negative information as positive information, e.g. if the set contains <code>{X, Y, Z}</code> <code>cannot be X =&gt; is one of {Y, Z}</code>.</p></li>
<li><p>Realistic Compilation by Partial Evaluator – Sperber, Thiemann. 1996.</p>
<p>I love this paper. It inspired <a href="http://osa1.net/posts/2015-05-13-comp-through-interp.html">a project of mine</a>. I met the first author at ICFP’16 after coincidentally sitting next to him at lunch :) .</p></li>
<li><p>A transformation-based optimiser for Haskell – Jones, Santos. 1997.</p>
<p>Describes “let-no-escape” optimizations that is still in used today in GHC.</p></li>
<li><p>Improvement Theory and its Application – Sands. 1997.</p>
<p>The idea is used in Bolingbroke’s PhD thesis, that’s why I printed this, but I haven’t read it yet.</p></li>
<li><p>MetaML and Multi-Stage Programming with Explicit Annotations – Taha, Sheard. 1997.</p>
<p>Introduction to MetaML.</p></li>
<li><p>Definitional Interpreters for Higher-Order Programming Languages – Reynolds. 1998.</p>
<p>Classic.</p></li>
<li><p>Growing a Language – Steele. 1998.</p>
<p>Watch his talk with the same title instead, it’s awesome.</p></li>
<li><p>Positive supercompilation for a higher-order call-by-value language – Jonsson, Nordlander. 1998.</p>
<p>Funny how the pages are full of notes, yet I don’t remember anything about this paper.</p></li>
<li><p>Type Inference with Constrained Types – Odersky, Sulzmann, Wehr. 1998.</p></li>
<li><p>On the Power of Homeomorphic Embedding for Online Termination – Leuschel, 1998.</p></li>
<li><p>A semantics for imprecise exceptions – Jones, Reid, Hoare, Marlow, Henderson. 1999.</p></li>
<li><p>Call-By-Push-Value: A Subsuming Paradigm (extended abstract) – Levy. 1999.</p>
<p>Another paper that I just couldn’t finish.</p></li>
<li><p>Introduction to Supercompilation – Sørensen, Glück. 1999.</p>
<p>This is a really good introduction. It uses “process trees” which help a lot when trying to understand the idea for the first time. I made a presentation here at IU using process trees in this paper.</p></li>
<li><p>Linear Scan Register Allocation – Poletto, Sarkar. 1999.</p>
<p>Very famous algorithm, used in many JIT compilers. I think GHC also has a variant of this (see <code>compiler/nativeGen/RegAlloc/Linear</code> directory).</p></li>
<li><p>Partial Evaluation and Automatic Program Generation – Jones, Gomard, Sestoft. 1999.</p>
<p>I really like this book. I tried to implement every language in this book, but it became tiresome real quick. Best introduction to partial evaluation.</p></li>
<li><p>Secrets of the Glasgow Haskell Compiler inliner – Jones, Marlow. 1999.</p></li>
<li><p>The STG runtime system (revised) – Jones, Marlow. 1999.</p></li>
<li><p>Compiling Embedded Languages – Elliott, Finne, de Moor. 2000.</p></li>
<li><p>Type-Preserving Garbage Collectors – Wang, Appel. 2001.</p>
<p>Haven’t read this.</p></li>
<li><p>The Essence of Program Transformation by Partial Evaluation and Driving – Jones. 2000.</p>
<p>This paper defines the concept of “driving” which IIRC is also used in some early (before Mitchell and Bolingbroke papers) supercompilation papers.</p></li>
<li><p>Composable and Compilable Macros - When Want it When? – Flatt. 2002.</p></li>
<li><p>Template Meta-programming for Haskell – Sheard, Jones. 2002.</p></li>
<li><p>A Functional Correspondence between Evaluators and Abstract Machines – Ager, Biernacki, Danvy, Midtgaard. 2003.</p></li>
<li><p>From Interpreter to Compiler and Virtual Machine: A Functional Derivation – Ager, Biernacki, Danvy, Midtgaard. 2003.</p></li>
<li><p>Garbage-First Garbage Collection – Detlefts, Flood, Heller, Printezis. 2004.</p></li>
<li><p>Self-Adjusting Computation (PhD thesis) – Acar. 2005.</p>
<p>I started reading this a couple of time, failed every time. I was looking for some “automated” way of getting incremental compilation out of compiler passes that don’t take incremental compilation into account.</p></li>
<li><p>Gaussian Elimination: a case study in efficient genericity with MetaOCaml – Carette. 2005.</p></li>
<li><p>Fast and Loose Reasoning is Morally Correct – Danielsson, Hughes, Hansson, Gibbons. 2006.</p></li>
<li><p>Haskell Is Not Not ML – Rudiak-Gould, Mycroft, Jones. 2006.</p>
<p>I remember trying to read this paper many times, but I couldn’t succeed. I was thinking about an intermediate language that support both lazy and strict programs equally well.</p></li>
<li><p>Out of the Tar Pit – Moseley, Marks. 2006.</p>
<p>Defines “essential complexity” and “accidental complexity”.</p></li>
<li><p>The Development of Chez Scheme – Dybvig. 2006.</p>
<p>Chez in <a href="https://github.com/cisco/ChezScheme">now open source</a>. The runtime performance of Chez programs is good, but the compiler was a huge disappointment for me. Unreadable, undocumented mess, and the passes I was expecting to see is not there (sub-0CFA).</p></li>
<li><p>Call-pattern Specialisation for Haskell Programs – Jones. 2007.</p></li>
<li><p>Faster Laziness Using Dynamic Pointer Tagging – Marlow, Yakushev, Jones. 2007.</p>
<p>The idea is very simple and very effective. It’s in use in GHC today, and it’s saving us a lot of jumps. One of the reasons why unpacking sum types are not as useful as one might expect.</p>
<p>Over the summer 2016 one of the projects I worked on was to improve this in some cases. The problem was that in some cases (when strict fields are involved) GHC is currently not tagging some pointers even though in theory it could and that’d save us some instructions in the binaries. Unfortunately the rabbit hole goes quite deep and I had to drop it to focus on unboxed sums.</p></li>
<li><p>System F with Type Equality Coercions – Sulzmann, Chakravarty, Jones, Donnelly. 2007.</p></li>
<li><p>Generational Real-Time Garbage Collection - A Three-Part Invention for Young Objects – Frampton, Bacon, Cheng, Grove. 2007.</p>
<p>Haven’t read yet.</p></li>
<li><p>Bitcoin: A Peer-to-Peer Electronic Cash System – Satoshi Nakamoto. 2008.</p></li>
<li><p>Computation and State Machines – Lamport. 2008.</p></li>
<li><p>Finally Tagless, Partially Evaluate - Tagless Staged Interpreters for Simpler Typed Languages – Carette, Kiselyov, Shan. 2009.</p></li>
<li><p>Idempotent Work Stealing – Michael, Vechev, Saraswat. 2009.</p>
<p>This idea is used in LVish.</p></li>
<li><p>Positive Supercompilation for a Higher Order Call-By-Value Language – Jonsson, Nordlander. 2009.</p>
<p>An attempt at supercompiling a call-by-value language.</p></li>
<li><p>Supercompiler HOSC 1.0: under the hood – Klyuchnikov, 2009.</p>
<p>The author’s another paper (also listed here) is my favorite introduction to supercompilation.</p></li>
<li><p>Tracing the Meta-Level: PyPy’s Tracing JIT Compiler – Bolz, Cuni, Fijalkowski, Rigo. 2009.</p>
<p>Everything done by RPython/PyPy team is great.</p></li>
<li><p>Types are calling conventions – Bolingbroke, Jones. 2009.</p>
<p>Yet another great Bolingbroke work. I worked on a variant of this during the summer of 2016.</p></li>
<li><p>Abstracting Abstract Machines – Horn, Might. 2010.</p>
<p>I was told that this is very cool work, but I haven’t read it yet.</p></li>
<li><p>A Play on Regular Expressions – Fischer, Huch, Wilke. 2010.</p></li>
<li><p>Lightweight Modular Staging: A Pragmatic Approach to Runtime Code Generation and Compiled DSLs – Rompf, Odersky. 2010.</p>
<p>Scala LMS paper.</p></li>
<li><p>Proving the Equivalence of Higher-Order Terms by Means of Supercompilation – Klyuchnikov, Romanenko. 2010.</p></li>
<li><p>Rethinking Supercompilation – Mitchell. 2010.</p>
<p>I remember that I really liked this paper at the time. Unlike most other papers, this paper can be implemented in a couple of hours, and it works good enough. IIRC the main novelty here was the tag-bag based termination criterion, which was later developed further by Bolingbroke in first “Supercompilation by evaluation” and then in his PhD thesis.</p></li>
<li><p>Scrapping your Inefficient Engine: Using Partial Evaluation to Improve Domain-Specific Language Implementation – Brady, Hammond. 2010.</p>
<p>Introduces Idris’s partial evaluator.</p></li>
<li><p>Supercompilation by Evaluation – Bolingbroke, Jones. 2010.</p>
<p>Best supercompilation paper at the time. The record was later broken again by the author of this paper in his PhD thesis (also listed here). The author is amazing and I was depressed for a very long time after reading his papers (another notable one is “Termination Combinators Forever” which is also listed here). I’ll never be this good as a researcher.</p></li>
<li><p>Ur: Statically-Typed Metaprogramming with Type-Level Record Computation – Chilpala. 2010.</p></li>
<li><p>C4: The Continuously Concurrent Compacting Collector – Tene, Iyengar, Wolf. 2011.</p>
<p>Haven’t read yet.</p></li>
<li><p>Flow-Sensitive Type Recovery in Linear-Log Time – Adams, Keep, Midtgaard, Might, Chauhan, Dybvig. 2011.</p>
<p>Sub-0CFA for type inference. Not used in current Chez implementation as far as I can see. Goal is to eliminate runtime type checks.</p></li>
<li><p>How To Write Shared Libraries – Drepper. 2011.</p></li>
<li><p>Practical aspects of evidence-based compilation in System FC – Vytiniotis, Jones. 2011.</p>
<p>IIRC this stuff was introduced with GHC 7.2. For some reason that I can’t recall, it’s sometimes useful to return coercions in functions. This paper is about that. I don’t remember much although the paper has some notes on it.</p></li>
<li><p>Termination Combinators Forever – Bolingbroke, Jones, Vytiniotis. 2011.</p>
<p>Shows how to build online termination checkers using some primitives and combinators. Checkers are correct by construction. The implementation is used in the author’s implementation of his PhD thesis.</p></li>
<li><p>Challenges for a Trace-Based Just-In-Time Compiler for Haskell – Schilling. 2012.</p>
<p>Read his PhD thesis instead.</p></li>
<li><p>Chaperones and Impersonators: Run-time Support for Reasonable Interposition – Strickland, Tobin-Hochstadt, Findler, Flatt. 2012.</p>
<p>I have a big “NO” marked on the paper in red.</p></li>
<li><p>Explicitly Heterogeneous Metaprogramming with MetaHaskell – Mainland. 2012.</p></li>
<li><p>Self-Optimizing AST Interpreters – Würthinger, Wöß, Stadler, Duboscq, Simon, Wimmer. 2012.</p></li>
<li><p>The HERMIT in the Machine - A Plugin for the Interactive Transformation of GHC Core Language Programs – Farmer, Gill, Komp, Sculthorpe. 2012.</p></li>
<li><p>Call-by-need supercompilation (PhD thesis) – Bolingbroke. 2013.</p></li>
<li><p>Forge: Generating a High Performance DSL Implementation from a Declarative Specification – Sujeeth, Gibbons, Brown, Lee, Rompf, Odersky, Olukotun. 2013.</p>
<p>After having played with LMS and Delite a little bit, I have nothing good to say about this work. Things may be improved since then though.</p></li>
<li><p>Hybrid Partial Evaluation – Shali, Cook. 2013.</p>
<p>Cook has an introductory blog post / web page about partial evaluation which is pretty good.</p></li>
<li><p>Optimizing Data Structures in High-Level Programs – Rompf, Sujeeth, Amin, Brown, Jovanovic, Lee, Jonnalagedda, Olukotun, Odersky. 2013.</p>
<p>A Scala LMS paper. All I remember about these papers is that I didn’t like them.</p></li>
<li><p>One VM to Rule Them All – Würthinger, Wimmer, Wöß, Stadler, Duboscq, Humer, Richards, Simon, Wolczko. 2013.</p>
<p>Has 9 authors.</p></li>
<li><p>Simple and Efficient Construction of Static Single Assignment Form – Braun, Buchwalk, Hack, Leißa, Malloc, Zwinkau. 2013.</p>
<p>I think the algorithm was already known in the compilers community, but this paper publishes it first and benchmarks it.</p></li>
<li><p>Supercompiling Erlang (MSc thesis) – Weinholt. 2013.</p></li>
<li><p>Terra: A Multi-Stage Language for High-Performance Computing – DeVito, Hegarty, Aiken, Hanrahan, Vitek. 2013.</p>
<p>Terra is awesome. I talked a little bit about it in my blog posts <a href="http://osa1.net/posts/2015-05-17-staging-is-not-just-codegen.html">1</a>, <a href="http://osa1.net/posts/2015-08-09-sufficiently-smart-compiler.html">2</a>.</p></li>
<li><p>Trace-based Just-in-time Compilation for Lazy Functional Programming Languages (PhD thesis) – Schilling, 2013.</p>
<p>Two good theses published in 2013, Bolingbroke and this one. Too bad neither of them were pursued further.</p>
<p>IIRC the JIT introduction in this thesis is very easy to read, doesn’t assume a lot of background.</p></li>
<li><p>Combinators for Impure yet Hygienic Code Generation – Kameyama, Kiselyov, Shan. 2014.</p></li>
<li><p>Compiling a Reflective Language using MetaOCaml – Asai. 2014.</p>
<p>I love everything related with MetaOCaml.</p></li>
<li><p>Freeze After Writing - Quasi-Deterministic Parallel Programming with LVars – Kuper, Turon, Krishnaswami, Newton. 2014.</p></li>
<li><p>Macros that Work Together - Compile-Time Bindings, Partial Expression, and Definition Contexts – Flatt, Culpepper, Darais, Findler. 2014.</p></li>
<li><p>Modular, Higher-Order Cardinality Analysis in Theory and Practice – Sergey, Vytiniotis, Jones. 2014.</p>
<p>This is still in use in GHC today. Cardinality analysis is done as a part of demand analysis (lattice is extended to handle cardinalities).</p></li>
<li><p>Optimizing SYB Is Easy! – Adams, Farmer, Magalhaes. 2014.</p></li>
<li><p>Safe Zero-cost Coercions for Haskell (extended edition) – Breitner, Eisenberg, Jones, Weirich. 2014.</p>
<p>Another paper full of notes yet I don’t remember anything.</p></li>
<li><p>Supercompilation: Ideas and Methods – Klyuchnikov, Krustev. 2014.</p>
<p>Published in “The Monad.Reader” issue 23, this is without a doubt the best introduction to supercompilation. It’s very well written, provides great bibliography for further reading, and comes with a simple implementation. Great stuff, although the language is too simple to be useful.</p></li>
<li><p>Taming the Parallel Effect Zoo – Kuper, Todd, Tobin-Hochstadt, Newton. 2014.</p></li>
<li><p>The Kansas University Rewrite Engine - A Haskell-Embedded Strategic Programming Language with Custom Closed Universes – Sculthorpe, Frisby, Gill. 2014.</p>
<p>This is about KURE, rewrite engine that powers HERMIT. I remember that at the time I decided to implement my own rewrite combinators than fighting HERMIT API to do whatever I wanted to do.</p></li>
<li><p>Go 1.5 concurrent garbage collector pacing – Celements. 2015.</p></li>
<li><p>Static Program Analysis (lecture notes) – Møller, Schwartzbach. 2015.</p>
<p><a href="https://cs.au.dk/~amoeller/spa/" class="uri">https://cs.au.dk/~amoeller/spa/</a></p></li>
<li><p>Static Single Assignment Book (in-progress book) – “Lots of authors”. 2015 (ongoing)</p>
<p>I’m still reading this.</p></li>
<li><p>Shallow Embedding of DSLs via Online Partial Evaluation – Leißa, Boesche, Hack, Membarth, Slusallek. 2015.</p></li>
<li><p>The Design of Terra: Harnessing the Best Features of High-Level and Low-Level Languages – DeVito, Hanrahan. 2015.</p></li>
<li><p>Improving Implicit Parallelism – Trilla, Runciman. 2015.</p></li>
<li><p>K-Java: A Complete Semantics of Java – Bogdanas, Rosu. 2015.</p></li>
<li><p>Zero-Overhead Metaprogramming – Marr, Seaton, Ducasse. 2015.</p>
<p>Related with JITs, partial evaluation, and metaobject protocols. I don’t remember reading this.</p></li>
<li><p>GADTs Meet Their Match: Pattern-Matching Warnings That Account for GADTs, Guards, and Laziness – Karachalias, Schrivers, Vytiniotis, Jones. 2016.</p></li>
<li><p>Staging Generic Programming – Yallop. 2016.</p></li>
<li><p>State Machines All The Way Down - An Architecture for Dependently Typed Applications – Brady. 2016.</p></li>
</ul>
<hr />
<ul>
<li><p>Common Subexpression Elimination in a Lazy Functional Language – Chitil. ???</p>
<p>Shows how CSE can lead to more memory residency and is not always beneficial.</p></li>
<li><p>Constructed Product Result Analysis for Haskell – Baker-Finch, Glynn, Jones. ???</p>
<p>This is still a part of GHC, done during demand analysis. We recently extended this to work on sum types.</p></li>
<li><p>Demand analysis (draft, not published) – Jones, Sestoft, Hughes</p>
<p>I hate this paper because it wasted so much of my time. GHC wiki links to that, even though this is not relevant to the implementation. Read Sergey et al. instead.</p></li>
<li><p>Lecture Notes: Control Flow Analysis for Functional Languages (lecture notes) – Aldrich. ???</p></li>
<li><p>Supercompiling with Staging – Inoue. ???</p>
<p>Shows how to use MetaOCaml’s staging operators to do supercompilation-like transformations.</p></li>
<li><p>Space and Time Efficient Supercompilation (PhD thesis) – Jonsson. ???.</p></li>
<li><p>The Design and Implementation of BER MetaOCaml – Kiselyov. ???</p></li>
<li><p>The Next Stage of Staging – Inoue, Kiselyov, Kameyama. ???</p></li>
<li><p>Two Techniques for Compiling Lazy Pattern Matching – Maranget. ???</p></li>
<li><p>Warnings for pattern matching – Maranget. ???</p></li>
</ul>]]></summary>
</entry>
<entry>
    <title>More Rust problems (and a sketch of a solution)</title>
    <link href="http://osa1.net/posts/2016-09-11-more-rust-problems.html" />
    <id>http://osa1.net/posts/2016-09-11-more-rust-problems.html</id>
    <published>2016-09-11T00:00:00Z</published>
    <updated>2016-09-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>It’s a nice coincidence that after a good productive weekend of Rust hacking I saw <a href="https://hackernoon.com/why-im-dropping-rust-fd1c32986c88">this blog post</a> about why the author is dropping Rust. I’ve been doing a lot of Rust programming lately (I have at least 3 programs –not libraries– that I’m hoping to publish in the near future), and I’m surprised to see that no one mentioned in the discussion threads about this blog post what IMHO is one of the most annoying problems with Rust.</p>
<p>Borrow checker rejects some programs that are perfectly valid in other languages, and by itself this isn’t a problem. Similar things happen in all languages <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. One of the first problems I encountered after started to write Rust was the OP’s second problem, namely, cyclic data structures (or graphs, but more specifically, widgets with parent/child relations). However, there is at least one pretty good solution for this, and all you need is to think harder and experiment with alternative designs. I’m actually very happy with my solution to this (which is also discovered independently by many people, for an example, see <a href="https://crates.io/crates/petgraph">petgraph</a>).</p>
<p>However, there are problems that basically can’t be solved in Rust without paying some runtime costs or using bad practices. See my <a href="">previous blog post</a> for some examples. In this post I’m going to show another, and more annoying, problem.</p>
<h1 id="self-borrows-all-of-its-fields"><code>self</code> borrows all of its fields</h1>
<p>This is a problem that happened in pretty much every single Rust program I’ve ever written. In a method, you can’t borrow some fields, and call another <code>&amp;mut self</code> method. This is because methods borrow the whole <code>self</code>, so you get an error saying that you can’t borrow <code>self</code> twice.</p>
<p>As an example, imagine writing a compiler. For some reason you want to collect all the variables defined in a scope, and then generate fresh variables for those. You may do something like this:</p>
<pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> FreshGen { <span class="co">/* abstract */</span> }

<span class="kw">struct</span> Var { <span class="co">/* abstract */</span> }

<span class="kw">impl</span> FreshGen {
    <span class="kw">fn</span> fresh(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; Var {
        <span class="ot">unimplemented!</span>()
    }
}

<span class="kw">struct</span> Compiler {
    fresh_gen: FreshGen,
    vars_in_scope: Vec&lt;Var&gt;,
}

<span class="kw">impl</span> Compiler {
    <span class="kw">fn</span> fresh(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; Var {
        <span class="kw">self</span>.fresh_gen.fresh()
    }

    <span class="kw">fn</span> gen_locals(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
        <span class="kw">let</span> <span class="kw">mut</span> fresh_vars = <span class="ot">vec!</span>[];
        <span class="kw">for</span> var in <span class="kw">self</span>.vars_in_scope.iter() {
            fresh_vars.push(<span class="kw">self</span>.fresh());
        }
        <span class="co">// use fresh_vars</span>
    }
}</code></pre>
<p>Can you see any problems here? When I compile this with nightly 11/9/2016, I get this annoying error message:</p>
<pre><code>error[E0502]: cannot borrow `*self` as mutable because `self.vars_in_scope` is also borrowed as immutable
  --&gt; &lt;anon&gt;:24:29
   |
23 |         for var in self.vars_in_scope.iter() {
   |                    ------------------ immutable borrow occurs here
24 |             fresh_vars.push(self.fresh());
   |                             ^^^^ mutable borrow occurs here
25 |         }
   |         - immutable borrow ends here</code></pre>
<p>So basically, <code>self.vars_in_scope</code> is borrowed from <code>self</code>, and then <code>self.fresh()</code> is called while <code>vars_in_scope</code> is still borrowed. Even though <code>self.fresh()</code> doesn’t have anything to do with <code>self.vars_in_scope</code>, this is not allowed because the compiler simply doesn’t care about what pieces of <code>self</code> methods actually borrow. For me this is probably the #1 most annoying problem with Rust.</p>
<p>Now, I believe this problem is solvable. I imagine an algorithm like this:</p>
<p>It works in two steps.</p>
<ol style="list-style-type: decimal">
<li><p>We generate, for every method, borrow sets. A borrow set is a set of fields that are, at some point in the method, borrowed from <code>self</code>.</p></li>
<li><p>For every method call statement in every method, we look at intersections of currently borrowed fields and the borrow set of callee (i.e. (1) for the method being called).</p></li>
</ol>
<p>(1) works like this:</p>
<pre><code>workset = set of all methods
caller-graph = graph of all methods, with edges from callees to callers

# initially none of methods borrow any fields
for method in methods:
    method.borrows = empty set

while workset is not empty:
    work = workset.pop()
    for statement in work.statements:
        for field in self.borrowed_at(statement):
            if not work.borrows.contains(field):
                work.borrows.insert(field)
                for caller in caller-graph[work]:
                    workset.insert(caller)</code></pre>
<p>For a statement that has a method call, <code>borrowed_at()</code> returns the borrow set of the method being called. So when we update borrow set of a method, we add its callers to the workset and <code>borrowed_at()</code> will return more variables next time, propagating the information in the graph from callees to callers.</p>
<p>Now, for the second step, we first need to generate “live ranges” of borrowed fields. Assume that they’re generated.</p>
<pre><code>for method in methods:
    for borrowed_field in method.borrows():
        for field_live_range in borrowed_field.live_ranges():
            # for methods called in the range
            for method in method_calls(field_live_range):
                if method.borrows().contains(borrowed_field):
                    error(&quot;can&#39;t borrow twice&quot;)</code></pre>
<p>I sketched this in 30 minutes so I don’t expect this to work perfectly. Also, 4-level nested for loops look scary! But this is just to give an idea of how this might be solved.</p>
<p>In the example I showed above, borrow set of <code>fresh</code> would be <code>{fresh_gen}</code>, and borrow set of <code>gen_locals</code> would be <code>{vars_in_scope, fresh_gen}</code>. Now we look at live ranges of variables borrowed from <code>self</code> in <code>gen_locals</code>.</p>
<ul>
<li><code>vars_in_scope</code> lives between lines 2-4 in the method.</li>
<li><code>fresh_gen</code> lives in line 3 in the method.</li>
</ul>
<p>Since each variable has only one live range here, clearly there won’t be any intersections. So this would pass the borrow checker.</p>
<p>If <code>fresh</code> was also borrowing <code>vars_in_scope</code>, we’d get an error because <code>vars_in_scope</code> would now have two “live ranges”: between lines 2-4 as before, and in line 3. Since those intersect, we get an error.</p>
<p>(Again, this is a very quick sketch, so let me know if I’m missing something.)</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I’m hoping to write more about this later. For now, think Haskell’s type system that separates pure functions from effectful ones as an example.<a href="#fnref1">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>I'm available for job offers</title>
    <link href="http://osa1.net/posts/2016-09-05-available-for-offers.html" />
    <id>http://osa1.net/posts/2016-09-05-available-for-offers.html</id>
    <published>2016-09-05T00:00:00Z</published>
    <updated>2016-09-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>After two years as a PhD student at Indiana University, I finally decided to move to the industry, and I’m currently available for job offers.</p>
<p>For the most part I really enjoyed my time here at Indiana University. I still think that IU is the ideal place for someone like me to pursue a PhD. We have a great <a href="http://wonks.github.io/">programming languages group</a>, and the group I work more closely (with <a href="http://www.cs.indiana.edu/~rrnewton/homepage.html">my advisor</a>) is doing lots of hacking, on GHC (we have two core GHC developers in our group!), various Haskell libraries like <a href="https://github.com/iu-parfunc/lvars">lvish</a>, and <a href="http://www.cs.indiana.edu/~rrnewton/papers/pldi16-crossmod.pdf">runtime binary instrumentation tools</a>, which I really enjoy.</p>
<p>But publications are still a big part of the life as a PhD student, and I really, really disliked everything about publishing a paper. I’ve never wanted to have great publications, I’m more interested in learning about programming languages, compilers, and related tools, and contributing to projects that I believe are contributing to the community (which is one of my motivations when contributing to GHC). I want to have a deep understanding of fundamentals of programming languages and compilers, but I also want to develop as a programmer and software engineer.</p>
<p>Graduate school just didn’t let me do these as much as I’d like, and instead forced me to write papers. After about a year it started to become clear to me that academia is not the right place for me because I will probably never enjoy writing papers or grant proposals. So I realized that the long road to PhD in the US (about 6 years usually, followed by more years as postdoc) will be mostly a waste of time, and I won’t be as successful as I want because I don’t enjoy publishing papers.</p>
<p>Sure, I can be a PL researcher/developer in the industry after a PhD. But I believe if I can find a somewhat related job right now, in a few years I can be a PL researcher/developer, without wasting my 3-4 years suffering while trying to publish papers. If I can’t find such a job, well, I think I’ll still be happier because at least I’ll be programming and be much more productive.</p>
<p>So I decided that it’s best for me to do the switch as soon as possible.</p>
<p>If you’re interested, send me an email and let’s have a chat.</p>]]></summary>
</entry>
<entry>
    <title>Add a flag to your compiler to print errors in reversed order</title>
    <link href="http://osa1.net/posts/2016-09-04-reverse-error-messages.html" />
    <id>http://osa1.net/posts/2016-09-04-reverse-error-messages.html</id>
    <published>2016-09-04T00:00:00Z</published>
    <updated>2016-09-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>About a year ago <a href="https://ghc.haskell.org/trac/ghc/ticket/10848">I opened a feature request</a> for printing error messages in reversed order in GHC. By default most compilers print error messages by sorting them by the line number that they’re originated from. This is good when you get one or two error messages because in that case messages usually fit in the screen. But when you’re middle of a big refactoring (even if it’s just renaming a type) usually what happens is, you make your changes, reload/recompile the code, scroll up for 5 seconds to find the first error, fix it, and repeat.</p>
<p>The reason you scroll up is because most of the time declarations come before uses, and fixing a declaration makes error messages originated from use sites go away.</p>
<p>With a flag that reverses the error message order this becomes much simpler because you don’t need to scroll every time you reload/recompile. So if you’re developing a compiler, please consider adding this to your compiler.</p>
<p>(If you’re a GHC user, this is available with <code>-freverse-errors</code> flag)</p>]]></summary>
</entry>

</feed>
