<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>osa1.net - Posts tagged en</title>
    <link href="http://osa1.net/tags/en.xml" rel="self" />
    <link href="http://osa1.net" />
    <id>http://osa1.net/tags/en.xml</id>
    <author>
        <name>Ömer Sinan Ağacan</name>
        <email>omeragacan@gmail.com</email>
    </author>
    <updated>2024-11-29T00:00:00Z</updated>
    <entry>
    <title>Exploring parsing APIs: the cost of recursion</title>
    <link href="http://osa1.net/posts/2024-11-29-how-to-parse-3.html" />
    <id>http://osa1.net/posts/2024-11-29-how-to-parse-3.html</id>
    <published>2024-11-29T00:00:00Z</published>
    <updated>2024-11-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In the <a href="https://osa1.net/posts/2024-11-22-how-to-parse-1.html">first post</a> of this series we looked at a few different ways of parsing a simple JSON-like language. In the <a href="https://osa1.net/posts/2024-11-28-how-to-parse-2.html">second post</a> we implemented a few lexers, and looked at the performance when the parsers from the first post are combined with the lexers in the second post.</p>
<p>One of the surprising results in these posts is that our recursive descent parser, which parses the input directly to an AST, and in some sense is the simplest possible implementation when we need an AST, actually performs the worst.</p>
<p>(The implementations that collect tokens in a vector before parsing perform worse than recursive descent parsing, but those implementations have other issues as well, and can’t be used in many cases. Maybe I should’ve omitted them entirely.)</p>
<p>To keep things simple, let’s consider these three benchmarks, from the last post:</p>
<ul>
<li>Recursive descent: 127 Mb/s</li>
<li>tokenize_iter + events_iter to AST: 138 Mb/s</li>
<li>tokenize_push + events_push to AST: 151 Mb/s</li>
</ul>
<p>To recap, the “iter” variants are <code>Iterator</code>s that return one parse (or lexing) event at a time. The “push” variants take a “listener” argument with callbacks for events. See the first post for details.</p>
<p>In the “iter” benchmark, the code that generates the AST iterates an event parser:</p>
<pre><code>fn event_to_tree&lt;I: Iterator&lt;Item = Result&lt;ParseEvent, ParseError&gt;&gt;&gt;(
    parser: &amp;mut I,
    input: &amp;str,
) -&gt; Result&lt;Json, ParseError&gt; {
  ...
}</code></pre>
<p>And the event parser iterates a lexer:</p>
<pre><code>fn parse_events_iter_using_lexer_iter&lt;I: Iterator&lt;Item = Result&lt;(usize, Token), usize&gt;&gt;&gt;(
    lexer: I,
    input_size: usize,
) -&gt; EventParser&lt;I&gt; {
    ...
}</code></pre>
<p>When the AST generator asks for the next parse event, the parse event generator asks for the next token (maybe multiple times) and returns an event. AST generator consumes all of the events and builds the AST.</p>
<p>In the “push” benchmark, we have a “listener” that handles parse events and builds up an AST:</p>
<pre><code>struct AstBuilderListener&lt;&#39;a&gt; {
    input: &amp;&#39;a str,
    container_stack: Vec&lt;Container&gt;,
    current_container: Option&lt;Container&gt;,
    parsed_object: Option&lt;Json&gt;,
    error: Option&lt;ParseError&gt;,
}

impl&lt;&#39;a&gt; EventListener for AstBuilderListener&lt;&#39;a&gt; {
    ...
}</code></pre>
<p>And another listener that handles tokens:</p>
<pre><code>struct LexerEventListenerImpl&lt;&#39;a, L: EventListener&gt; {
    listener: &amp;&#39;a mut L,
    container_stack: Vec&lt;Container&gt;,
    state: ParserState,
}

impl&lt;&#39;a, L: EventListener&gt; LexerEventListener for LexerEventListenerImpl&lt;&#39;a, L&gt; {
  ...
}</code></pre>
<p>This implementation is driven by the lexer which “pushes” the tokens to the event parser, which (possibly after handling multiple tokens) “pushes” parse events to the AST builder.</p>
<p>Both of these setups are considerably more complicated than recursive descent, yet they perform better. How?</p>
<p>When we consider what the recursive descent parser does that these don’t, it’s kind of obvious. It’s even in the name: recursion.</p>
<p>Our lexers and event parsers all optimize really well: there is no heap allocation anywhere, the code that “pushes” events are all monomorphised based on the handler type, so the handler calls are direct calls and can be (and probably) inlined. There’s also no recursion anywhere.</p>
<p>The recursive descent parser is basically one function that recursively calls itself for nested objects. It turns out this recursion has a cost. When I eliminate the recursion with some more state:</p>
<pre><code>enum ParserState {
    /// Parse any kind of object, update state based on the current container.
    TopLevel,

    /// Parsing a container, parse another element on &#39;,&#39;, or finish the
    /// container on &#39;]&#39; or &#39;}&#39;.
    ExpectComma,

    /// Parsing an object, parse a key.
    ObjectExpectKeyValue,

    /// Parsing an object, parse a key, or terminate the object.
    ObjectExpectKeyValueTerminate,

    /// Parsing an object and we&#39;ve just parsed a key, expect &#39;:&#39;.
    ObjectExpectColon,
}

fn parse_single(iter: &amp;mut Peekable&lt;CharIndices&gt;, input: &amp;str) -&gt; Result&lt;Json, ParseError&gt; {
    let mut container_stack: Vec&lt;Container&gt; = vec![];
    let mut state = ParserState::TopLevel;

    loop {
      ...
    }
}</code></pre>
<p>It performs better than the recursive descent parser and the iterator based parser, and on par with the “push” based parser: (numbers are slightly different than above as I rerun them together)</p>
<ul>
<li>Recursive descent: 127 Mb/s</li>
<li>tokenize_iter + events_iter to AST: 136 Mb/s</li>
<li>tokenize_push + events_push to AST: 158 Mb/s</li>
<li>Direct parser without recursion: 156 Mb/s</li>
</ul>
<p>I’m not quite sure what about recursion that makes the recursive descent parser perform so much worse, but my guess is that it makes the control flow more complicated to analyze, and in runtime, you have to move things around (in registers and stack locations) based on calling conventions. When moving between registers and stack locations you do memory reads and writes. My guess is that when combined, these cost something.</p>
<h1 id="other-considerations-with-recursion">Other considerations with recursion</h1>
<p>If you checkout the git repo and run the tests with <code>cargo test</code>, you will see that a test fails with a stack overflow.</p>
<p>This is something else to keep in mind when parsing recursively. Stack overflows are a real issue with recursive parsing, and I know some libraries that are <a href="https://github.com/google/protobuf.dart/blob/ccf104dbc36929c0f8708285d5f3a8fae206343e/protobuf/lib/src/protobuf/coded_buffer_reader.dart#L29">explicit about it</a>.</p>
<p>In practice though, I’m not sure if this can be the main reason to avoid recursive parsing. Recursion can happen in other places as well, and in a server application you would probably monitor runtime, memory consumption, and maybe even other resources of a handler, and have some kind of error handler that handles everything else.</p>
<p>In higher level languages like <a href="https://hackage.haskell.org/package/base-4.20.0.1/docs/GHC-IO-Exception.html#t:AsyncException">Haskell</a> and <a href="https://api.dart.dev/dart-core/StackOverflowError-class.html">Dart</a> that make stack overflows exceptions/errors that can be caught and handled, so they can be handled as a part of “unexpected” crashes easily. In Rust, they stack overflows can be handled at thread boundaries.</p>
<p>If the application is command line tool or a compiler, where the input is provided by the user and handled on the user’s computer, it’s less of a problem and you can probably just let the application crash.</p>
<p>So I don’t think we can say that recursion should be avoided at all costs when parsing.</p>
<h1 id="references">References</h1>
<p>As usual, the code is available: <a href="https://github.com/osa1/how-to-parse-3">github.com/osa1/how-to-parse-3</a>.</p>
<p>To work around the stack overflow when testing, test in release mode: <code>cargo test --release</code>.</p>
<p>If you want to profile the code and understand more about why one version is faster than the other, I added 4 executables to the package, one for each benchmark listed above. You can generate a 100M input and run the parsers individually with:</p>
<pre><code>$ cargo build --release
...

$ ./target/release/test_gen 100000000 &gt; input

$ time ./target/release/parse_non_recursive input
./target/release/parse_non_recursive input  0.64s user 0.22s system 99% cpu 0.854 total</code></pre>]]></summary>
</entry>
<entry>
    <title>Exploring parsing APIs: adding a lexer</title>
    <link href="http://osa1.net/posts/2024-11-28-how-to-parse-2.html" />
    <id>http://osa1.net/posts/2024-11-28-how-to-parse-2.html</id>
    <published>2024-11-28T00:00:00Z</published>
    <updated>2024-11-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In the <a href="https://osa1.net/posts/2024-11-22-how-to-parse-1.html">previous post</a> we looked at three different parsing APIs, and compared them for runtime and the use cases they support.</p>
<p>In this post we’ll add a lexer (or “tokenizer”), with two APIs, and for each lexer see how the parsers from the previous post perform when combined with the lexer.</p>
<p><strong>What is a lexer?</strong> A lexer is very similar to the event parsers we saw in the previous post, but it doesn’t try to maintain any structure. It generates “tokens”, which are parts of the program that cannot be split into smaller parts. A lexer doesn’t care about parentheses or other delimiters being balanced, or that values in an array are separated by commas, or anything else. It simply splits the input into tokens.</p>
<p><strong>Why is a lexer useful?</strong> If you already have an event parser, adding a lexer may not allow a lot of new use cases. The main use cases that I’m aware of are:</p>
<ul>
<li><p>Syntax highlighting: when higlighting syntax we don’t care about the tree structure, we care about keywords, punctuation (list separators, dots in paths etc.), delimiters (commas, bracets, brackets), and literals. A lexer gives us exactly these and nothing else.</p></li>
<li><p>Supporting incremental parsing: one way of incrementally update an AST is by starting re-lexing a few (often just one) tokens before the edited token, re-lexing until after the edit location, until generating a token identical to an existing token again. AST nodes of modified tokens are then marked as “modified” and re-parsed.</p>
<p>The details are complicated, I recommend chapter 2 of <a href="https://diekmann.uk/diekmann_phd.pdf">this PhD thesis</a> for an introduction to incremental parsing.</p>
<p>If you need to re-parse code as it gets edited, even if you don’t need or want incremental parsing, incremental lexing is easy, it makes sense to re-lex incrementally and then parse from scratch using the incrementally updated token list, because incremental lexing is so simple.</p></li>
<li><p>For separating complex parsing code into smaller parts: modern languages can have complicated literal syntax, with multiple string literals with varying delimiters (like <code>r#"..."#</code> syntax in Rust, or <code>[=[...]=]</code> in Lua), multiple variants of comments (single line and multi-line, documentation and normal), multiple number syntaxes (with different suffixes like <code>123u32</code> in Rust, underscores to separate digits for readability) and so on.</p>
<p>A lexer separates handling of these from the part of the parser that deals with the program structure.</p></li>
</ul>
<h1 id="the-apis">The APIs</h1>
<p>Similar to the previous post, we will look at three different APIs for lexing:</p>
<ul>
<li>A lexer that generates a list of tokens directly: <code>tokenize_list</code>.</li>
<li>An iterator that generates one token at a time: <code>tokenize_iter</code>.</li>
<li>A “push” API that calls “listener” methods for the tokens: <code>tokenize_push</code>.</li>
</ul>
<p>For our simplified (and enhanced, with comments) JSON, our token type is:</p>
<pre><code>pub enum Token {
    Int(u64),
    Str { size_in_bytes: usize },
    True,
    False,
    Null,
    LBracket,
    RBracket,
    LBrace,
    RBrace,
    Colon,
    Comma,
    Comment { size_in_bytes: usize },
}</code></pre>
<p>Similar to our event type from the previous post, this type needs to be cheap to generate (ideally stack allocated).</p>
<p>The tokens are generated along with byte offsets in the input, also similar to events.</p>
<p>For the push API, the listener interface also directly follows the token type:</p>
<pre><code>pub trait LexerEventListener {
    fn handle_int(&amp;mut self, byte_offset: usize, i: u64);

    fn handle_str(&amp;mut self, byte_offset: usize, size_in_bytes: usize);

    // Similar for other token types.
    ...

    fn handle_error(&amp;mut self, byte_offset: usize);
}</code></pre>
<p>To keep things simple, the event handlers don’t return a <code>bool</code> to stop parsing. It can be added in a few lines of code and it doesn’t affect performance.</p>
<p>Unlike the different types of event parsers from the previous post, implementations of these lexer APIs are almost identical. This is because the lexer has only one state, which is the current position in the input. A <code>next</code> call in the iterator implementation simply continues from the current location in the input, and updates the current location as it reads characters from the input.</p>
<p>The entry points are:</p>
<pre><code>pub fn tokenize_iter&lt;&#39;a&gt;(input: &amp;&#39;a str) -&gt; Lexer&lt;&#39;a&gt; { ... }
  // Lexer implements `Iterator`

pub fn tokenize_push&lt;L: LexerEventListener&gt;(input: &amp;str, listener: &amp;mut L) { ... }

pub fn tokenize_list(input: &amp;str) -&gt; Result&lt;Vec&lt;(usize, Token)&gt; usize&gt; { ... }</code></pre>
<h1 id="combining-with-the-event-parsers">Combining with the event parsers</h1>
<p>We have 3 lexers and 2 event parsers, so 6 combinations in total:</p>
<ol type="1">
<li>tokenize_list + parse_events_iter</li>
<li>tokenize_list + parse_events_push</li>
<li>tokenize_iter + parse_events_iter</li>
<li>tokenize_iter + parse_events_push</li>
<li>tokenize_push + parse_events_iter</li>
<li>tokenize_push + parse_events_push</li>
</ol>
<p>However (5) is not easily possible in Rust. The problem is that a push implementation cannot be converted into an iterator, as it will scan the entire input without ever returning and keep calling the listener methods. To convert a push API into an iterator, we need a language feature that allows us to stop the current thread (or maybe a “fiber”, green thread etc.) and resume it later. In Rust, this is possible with <code>async</code> or threads. Threads are expensive, and <code>async</code> requires a lot of refactoring, and all the call sites to be made <code>async</code> as well.</p>
<p>So in this post we won’t consider this combination.</p>
<h1 id="notes-on-implementations">Notes on implementations</h1>
<p>Implementing these combinations is mostly straightforward. Full code is linked below as usual. The takeaways are:</p>
<ul>
<li>The push API cannot be converted into an iterator API, without language features.</li>
<li>The push API requires state management in the consumer: the consumer will have to save the state that needs to be maintained between the calls to the listener methods.</li>
<li>The iterator API is more flexible as it can be converted into a push API.</li>
<li>The iterator API is also easier to use: the consumer can iterate through the elements in nested loops, and needs less state management. The state can also be function locals, instead of fields of a struct (or class etc.).</li>
<li>The list API (generates an entire vector of tokens) only makes sense when you need to collect all of the tokens in memory. The only use case for this that I’m aware of is incremental parsing.</li>
</ul>
<h1 id="references-and-benchmarks">References and benchmarks</h1>
<p>The code (including benchmarks) is here: <a href="https://github.com/osa1/how-to-parse-2">github.com/osa1/how-to-parse-2</a>.</p>
<p><strong>Token generation benchmarks:</strong> Collect all of the tokens in a <code>Vec</code>.</p>
<ul>
<li>tokenize_list: 305 MB/s</li>
<li>tokenize_push: 303 MB/s</li>
<li>tokenize_iter: 329 MB/s</li>
</ul>
<p>In the event generation benchmarks in the last post, the push implementation is about 10% faster than the iterator. But in the lexer, the iterator is faster when collecting the tokens in a vector. It looks like when the state that the parser manages between the <code>next</code> calls gets simpler, the compiler is able to optimize the code better, and iterator implementation beats the push implementation.</p>
<p>The vector generator and push implementation adding the elements to a vector via the listener perform the same, which shows that when monomorphised, the push implementation optimizes quite well for simple cases (but also in complex cases, as we will see below). In languages without monomorphisation, the push API should be slower.</p>
<p><strong>Tokens to events:</strong> Convert tokens to events.</p>
<ul>
<li>events_iter: 282 MB/s</li>
<li>events_push: 315 MB/s</li>
<li>tokenize_list + events_iter: 181 MB/s</li>
<li>tokenize_list + events_push: 187 MB/s</li>
<li>tokenize_iter + events_iter: 269 MB/s</li>
<li>tokenize_iter + events_push: 275 MB/s</li>
<li>tokenize_push + events_push: 351 MB/s</li>
</ul>
<p>The first two benchmarks are the ones from the previous post that don’t use a lexer, generate events directly. The numbers are slightly different than the numbers from the previous post as I rerun them again.</p>
<p>If you need some kind of incremental implementation, scanning the entire input and collecting the events or tokens in a vector performs bad. There’s no point in combining the list API with push or iterator APIs.</p>
<p>What’s surprising is that the push lexer implementation combined with the push event generator implementation performs better than the event generator implementation that parses the input directly without a lexer. I don’t have an explanation to why, yet.</p>
<p>Lexer iterator implementations combined with any of the event generation implementations perform slower than the event push implementation that parses the input directly, but about as fast as the event iterator implementation that parses the input directly.</p>
<p><strong>Tokens to AST:</strong> Converts tokens to events, builds AST from the events.</p>
<ul>
<li>Recursive descent: 127 MB/s</li>
<li>events_iter to AST: 140 MB/s</li>
<li>events_push to AST: 145 MB/s</li>
<li>tokenize_list + events_iter to AST: 108 MB/s</li>
<li>tokenize_list + events_push to AST: 108 MB/s</li>
<li>tokenize_iter + events_iter to AST: 138 MB/s</li>
<li>tokenize_iter + events_push to AST: 139 MB/s</li>
<li>tokenize_push + events_push to AST: 151 MB/s</li>
</ul>
<p>The first three benchmarks below are from the last post. Rerun and included here for comparison.</p>
<p>When we add an AST building step, which is more complicated compared to the rest of steps, the performance difference between the most convenient implementation (tokenize_iter + events_iter to AST) and the most performant one (tokenize_push + events_push to AST) diminishes. In the event generation benchmark, the fast one is 30% faster, but when building an AST, it’s only 9% faster.</p>
<p>The push implementation is still faster than the recursive descent parser, even with the extra lexing step. I’m planning to investigate this further in a future post.</p>]]></summary>
</entry>
<entry>
    <title>Exploring parsing APIs: what to generate, and how</title>
    <link href="http://osa1.net/posts/2024-11-22-how-to-parse-1.html" />
    <id>http://osa1.net/posts/2024-11-22-how-to-parse-1.html</id>
    <published>2024-11-22T00:00:00Z</published>
    <updated>2024-11-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Consider a simplified and enhanced version of JSON, with these changes:</p>
<ul>
<li>Numbers are 64-bit unsigned integers.</li>
<li>Strings cannot have control and escape characters.</li>
<li>Single-line comments are allowed, with the usual syntax: <code>// ...</code> .</li>
</ul>
<p>When parsing a language like this, a common first step if to define an “abstract syntax tree” (AST), with only the details we want from the parser output.</p>
<p>For example, if we’re implementing a tool like <a href="https://jqlang.github.io/jq/">jq</a>, the AST may look like:</p>
<pre><code>enum Json {
    Int(u64),
    Str(String),
    Bool(bool),
    Array(Vec&lt;Json&gt;),
    Object(Vec&lt;(String, Json)&gt;),
    Null,
}</code></pre>
<p>This type is called an “abstract” syntax tree because it abstracts the unnecessary details from the parse output. In our tool we don’t need locations of nodes and comments, so the AST doesn’t contain them.</p>
<p>It’s easy to implement a parser for this AST: we iterate the input, skip whitespace and comments, then based on the next character decide what type of node (integer, string, etc.) to parse. For nested <code>Json</code> nodes in arrays and objects, we recursively call the parser.</p>
<p>This kind of parser is called a “recursive descent parser”. For our AST above, the parser looks like this:</p>
<pre><code>// The entry point: parses all of the input to JSON.
pub fn parse(input: &amp;str) -&gt; Result&lt;Json, JsonParseError&gt; {
    let mut iter = input.char_indices().peekable();
    let (_, json) = parse_single(&amp;mut iter, input)?;
    skip_trivia(&amp;mut iter)?;
    // Check that all of the input is consumed.
    ...
}

// Parse a single Json. After parsing, the input may have more characters to be parsed.
fn parse_single(
    iter: &amp;mut Peekable&lt;CharIndices&gt;,
    input: &amp;str,
) -&gt; Result&lt;(usize, Json), ParseError&gt; {
    // Skip whitespace and comments.
    skip_trivia(iter)?;

    // Get next character.
    let (byte_offset, char) = match iter.next() { ... }

    if char == &#39;[&#39; {
        // Parse an array. Call `parse_single` recursively for elements.
        ...
    }

    if char == &#39;{&#39; {
        // Parse an object. Call `parse_single` recursively for values.
        ...
    }

    if char == &#39;t&#39; {
        // Parse keyword &quot;true&quot;.
        ...
    }

    // Same for other keywords, integers, strings.
    ...
}</code></pre>
<p>While very common, this kind of parsers are inflexible, and slower than more flexible alternatives for many use cases.</p>
<p>Consider these use cases:</p>
<ul>
<li><p>A JSON formatter: a formatter needs to know about comments to be able to keep them in the formatted code. To support this use case, the AST needs to include comments too, which will make it larger, and parsing will be less efficient for the applications that don’t need comments.</p></li>
<li><p>A configuration file parser for a text editor: to be able to show error locations in configuration errors (such as an invalid value used for a setting), the AST will have to include source locations. Similar to above, this will make the AST larger and slower to parse for other applications that don’t need source locations.</p></li>
<li><p>An RPC server that looks at the command name in incoming JSON messages and relays the messages based on the command name: the server doesn’t even need a full parser, just a parser that can keep track of nesting level so that it can extract the request name field at the right level will suffice. Using a full AST parser will parse the whole message and be inefficient.</p></li>
<li><p>A log sorting tool that reads a file with one JSON log per line, sorts the lines based on top-level “timestamp” field values. Similar to the use case above, this tool only needs to read one field and parsing whole lines is wasteful.</p></li>
</ul>
<p>A well-known solution to these is to introduce a lower level parser that doesn’t generate a fully structured output like an AST, but a stream of “parse events”. These events should be general enough to allow different use cases like the ones we listed above, and should be cheap to allocate and pass around, ideally as stack allocated values, so that applications that don’t need them can skip them efficiently.</p>
<p>This type of parsing is often called “event driven parsing”. In our JSON variant, the events look like this:</p>
<pre><code>/// A parse event, with location of the event in the input.
pub struct ParseEvent {
    pub kind: ParseEventKind,
    pub byte_offset: usize,
}

/// Details of a parse event.
pub enum ParseEventKind {
    StartObject,
    EndObject,
    StartArray,
    EndArray,
    Int(u64),
    Str {
        /// Size of the string, not including the double quotes.
        size_in_bytes: usize,
    },
    Bool(bool),
    Null,
    Comment {
        /// Size of the comment, including the &quot;//&quot; a the beginning and newline at the end.
        size_in_bytes: usize,
    },
}</code></pre>
<p>Note that there’s no heap allocation required for these events. Contents of strings and comments can be obtained by slicing the input using the event location and <code>size_in_bytes</code> field.</p>
<p>When generating these event, it’s important that we don’t scan the whole input and collect all of the events in a list, as that would mean some of the users, like our RPC server and log sorted examples above, would have to do more work than necessary.</p>
<p>This means that the parser will have to be stateful: after returning an event, it needs to be able to continue from the last event location. This complicates the parser implementation quite a bit. Here’s how the parser looks like at a high level:</p>
<pre><code>// The entry point. Use via the `Iterator` interface.
pub fn parse_events(input: &amp;str) -&gt; EventParser {
    EventParser::new(input)
}

// The parser state.
pub struct EventParser&lt;&#39;a&gt; {
    input: &amp;&#39;a str,
    byte_offset: usize,
    container_stack: Vec&lt;Container&gt;,
    state: ParserState,
}

enum Container {
    Array,
    Object,
}

enum ParserState {
    /// Parse any kind of object, update state based on the current container.
    TopLevel,

    /// Finished parsing a top-level object, expect end-of-input.
    Done,

    /// Parsing an object, parse another element on &#39;,&#39;, or finish the array on &#39;}&#39;.
    ObjectExpectComma,

    /// Parsing an object, parse the first element, or finish the array on &#39;]&#39;.
    ObjectExpectKeyValue,

    /// Parsing an object and we&#39;ve just parsed a key, expect &#39;:&#39;.
    ObjectExpectColon,

    /// Parsing an array, parse another element on &#39;,&#39;, or finish the array on &#39;]&#39;.
    ArrayExpectComma,
}

impl&lt;&#39;a&gt; Iterator for EventParser&lt;&#39;a&gt; {
    type Item = Result&lt;ParseEvent, ParseError&gt;;

    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {
        match self.state {
            ParserState::TopLevel =&gt; self.top_level(),
            ParserState::Done =&gt; self.done(),
            ParserState::ObjectExpectComma =&gt; self.object_expect_comma(),
            ParserState::ObjectExpectKeyValue =&gt; self.object_expect_key_value(),
            ParserState::ObjectExpectColon =&gt; self.object_expect_colon(),
            ParserState::ArrayExpectComma =&gt; self.array_expect_comma(),
        }
    }
}

...</code></pre>
<p>The main complexity of this parser comes from the fact that it cannot return an event and keep running, the caller needs to call the relevant method (<code>next</code> from the <code>Iterator</code> trait above) to keep parsing. To be able to continue from where it’s left, the parser needs to maintain some state outside of the parse functions.</p>
<p>This parser is general enough to allow implementing our original AST parser:</p>
<pre><code>pub fn event_to_tree&lt;I: Iterator&lt;Item = Result&lt;ParseEvent, ParseError&gt;&gt;&gt;(
    parser: &amp;mut I,
    input: &amp;str,
) -&gt; Result&lt;Json, ParseError&gt; {
    let mut container_stack: Vec&lt;Container&gt; = vec![];
    let mut current_container: Option&lt;Container&gt; = None;
    let mut parsed_object: Option&lt;Json&gt; = None;

    for event in parser.by_ref() {
        match event {
            ...
        }
    }

    Ok(parsed_object.unwrap())
}</code></pre>
<p>But it also allows parsing to an AST with comments (for our formatter), source locations (for our configuration parser), and our RPC server and log sorter. Here’s how the timestamp parser that stops after finding the field looks like:</p>
<pre><code>/// Parse the &quot;timestamp&quot; field at the top-level map of the JSON.
pub fn parse_timestamp(log_line: &amp;str) -&gt; Result&lt;Option&lt;u64&gt;, ParseError&gt; {
    let mut container_depth: u32 = 0;
    let mut expect_timestamp = false;

    for event in parse_events(log_line) {
        let ParseEvent { kind, byte_offset } = match event {
            Ok(event) =&gt; event,
            Err(err) =&gt; return Err(err),
        };

        let expect_timestamp_ = expect_timestamp;
        expect_timestamp = false;

        match kind {
            ParseEventKind::StartObject =&gt; {
                container_depth += 1;
            }

            ParseEventKind::EndObject =&gt; {
                container_depth -= 1;
            }

            ParseEventKind::StartArray =&gt; {
                if container_depth == 0 {
                    // Array at the top level, the line does not contain the field.
                    return Ok(None);
                }
                container_depth += 1;
            }

            ParseEventKind::EndArray =&gt; {
                container_depth -= 1;
            }

            ParseEventKind::Str { size_in_bytes } =&gt; {
                if container_depth != 1 {
                    continue;
                }
                let str = &amp;log_line[byte_offset..byte_offset + size_in_bytes];
                expect_timestamp = str == &quot;timestamp&quot;;
            }

            ParseEventKind::Int(i) =&gt; {
                if expect_timestamp_ {
                    return Ok(Some(i));
                }
            }

            ParseEventKind::Bool(_)
            | ParseEventKind::Null
            | ParseEventKind::Comment { .. } =&gt; {}
        }
    }

    Ok(None)
}</code></pre>
<p>A nice property of this parser is that it does not allocate at all. It doesn’t build an AST (so no heap-allocated vectors), and parse events are 24-byte stack allocated values. The event parser is also stack allocated by this function.</p>
<p>An alternative design to this that is slightly less flexible and more difficult to use, but easier to implement and faster is what’s sometimes called a “push parser”.</p>
<p>The idea is that, instead of returning one event at a time, the parser takes a “listener” argument, and calls the listener callbacks for each event generated. The listener type directly follows our event type above:</p>
<pre><code>// Methods return a `bool` indicating whether to continue parsing after the event.
pub trait EventListener {
    fn handle_start_object(&amp;mut self, _byte_offset: usize) -&gt; bool {
        true
    }

    fn handle_end_object(&amp;mut self, _byte_offset: usize) -&gt; bool {
        true
    }

    fn handle_start_array(&amp;mut self, _byte_offset: usize) -&gt; bool {
        true
    }

    fn handle_end_array(&amp;mut self, _byte_offset: usize) -&gt; bool {
        true
    }

    fn handle_int(&amp;mut self, _byte_offset: usize, _i: u64) -&gt; bool {
        true
    }

    fn handle_str(&amp;mut self, _byte_offset: usize, _size_in_bytes: usize) -&gt; bool {
        true
    }

    fn handle_bool(&amp;mut self, _byte_offset: usize, _b: bool) -&gt; bool {
        true
    }

    fn handle_null(&amp;mut self, _byte_offset: usize) -&gt; bool {
        true
    }

    fn handle_comment(&amp;mut self, _byte_offset: usize, _size_in_bytes: usize) -&gt; bool {
        true
    }

    fn handle_error(&amp;mut self, _error: ParseError);
}</code></pre>
<p>The parser:</p>
<pre><code>// The entry point. Parse all of the input, call `listener` with the events.
pub fn parse&lt;L: EventListener&gt;(input: &amp;str, listener: &amp;mut L) {
    let mut iter = input.char_indices().peekable();
    let input_size = input.len();

    // Parse a single JSON.
    if !parse_single(&amp;mut iter, input_size, listener) {
        return;
    }

    // Check that all of the input is consumed.
    ...
}

// Returns whether an error was reported.
fn parse_single&lt;L: EventListener&gt;(
    iter: &amp;mut Peekable&lt;CharIndices&gt;,
    input_size: usize,
    listener: &amp;mut L,
) -&gt; bool {
    // Skip whitespace and comments, generate events for comments.
    skip_trivia!(iter, listener);

    // Get next character.
    let (byte_offset, char) = match iter.next() {
        Some(next) =&gt; next,
        None =&gt; {
            listener.handle_error(ParseError {
                byte_offset: input_size,
                reason: &quot;unexpected end of input&quot;,
            });
            return false;
        }
    };

    if char == &#39;[&#39; {
        // Parse an array. Call `parse_single` recursively for elements.
        ...
    }

    if char == &#39;{&#39; {
        // Parse an object. Call `parse_single` recursively for values.
        ...
    }

    if char == &#39;t&#39; {
        // Parse keyword &quot;true&quot;.
        ...
    }

    // Same for other keywords, integers, strings.
    ...
}</code></pre>
<p>Note that the parser functions are identical (in terms of names and what they do) to our simple recursive descent parser. This is because the parser no longer needs to maintain state to be able to return and continue from where it was left, as it does all of the work in one go. Instead of building an AST or a list of events, it takes an <code>EventListener</code> argument and calls the handle methods.</p>
<p>This is a bit less convenient to use, but it’s still flexible enough to build an AST. An <code>EventListener</code> implementation that builds up a <code>Json</code> AST looks like this:</p>
<pre><code>pub struct AstBuilderListener&lt;&#39;a&gt; {
    input: &amp;&#39;a str,
    container_stack: Vec&lt;Container&gt;,
    current_container: Option&lt;Container&gt;,
    parsed_object: Option&lt;Json&gt;,
    error: Option&lt;ParseError&gt;,
}

impl&lt;&#39;a&gt; EventListener for AstBuilderListener&lt;&#39;a&gt; {
    ...
}</code></pre>
<p>However, if you need to be able to stop parsing and continue later, this parser can’t do that.</p>
<p>The main advantage of this parser is that, with the right programming language and parser design, it can be faster than the alternatives, while still being flexible enough for most use cases. See below for benchmarks.</p>
<hr />
<h1 id="aside-event-parsing-vs.-lexing">Aside: event parsing vs. lexing</h1>
<p>Our <code>ParseEvent</code> type has no nested data and looks like what we could define as the “tokens” in a parser for a programming language.</p>
<p>So it shouldn’t be surprising that we can use a lexer generator to implement a parse event generator:</p>
<pre><code>// Same `parse_events` as above, but uses a generated lexer.
pub fn parse_events(input: &amp;str) -&gt; LexgenIteratorAdapter {
    LexgenIteratorAdapter {
        lexer: Lexer::new(input),
    }
}

// An adapter is necessary to convert lexgen values to `parse_events` items.
pub struct LexgenIteratorAdapter&lt;&#39;a&gt; {
    lexer: Lexer&lt;&#39;a, std::str::Chars&lt;&#39;a&gt;&gt;,
}

impl&lt;&#39;a&gt; Iterator for LexgenIteratorAdapter&lt;&#39;a&gt; {
    type Item = Result&lt;ParseEvent, ParseError&gt;;

    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {
        ...
    }
}

struct LexerState {
    container_stack: Vec&lt;Container&gt;,
}

lexgen::lexer! {
    Lexer(LexerState) -&gt; ParseEvent;

    type Error = &amp;&#39;static str;

    let comment = &quot;//&quot; (_ # &#39;\n&#39;)* &#39;\n&#39;;

    rule Init {
        $$ascii_whitespace,

        $comment =&gt; comment,

        &#39;[&#39; =&gt; ...,

        &#39;]&#39; =&gt; ...,

        &#39;{&#39; =&gt; ...,

        &quot;true&quot; =&gt; ...,

        &quot;false&quot; =&gt; ...,

        &quot;null&quot; =&gt; ...,

        [&#39;0&#39;-&#39;9&#39;]+ =&gt; ...,

        &#39;&quot;&#39; (_ # &#39;&quot;&#39;)* &#39;&quot;&#39; =&gt; ...
    }

    rule Done { ... }

    rule ArrayExpectComma { ... }

    rule ObjectExpectKeyValue { ... }

    rule ObjectExpectColon { ... }

    rule ObjectExpectComma { ... }
}</code></pre>
<p>This uses <a href="https://github.com/osa1/lexgen">lexgen</a>. lexgen generates slightly different values than what we want, so we have a <code>map</code> in the entry point to convert the lexgen values.</p>
<p>The main difference between an event parser and lexer is that an event parser maintains some of the structure of the parsed format. For example, we check that brackets are balanced, after a key in a map a colon follows, and so on.</p>
<p>A lexer generator can be used to implement an event parser, as demonstrated above.</p>
<hr />
<h1 id="references-and-benchmarks">References and benchmarks</h1>
<p>All of the code in this blog post, and more, is here: <a href="https://github.com/osa1/how-to-parse">github.com/osa1/how-to-parse</a>.</p>
<p>In the benchmark program (run with <code>cargo bench</code>), we generate a 10M large JSON, and parse it to either an AST or a vector of events.</p>
<p><strong>AST building benchmarks:</strong></p>
<ul>
<li><p>Recursive descent: the recursive descent parser that generates an AST.</p>
<p>Throughput: 128 Mb/s.</p></li>
<li><p>Event generator to AST: the iterator-style event generator, events processed by <code>event_to_tree</code> to build an AST.</p>
<p>Throughput: 138 Mb/s.</p></li>
<li><p>Lexgen event to AST: same as above, but the event parser is implemented with lexgen.</p>
<p>Throughput: 106 Mb/s.</p></li>
<li><p>Push event parser to AST: the “push” event parser, <code>AstBuilderListener</code> as the event listener.</p>
<p>Throughput: 147 Mb/s.</p></li>
</ul>
<p><strong>Event generation benchmarks:</strong> (collect events in a <code>Vec</code>)</p>
<ul>
<li><p>Parse events: the iterator-style event generator.</p>
<p>Throughput: 274 Mb/s.</p></li>
<li><p>Parse events lexgen: the lexgen-generated event generator.</p>
<p>Throughput: 179 Mb/s.</p></li>
<li><p>Parse events via push: the push event parser, events added to a <code>Vec</code> via by the listener.</p>
<p>Throughput: 304 Mb/s.</p></li>
</ul>
<p><strong>Notes:</strong></p>
<ul>
<li><p>lexgen-generated event parser is the slowest, but I think it should be possible to make it perform at least as good as the hand-written one. So far I’ve spent very little time to optimize lexgen’s code generator.</p></li>
<li><p>Push-based implementation is faster than the iterator-style implementation, both for generating events in a list, and also for building an AST.</p>
<p>The main advantage of the push-based implementation is that the control flow is as simple as the recursive descent parsing (contained within parse functions, as opposed to externally in a struct), as it does all of the parsing in one go. It looks like managing the parser state externally in a struct is not free.</p></li>
<li><p>I think the tradeoffs between the push-based and iterator implementations will be different in most high-level languages without control over allocations and monomorphisation.</p>
<ul>
<li><p>In the Rust implementation, events are stack allocated values, which will be heap-allocated objects in some of the other languages.</p></li>
<li><p>In the push-based implementation, the parser is monomorphised based on the listener type. Both the listener and parser are stack allocated. All event handler method calls are direct calls (as opposed to virtual, or via some other dynamic invocation method), which can be inlined. None of these will be the case in, e.g., Haskell and Dart.</p></li>
</ul>
<p>It would be interesting to implement the same in some other languages to see how they perform relative to each other.</p></li>
<li><p>I’m not sure why the recursive descent parser is not at least as fast as the push-based implementation, and not faster than the iterator-style one. If you have any insights into this, please let me know.</p></li>
</ul>
<h1 id="more-use-cases">More use cases</h1>
<p>The use cases described at the beginning of the post are all extracted from real-world use cases of various other formats.</p>
<p>Here are more use cases that require flexible and fast parser design:</p>
<ul>
<li><p>“Outline” views in text editors or online code browsing tools may want to process top-level definitions, and definitions nested in <code>class</code>, <code>impl</code>, and similar blocks. Parsing the whole file to an AST would be inefficient.</p></li>
<li><p>Syntax-aware code search tools like <a href="https://github.com/osa1/sg">sg</a> can implement searching only in identifiers, string literals, comments with an event-based parser. This could also be implemented with a lexer.</p></li>
<li><p>As mentioned in a <a href="https://osa1.net/posts/2024-11-04-resumable-exceptions.html">previous post</a>, ideally a formatter, language server, compiler, and refactoring tools, should reuse as much parsing code as possible. It’s difficult to do this with an AST parser, as the AST would have too much information for each of these tools. Event-based parsing makes this easier.</p></li>
</ul>
<h1 id="event-parsing-examples-from-programming-languages">Event parsing examples from programming languages</h1>
<p>I think event-driven parsing is common in some languages when parsing data formats like XML, but less common for parsing programming languages. Two examples that I’m aware of that applies the ideas to programming languages:</p>
<ul>
<li><p>rust-analyzer’s parser is <a href="https://github.com/rust-lang/rust-analyzer/blob/c0bbbb3e5d7d1d1d60308c8270bfd5b250032bb4/docs/dev/architecture.md#cratesparser">a hand written one that generates events</a>. The architecture documentation mentions that Kotlin uses a similar idea:</p>
<blockquote>
<p>It is a hand-written recursive descent parser, which produces a sequence of events like “start node X”, “finish node Y”. It works similarly to kotlin’s parser, which is a good source of inspiration for dealing with syntax errors and incomplete input</p>
</blockquote></li>
<li><p>Dart’s parser <a href="https://github.com/dart-lang/sdk/blob/19da943583e020e96026f797904dc5c6b993d4ac/pkg/_fe_analyzer_shared/lib/src/parser/listener.dart#L35-L46">uses the push-based API</a>. This parser is the only Dart language parser used by the SDK. It’s used by the analyzer, language server, compilers, and anything else that the SDK includes.</p></li>
</ul>]]></summary>
</entry>
<entry>
    <title>Resumable exceptions</title>
    <link href="http://osa1.net/posts/2024-11-04-resumable-exceptions.html" />
    <id>http://osa1.net/posts/2024-11-04-resumable-exceptions.html</id>
    <published>2024-11-04T00:00:00Z</published>
    <updated>2024-11-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>The main use case of resumable exceptions would be collecting a bunch of errors (instead of bailing out after the first one) to log or show to the user, or actually recovering and continuing from the point of error detection, rather than in a call site.</p>
<p><em>Why not design the code to allow error recovery, instead of using a language feature?</em> There are a few problems with this:</p>
<ul>
<li><p>Without a language feature to do this, libraries will have to implement their own ways to recover from errors, causing inconsistencies and fragmented ecosystem of error handling libraries.</p></li>
<li><p>With resumable exceptions, any code can be trivially made to transfer control to a exception handler, and back. Manually refactoring code to do the same can be a big task. This may even be infeasible.</p></li>
<li><p>With resumable exceptions as a part of the language, libraries will be designed with resumption in mind. Libraries that would normally not allow error recovery will allow error recovery, as it will be easy to do, and it will be a common thing to resume from errors.</p></li>
</ul>
<h1 id="example-use-case-parser-shared-by-a-compiler-and-a-language-server">Example use case: parser shared by a compiler and a language server</h1>
<p>Modern programming languages have complex syntax. Parsers for these languages are often thousands of lines of code.</p>
<p>Ideally, all tooling for a language would share the parser, as it’s a significant amount of work to implement, debug, maintain parsers for such large languages.</p>
<p>However not all of these tools will have the same error handling behavior. A compiler <em>cannot</em> continue in the presence of a parse error, but a language server <em>has to</em> continue.</p>
<p>With resumable exceptions, the compiler can abort after a parse error, the language server can provide placeholder AST nodes for failing parse operations and resume. This flexibility does not make the parser API any more complicated than a parser that throws an exception in any other language. A one-off refactoring script that uses the parser library doesn’t have to deal with error recovery just because the language server, which uses the same parser, needs to recover from parse errors and continue parsing.</p>
<h1 id="types-of-resumable-exceptions">Types of resumable exceptions</h1>
<p>With resumable exceptions <code>throw</code> expressions generate a value. The value depends on the exception type thrown. For example, a <code>FooDecodingException</code> can be resumed with a value of <code>Foo</code> provided by the handler.</p>
<p>This can be implemented with an abstract base class or typeclass/trait with a type parameter:</p>
<pre><code>// in a system with classes:
abstract class ResumableException&lt;Resume&gt; { 
    prim Resume throw();
    prim Never resume(Resume resumptionValue);
}

// or in a system with typeclasses/traits:
trait ResumableException&lt;Resume&gt; {
    prim fn throw(self) -&gt; Resume;
    prim fn resume(resumptionValue: Resume) -&gt; !;
}</code></pre>
<p>Here the <code>prim</code> keyword indicates that the <code>throw</code> and <code>resume</code> methods are provided by the compiler.</p>
<p><code>throw e</code> can then be type checked as <code>e.throw()</code>, and <code>resume e with value</code> can be type checked as <code>e.resume(value)</code>. Or we can use the function call syntax instead of special syntax for throwing and resuming.</p>
<p>Whether to make exceptions thrown by a function a part of its type signature or not is an orthogonal concern.</p>
<h1 id="exception-type-design-considerations">Exception type design considerations</h1>
<p>The same considerations when designing non-resumable exceptions apply to resumable exceptions:</p>
<ul>
<li>The more general an exception type gets, the less you can do with it.</li>
<li>We still want to distinguish “log and stop” kind of exceptions from recoverable ones.</li>
</ul>
<p>For example, it doesn’t make sense to resume from an <a href="https://api.dart.dev/stable/3.5.4/dart-core/ArgumentError-class.html"><code>ArgumentError</code></a>, so we don’t implement <code>ResumableException</code> for it.</p>
<p>To be able to meaningfully resume from an exception, the exception type should document when exactly it is thrown, or have a resumption value type that is specific enough to give an idea on when it is thrown.</p>
<p>For example, an exception that can be resumed with an <code>int</code> cannot be resumed without knowing what that <code>int</code> is going to be used for, so this should be documented. But an exception <code>FooDecodingError implements ResumableException&lt;Foo&gt;</code> makes it clear that it’s thrown when there’s an error during decoding a <code>Foo</code>, and the resumption value is the value to be used as the <code>Foo</code> being decoded.</p>]]></summary>
</entry>
<entry>
    <title>Idea: a more structural code editor</title>
    <link href="http://osa1.net/posts/2024-11-02-structural-editor.html" />
    <id>http://osa1.net/posts/2024-11-02-structural-editor.html</id>
    <published>2024-11-02T00:00:00Z</published>
    <updated>2024-11-02T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Code is tree structured, but manipulated as a sequence of characters.</p>
<p>Most language tools<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> need to convert these sequence of characters to the tree form as the first thing to be able to do anything.</p>
<p>When the program is being edited, the tree structure is often broken, and often to the point where the tool cannot operate.</p>
<p>For example:</p>
<ul>
<li>An opening parenthesis, brace, or bracket, without a matching closing one</li>
<li>An unterminated string literal or multi-line comment</li>
<li>A keyword inserted at a wrong place, or without the right tokens afterwards</li>
</ul>
<p>These can make it impossible to main the tree structure of the code.</p>
<p>Since these cases are common, tools need to deal with these. A lot of time and effort is spent on error recovery so that when one of these common cases occur, the tool can still operate and do something useful.</p>
<p>For some tools handling these cases is a requirement: many of the language server functions need to work even when the code is being edited and not in a valid state. For example, “go to definition” should work, “outline” shouldn’t be reset every time the user inserts an opening brace, bracket, or parenthesis.</p>
<p><em>We can’t invent a new language</em> to solve this problem: this creates a thousand new problems, each bigger than the one we are trying to solve. Designing and implementing a new language is major undertaking on its own. We can’t design and implement a language <em>and</em> an experimental code editor at the same time, and succeed in both.</p>
<p>So we want need to support existing languages, <em>but existing languages are incredibly complex</em>, sometimes with a hundred kinds of statements, expressions, types, and so on.</p>
<p>What I’d like to propose as a solution is a “mostly structural” editor, where programs are edited in a structural way at the highest levels, but as text at the statement and expression level.</p>
<p>The details depend on the language. As an example, let’s consider Rust. In Rust, packages (called “crates”), modules, and the items in modules (function and type definitions) can be defined structurally, because there aren’t a lot of different kinds of top-level declarations. Then in the function (and method) bodies, we write the code as text, as usual.</p>
<p>The advantages of this approach are:</p>
<ul>
<li><p>We avoid inventing a new language. The idea can be applied to most languages.</p></li>
<li><p>Because we isolate invalid syntax to function bodies, no edit can cause syntax errors in the other functions in the same module, or in the other modules and packages.</p></li>
<li><p>Because we define function and method signatures separately from function/method bodies, syntax errors cannot invalidate types and cannot generate type errors outside of the function being edited.</p></li>
<li><p>For the same reason as above, “outline” view in the IDE is never broken. Functions like “go to definition” and “find references” always work.</p></li>
</ul>
<p>As for the GUI part, I imagine an editor “pane” for each function being edited. I should be able to quickly switch between functions (maybe with a fuzzy search similar to <code>ctrl-p</code> in some editors), and when working on a function I should be able to quickly open documentation or definitions of the symbols used in the function, in new panes. I imagine there will be a lot of panes open at any time. This may require a solution like a tiling window manager to quickly arrange them and switch between them.</p>
<p>This problem is not new, I do a lot of buffer/split management every day while coding, and almost never use just a single editor window. However with each pane editing just one function, there will be a lot of splits and panes. Some creativity will be needed here to make managing these panes easy for the users.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>I’m not aware of any language tool that doesn’t need to parse the source. Please let me know if you know such tools.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></summary>
</entry>
<entry>
    <title>Subtyping and subsumption</title>
    <link href="http://osa1.net/posts/2024-10-21-subtyping-subsumption.html" />
    <id>http://osa1.net/posts/2024-10-21-subtyping-subsumption.html</id>
    <published>2024-10-21T00:00:00Z</published>
    <updated>2024-10-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Subtyping is a relation between two types. It often comes with a typing rule called “subsumption”, which says that if type B is a subtype of type A (usually shown as <code>B &lt;: A</code>), then a value of type B can be assumed to have type A.</p>
<p>The crucial part is that subsumption is <em>implicit</em>, the programmer doesn’t explicitly cast the value with type <code>B</code> to type <code>A</code>.</p>
<p>When we make an operation implicit in a language, we need to make sure that it is (1) safe (2) performant. Users will be doing it without realizing, and we don’t want to accidentally break things or make them slow.</p>
<p>Let’s consider how we can make subsumption safe and performant.</p>
<h1 id="safety-of-subsumption">Safety of subsumption</h1>
<p>Different languages give different safety guarantees. High-level languages often guarantee:</p>
<ol type="1">
<li><p>Memory safety: a memory read or write shouldn’t cause undefined behavior.</p>
<p>Examples: out-of-bounds array accesses should be caught, dangling pointers shouldn’t be allowed or dereferencing them should be caught in runtime.</p></li>
<li><p>Type safety: static guarantees of the language’s type system should be uphold.</p>
<p>Example: if I have a function <code>f : A -&gt; B</code> and a value <code>x : A</code> after subsumption, <code>f(x)</code> shouldn’t fail in compile time or runtime.</p></li>
</ol>
<p>There could be different safeties that the language guarantees. Some of those safeties may also be checked in runtime instead of compile time.</p>
<p>Whatever safeties the language guarantees, they must be preserved with subsumption.</p>
<p>From a programmer’s perspective however, these are not enough to make sure that the program will work as before when subsumption is used. If I can pass a value of type <code>B</code> where <code>A</code> is expected, I need to make sure <code>B</code>, when used as <code>A</code>, acts like <code>A</code>.</p>
<p>This is called “behavioral subtyping” (or “substitutability”), and it depends on not the types of <code>A</code>’s operations but the observable behaviors of <code>A</code> and its subtypes.</p>
<p>I don’t have a good real-world example of this, but you can imagine two types with the same public APIs that work differently. Since the public APIs are the same one can be made subtype of the other and (1) and (2) would still be satisfied, but doing that would cause bugs when one is accidentally passed as the other.</p>
<h1 id="performance-of-subsumption">Performance of subsumption</h1>
<p>Definition of “fast” or “performant” also depends on the language. A C++ programmer’s fast and Python programmer’s fast are often not the same.</p>
<p>However in general, heap allocation should be avoided.</p>
<p>Object-oriented languages (as defined in my <a href="https://osa1.net/posts/2024-10-09-oop-good.html">previous post</a>) without multiple inheritance can often implement subsumption of reference values as no-op, i.e. values of type <code>B</code> work as <code>A</code> in runtime without any changes or copying.</p>
<p>Multiple inheritance makes things more complicated, but a reference to an object can still be converted to a reference of one of its supertypes by just <a href="https://people.montefiore.uliege.be/declercq/INFO0004/documents/vtable.html">adjusting the pointer value</a>.</p>
<p>With unboxed/value types, conceptually, the value needs to be copied as its supertype, but that operation is often no-op. Consider an unboxed record <code>(x: Int, y: Int, z: Int)</code> that we store in a variable <code>a</code>. In runtime, <code>a</code> actually holds multiple stack locations or registers. When we copy it as <code>let b: (x: Int, y: Int) = a</code>, we don’t have to allocate new stack locations for <code>b.x</code> and <code>b.y</code>, we just map those locations to the same locations as <code>a.x</code> and <code>a.y</code>. When we pass <code>b</code> to a function, we pass <code>a.x</code> and <code>a.y</code>.</p>
<p>Where copying becomes a requirement and prohibitive is when you have something like <code>ReadOnlyList&lt;(x: Int, y: Int, z: Int)&gt;</code> and want to upcast it to <code>ReadOnlyList&lt;(x: Int, y: Int)&gt;</code> (the records are unboxed). From the safety perspective this operation is fine, but you have to allocate a new list and copy all the values.</p>
<p>I think this is rarely a problem in practice though, because most generic types, like <code>List&lt;T&gt;</code>, end up being invariant in <code>T</code> anyway, because their API often uses <code>T</code> in both covariant and contravariant positions. So <code>List&lt;(x: Int, y: Int)&gt;</code> is not a supertype of <code>List&lt;(x: Int, y: Int, z: Int)&gt;</code> and subsumption does not apply.</p>
<h1 id="no-conclusions-this-time">No conclusions this time</h1>
<p>In this short post I just wanted to give some definitions that I’m hoping to refer to in future posts.</p>]]></summary>
</entry>
<entry>
    <title>OOP is not that bad, actually</title>
    <link href="http://osa1.net/posts/2024-10-09-oop-good.html" />
    <id>http://osa1.net/posts/2024-10-09-oop-good.html</id>
    <published>2024-10-09T00:00:00Z</published>
    <updated>2024-10-09T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>OOP is certainly not my favorite paradigm, but I think mainstream statically-typed OOP does a few things right that are very important for programming with many people, over long periods of time.</p>
<p>In this post I want to explain what I think is the most important one of these things that the mainstream statically-typed OOP languages do well.</p>
<p>I will then compare the OOP code with Haskell, to try to make the point that OOP is not as bad in everything as some functional programmers seem to think.</p>
<h1 id="what-even-is-oop">What even is OOP?</h1>
<p>In this post I use the word “OOP” to mean programming in statically-typed language with:</p>
<ol type="1">
<li>Classes, that combine state and methods that can modify the state.</li>
<li>Inheritance, which allows classes to reuse state and methods of other classes.</li>
<li>Subtyping, where if a type <code>B</code> implements the public interface of type <code>A</code>, values of type <code>B</code> can be passed as <code>A</code>.</li>
<li>Virtual calls, where receiver class of a method call is not determined by the static type of the receiver but its runtime type.</li>
</ol>
<p>Examples of OO languages according to this definition: C++, Java, C#, Dart.</p>
<h1 id="an-example-of-what-this-allows">An example of what this allows</h1>
<p>This set of features allows a simple and convenient way of developing composable libraries, and extending the libraries with new functionality in a backwards compatible way.</p>
<p>It’s probably best explained with an example. Suppose we have a simple logger library:</p>
<pre><code>class Logger {
  // Private constructor: initializes state, returns an instance of `Logger`.
  Logger._();

  // Public factory: can return `Logger` or any of the subtypes.
  factory Logger() =&gt; Logger._();

  void log(String message, Severity severity) { /* ... */ }
}

enum Severity {
  Info,
  Error,
  Fatal,
}</code></pre>
<p>and another library that does some database stuff:</p>
<pre><code>class DatabaseHandle {
  /* ... */
}</code></pre>
<p>and an application that uses both:</p>
<pre><code>class MyApp {
  final Logger _logger;
  final DatabaseHandle _dbHandle;

  MyApp()
      : _logger = Logger(),
        _dbHandle = DatabaseHandle(...);
}</code></pre>
<p>As is usually the case, things that make network connections, change shared state etc. need to be mocked, faked, or stubbed to be able to test applications. We may also want to extend the libraries with new functionality. With the features that we have, we don’t have to see this coming and prepare the types based on this.</p>
<p>In the first iteration we might just add a concrete class that is just the copy of the current class, and make the current class abstract:</p>
<pre><code>// The class is now abstract.
abstract class Logger {
  // Public factory now returns an instance of a concrete subtype.
  factory Logger() =&gt; _SimpleLogger();

  Logger._();

  // `log` is now abstract.
  void log(String message, Severity severity);
}

class _SimpleLogger extends Logger {
  factory _SimpleLogger() =&gt; _SimpleLogger._();

  _SimpleLogger._() : super._() {/* ... */}

  @override
  void log(String message, Severity severity) {/* ... */}
}</code></pre>
<p>This change is backwards compatible, requires no changes in user code.</p>
<p>Now we might add more implementations, e.g. for ignoring log messages:</p>
<pre><code>abstract class Logger {
  factory Logger() =&gt; _SimpleLogger();

  // New.
  factory Logger.ignoring() =&gt; _IgnoringLogger();

  Logger._();

  void log(String message, Severity severity);
}

class _IgnoringLogger extends Logger {
  factory _IgnoringLogger() =&gt; _IgnoringLogger._();

  _IgnoringLogger._() : super._() {}

  @override
  void log(String message, Severity severity) {}
}</code></pre>
<p>Similarly we can add a logger that logs to a file, to a DB, etc.</p>
<p>We can do the same for the database handle class, but for mocking, faking, or stubbing, in tests.</p>
<p>To be able to use these new subtypes in our app, we implement a factory, or add a constructor to allow passing a logger and a db handle:</p>
<pre><code>class MyApp {
  final Logger _logger;
  final DatabaseHandle _dbHandle;

  MyApp()
      : _logger = Logger(),
        _dbHandle = DatabaseHandle();

  MyApp.withLoggerAndDb(this._logger, this._dbHandle);
}</code></pre>
<p>Note that we did not have to change any types, or add type parameters. Any methods of <code>MyApp</code> that use the <code>_logger</code> and <code>_dbHandle</code> fields do not have to know about the changes.</p>
<p>Now suppose one of the <code>DatabaseHandle</code> implementations also start using the logger library:</p>
<pre><code>abstract class DatabaseHandle {
  factory DatabaseHandle.withLogger(Logger logger) =&gt;
      _LoggingDatabaseHandle._(logger);

  factory DatabaseHandle() =&gt; _LoggingDatabaseHandle._(Logger.ignoring());

  DatabaseHandle._();

  /* ... */
}

class _LoggingDatabaseHandle extends DatabaseHandle {
  final Logger _logger;

  _LoggingDatabaseHandle._(this._logger) : super._();

  /* ... */
}</code></pre>
<p>In our app, we might test by disabling logging in the db library, but start logging db operations in production:</p>
<pre><code>class MyApp {
  // New
  MyApp.testingSetup()
      : _logger = Logger(),
        _dbHandle = DatabaseHandle.withLogger(Logger.ignoring());

  // Updated to start using the logging feature of the DB library.
  MyApp()
      : _logger = Logger(),
        _dbHandle = DatabaseHandle.withLogger(Logger.toFile(...));

  /* ... */
}</code></pre>
<p>As an example that adds more state to the types, we can add a logger implementation that only logs messages above certain severity:</p>
<pre><code>class _LogAboveSeverity extends _SimpleLogger {
  // Only logs messages with this severity or more severe.
  final Severity _severity;

  _LogAboveSeverity(this._severity) : super._();

  @override
  void log(String message, Severity severity) { /* ... */ }
}</code></pre>
<p>We can add another factory to the <code>Logger</code> abstract class that returns this type, or we can even implement this in another library:</p>
<pre><code>// Implemented in another library, not in `Logger`&#39;s library.
class LogAboveSeverity implements Logger {
  // Only logs messages with this severity or more severe.
  final Severity _severity;

  final Logger _logger;

  LogAboveSeverity(this._severity) : _logger = Logger();

  LogAboveSeverity.withLogger(this._severity, this._logger);

  @override
  void log(String message, Severity severity) { /* ... */ }
}</code></pre>
<p>As a final example to demonstrate adding more operations (rather than more state), we can have a logger that logs to a file, with a <code>flush</code> operation:</p>
<pre><code>class FileLogger implements Logger {
  final File _file;

  FileLogger(this._file);

  @override
  void log(String message, Severity severity) {/* ... */}

  void flush() {/* ... */}
}</code></pre>
<p>In summary:</p>
<ul>
<li>We started with a simple logging and database library and wrote an app.</li>
<li>We added more capabilities to the logging and database libraries for testing and also in production use. In particular, we added:
<ul>
<li>New functionality to the logger library, to disable logging, or logging to a file.</li>
<li>A new dependency to the database library for logging database operations. We also allowed the users to override the default logger used.</li>
</ul></li>
</ul>
<p>Crucially, we didn’t have to change any types while doing these changes, and the new code is still as type safe as before.</p>
<p>The logger and database libraries evolved in a completely backwards compatible way.</p>
<p>Since none of the types used in our application changed, <code>MyApp</code> methods didn’t have to change at all.</p>
<p>When we decide to take advantage of the new functionality, we updated only how we construct the logger and db handle instances in our app. Rest of the app didn’t change.</p>
<p>Now let’s consider how something like this could be done in Haskell.</p>
<h1 id="attempting-it-in-haskell">Attempting it in Haskell</h1>
<p>Immediately at the start, we have a few choices on how to represent it.</p>
<p><strong>Option 1:</strong> An ADT, with callback fields to be able to add different types of loggers later:</p>
<pre><code>data Logger = MkLogger
    { _log :: Message -&gt; Severity -&gt; IO ()
    }

simpleLogger :: IO Logger

data Severity = Info | Error | Fatal
    deriving (Eq, Ord)

log :: Logger -&gt; String -&gt; Severity -&gt; IO ()</code></pre>
<p>In this representation, extra state like the minimum severity level in our <code>_LogAboveSeverity</code> is not added to the type, but captured by the closures:</p>
<pre><code>logAboveSeverity :: Severity -&gt; IO Logger
logAboveSeverity minSeverity = MkLogger
    { _log = \message severity -&gt; if severity &gt;= minSeverity then ... else pure ()
    }</code></pre>
<p>If we need to update some of the state shared by the closures, the state needs to be stored in some kind of reference type like <code>IORef</code>.</p>
<p>Similar to the OOP code, the <code>FileLogger</code> needs to be a separate type:</p>
<pre><code>data FileLogger = MkFileLogger
  { _logger :: Logger   -- callbacks capture the file descriptor/buffer and write to it
  , _flush  :: IO ()    -- similarly captures the file descriptor/buffer, flushes it
  }

logFileLogger :: FileLogger -&gt; String -&gt; Severity -&gt; IO ()
logFileLogger = log . _logger</code></pre>
<p>However, unlike our OOP example, existing code that uses the <code>Logger</code> type and <code>log</code> function cannot work with this new type. There needs to be some refactoring, and how the user code will need to be refactored depends on how we want to expose this new type to the users.</p>
<p><strong>Option 2:</strong> A typeclass that we can implement for our concrete logger types:</p>
<pre><code>class Logger a where
    log :: a -&gt; String -&gt; Severity -&gt; IO ()

data SimpleLogger = MkSimpleLogger { ... }

simpleLogger :: IO SimpleLogger
simpleLogger = ...

instance Logger SimpleLogger where
  log = ...</code></pre>
<p>To allow backwards-compatible changes in the logger library, we need to hide the concrete logger class:</p>
<pre><code>module Logger
    ( Logger
    , simpleLogger -- I can export this without exporting its return type
    ) where

...</code></pre>
<p>With this module, we have to either add a type parameter to the functions and other types that use <code>Logger</code>, or use existentials.</p>
<p>Adding a type parameter is not a backwards compatible change, and in general it can cause snowball effect of propagating the type parameter to the direct users, and then their users, and so on, creating a massive change and difficult to use types.</p>
<p>The problem with existentials is that they are limited in how you can use them, and are somewhat strange in some areas. In our application we can do this:</p>
<pre><code>data MyApp = forall a . Logger a =&gt; MkMyApp
  { _logger :: a
  }</code></pre>
<p>But we can’t have a local variable with this existential type:</p>
<pre><code>createMyApp :: IO MyApp
createMyApp = do
  -- I can&#39;t add a type annotation to myLogger without the concrete type
  myLogger &lt;- simpleLogger      -- simpleLogger :: IO SimpleLogger
  return MkMyApp { _logger = myLogger }</code></pre>
<p>I also cannot have an existential type in a function argument:</p>
<pre><code>-- The type signature is accepted by the compiler, but the value cannot be used.
doStuffWithLogging :: (forall a . Logger a =&gt; a) -&gt; IO ()
doStuffWithLogging logger = log logger &quot;test&quot; Info -- some obscure type error</code></pre>
<p>Instead we have to “pack” the logger value with its typeclass dictionary in a new type:</p>
<pre><code>data LoggerBox = forall a . Logger a =&gt; LoggerBox a

doStuffWithLogging :: LoggerBox -&gt; IO ()
doStuffWithLogging (LoggerBox logger) = log logger &quot;test&quot; Info</code></pre>
<p>Other problems and limitations of this approach:</p>
<ul>
<li>The syntax is just awful to the point where it’s deterrent: <code>forall a . Logger a =&gt; ... a ...</code> instead of just <code>Logger</code>.</li>
<li>It allows implementing <code>FileLogger</code>, but
<ul>
<li>All subtypes need to be a new typeclass + an implementation (in OOP: just one class).</li>
<li>This cannot be used for safe downcasting of a <code>Logger</code> value to <code>FileLogger</code>, without knowing the concrete type of the <code>FileLogger</code>.</li>
</ul></li>
</ul>
<h1 id="effect-monad-approach">Effect monad approach</h1>
<p>The effect monad approach is a variation of option (2) without existentials. Instead of</p>
<pre><code>class Logger a where
    log :: a -&gt; String -&gt; Severity -&gt; IO ()</code></pre>
<p>We add the ability to log in a monad type parameter:</p>
<pre><code>class MonadLogger m where
    log :: String -&gt; Severity -&gt; m ()</code></pre>
<p>Then provide a “monad transformer” for each of the logger implementations:</p>
<pre><code>newtype SimpleLoggerT m a = SimpleLoggerT { runSimpleLoggerT :: m a }

instance MonadIO m =&gt; MonadLogger (SimpleLoggerT m) where
  log msg sev = SimpleLoggerT { runSimpleLoggerT = liftIO (logStdout msg sev) }

newtype FileLoggerT m a = FileLoggerT { runFileLoggerT :: Handle -&gt; m a }

instance MonadIO m =&gt; MonadLogger (FileLoggerT m) where
  log msg sev = FileLoggerT { runFileLoggerT = \handle -&gt; liftIO (logFile handle msg sev) }</code></pre>
<p>The database library does the same, and the app combines these together:</p>
<pre><code>newtype MyAppMonad a = ...

instance MonadLogger MyAppMonad where ...

instance MonadDb MyAppMonad where ...</code></pre>
<p>Because we have one type parameter that encapsulates all side effects (instead of one for logging, one for database operations), this avoids the issues with snowballed type parameters in the use sites.</p>
<p>The database library can also add a logger dependency without breaking the user code.</p>
<p>I think this is the best we can get in Haskell, and it’s quite similar to our OOP solution in terms of code changes needed to be done in the user code.</p>
<p>However for this to work the entire ecosystem of libraries need to do things this way. If the database library decides to use the ADT approach, we will need an “adapter”, e.g. a monad typeclass for the DB operations, with a concrete monad transformer type to call the DB library functions.</p>
<p>This is also the main problem with the composable effects libraries.</p>
<p>(There are also issues with how this kind of code performs in runtime, but that’s probably a topic for another blog post.)</p>
<h1 id="composable-effects">Composable effects</h1>
<p>Haskellers have been developing various ways of modelling side effects (such as DB operations, logging) as “effects” and various ways of composing them.</p>
<p>A simple and widespread way of doing this is via the effect monads, as we’ve seen in the previous section.</p>
<p>However these systems have a few drawbacks, compared to our OOP solution:</p>
<ul>
<li><p>Different effect libraries generally don’t work together. For example, <a href="https://hackage.haskell.org/package/mtl">mtl</a> and <a href="https://github.com/hasura/eff">eff</a> functions won’t work together without some kind of adapter turning one into the other.</p></li>
<li><p>Even if the entire Haskell ecosystem decides to use one particular effect system, things like using two different handlers for different parts of the program, such as the example of using different logger in the db library and the main app, requires type juggling. In some effect libraries this is not even possible.</p></li>
<li><p>Finally, note that the OOP code shown in this post are very basic and straightforward code that even a beginner in OOP can write. Any new person who joins the project, or any one time contributor who just wants to fix a bug and move on, will be able to work on either one of the libraries or the application code. It’s difficult to say the same with the composable effects libraries in Haskell.</p></li>
</ul>
<h1 id="conclusions">Conclusions</h1>
<p>Mainstream statically-typed OOP allows straightforward backwards compatible evolution of types, while keeping them easy to compose. I consider this to be one of the killer features of mainstream statically-typed OOP, and I believe it is an essential feature for programming with many people, over long periods of time.</p>
<p>Just like OOP, Haskell has design patterns, such as the effect monad pattern we’ve shown above. Some of these design patterns solve the problem nicely, but they need an entire ecosystem to follow the same pattern to be useful.</p>
<p>I think it would be beneficial for the functional programming community to stop dismissing OOP’s successes in the industry as an accident of history and try to understand what OOP does well.</p>
<hr />
<p>Thanks to Chris Penner and Matthías Páll Gissurarson for reviewing a draft of this blog post.</p>]]></summary>
</entry>
<entry>
    <title>My thoughts on OCaml</title>
    <link href="http://osa1.net/posts/2023-04-24-ocaml-thoughts.html" />
    <id>http://osa1.net/posts/2023-04-24-ocaml-thoughts.html</id>
    <published>2023-04-24T00:00:00Z</published>
    <updated>2023-04-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Since 2013 I’ve had the chance to use OCaml a few times in different jobs, and I got frustrated and disappointed every time I had to use it. I just don’t enjoy writing OCaml.</p>
<p>In this post I want to summarize some of the reasons why I don’t like OCaml and why I wouldn’t choose it for a new project today.</p>
<h1 id="no-standard-and-easy-way-of-implementing-interfaces">No standard and easy way of implementing interfaces</h1>
<p>To me it’s absolutely essential that the language should have some way of defining interfaces, implementing those interfaces for the types, and programming against those interfaces.</p>
<p>In Haskell, this is done with typeclasses. Rust has a similar mechanism called traits. In languages with classes this is often done with abstract classes and “implementing” those classes in new classes (e.g. <code>implements</code> in Dart).</p>
<p>In OCaml there’s no way to do this. I have to explicitly pass functions along with my values, maybe in a product type, or with a functor, or as an argument.</p>
<p>Regardless of how I work around this limitation, it’s extremely inconvenient. Things that must be trivial in any code base, such as converting a value to a string for debugging purposes, become a chore, and sometimes even impossible.</p>
<p>As far as I know, there was at least one attempt at ameliorating this with modular implicits (implicit parameter passing), but I don’t know what happened to it since 2017. It looks like it’s still not a part of the language and the standard library is not using it.</p>
<h1 id="bad-standard-library">Bad standard library</h1>
<p>OCaml’s standard library is just bizarre. It has lots of small issues, and a few larger ones. It’s really just extremely painful to use.</p>
<p>Some examples of the issues:</p>
<ul>
<li><p>Zoo of printing/debugging and conversion functions such as <code>string_of_int</code>, <code>string_of_float</code>, <code>print_char</code>, <code>Int64.of_int</code>, <code>string_of_int</code>, …</p></li>
<li><p>Overly polymorphic operators with type <code>'a -&gt; 'a -&gt; bool</code> such as <code>=</code> (called “structural equality”, throws an exception if you pass a function) and <code>&gt;</code>. Code that uses these operators will probably not work on user-defined types as expected.</p></li>
<li><p>Standard types are sometimes persistent, sometimes mutable. <code>List</code>, <code>Map</code>, and <code>Set</code> are persistent. <code>Stack</code> and <code>Hashtbl</code> are mutable.</p></li>
<li><p>Inconsistent naming:</p>
<ul>
<li>Length function for <code>Map</code> is <code>cardinal</code>, length function for <code>Hashtbl</code> is <code>length</code>.</li>
<li>The “bytes” type is <code>Bytes.t</code>, the big int type is <code>Big_int.big_int</code> (instead of <code>Big_int.t</code>). The functions in these modules are also inconsistently named. <code>Big_int</code> functions are suffixed with <code>_big_int</code>, <code>Bytes</code> module functions are not prefixed or suffixed.</li>
</ul></li>
<li><p>The regex module uses global state: <code>string_match</code> runs a regex and sets some global state. <code>matched_string</code> returns the last matched string using the global state.</p></li>
<li><p>Lack of widely used operations such as <code>popcount</code> for integer types, unicode character operations.</p></li>
<li><p>It doesn’t have proper string and character types: <code>String</code> is a byte array, <code>char</code> is a byte.</p></li>
</ul>
<p>The bad state of OCaml’s standard library also causes fragmentation in the ecosystem with two competing alternatives: <a href="https://opensource.janestreet.com/core/">Core</a> and <a href="https://github.com/ocaml-batteries-team/batteries-included">Batteries</a>.</p>
<h1 id="syntax-problems">Syntax problems</h1>
<p>OCaml doesn’t have a single-line comment syntax.</p>
<p><a href="https://v2.ocaml.org/manual/expr.html">The expression syntax</a> has just too many issues. It’s inconsistent in how it uses delimiters. <code>for</code> and <code>while</code> end with <code>end</code>, but <code>let</code>, <code>if</code>, <code>match</code>, and <code>try</code> don’t, even though the right-most non-terminal is the same in all of these productions:</p>
<pre><code>expr ::= ...
      | while &lt;expr&gt; do &lt;expr&gt; done
      | for &lt;value-name&gt; = &lt;expr&gt; ( to | downto ) &lt;expr&gt; do &lt;expr&gt; done
      | let &lt;let-binding&gt; in &lt;expr&gt;
      | if &lt;expr&gt; then &lt;expr&gt; [ else &lt;expr&gt; ]
      | match &lt;expr&gt; with (| &lt;pattern&gt; [ when &lt;expr&gt; ] -&gt; &lt;expr&gt;)+
      | try &lt;expr&gt; with (| &lt;pattern&gt; [ when &lt;expr&gt; ] -&gt; &lt;expr&gt;)+
      ...</code></pre>
<p>It has <code>for</code> and <code>while</code>, but no <code>break</code> and <code>continue</code>. So you use exceptions with a <code>try</code> inside the loop for <code>continue</code>, and outside for <code>break</code>.</p>
<p>It also has lots of ambiguities, and some of these ambiguities are resolved in an unintuitive way. In addition to making OCaml <a href="https://github.com/ocaml/ocaml/blob/063894d3fa8f63fedf6959744510e1635dccb3ca/parsing/parser.mly#L798-L837">difficult to parse correctly</a>, this can actually cause incorrect reading of the code.</p>
<p>Most common example is probably nesting <code>match</code> and <code>try</code> expressions:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="kw">match</span> e0 <span class="kw">with</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>| p1 -&gt; <span class="kw">try</span> e1 <span class="kw">with</span> p2 -&gt; e2</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>| p3 -&gt; e3</span></code></pre></div>
<p>Here <code>p3 -&gt; e3</code> is a part of the <code>try</code> expression.</p>
<p>Another example is the sequencing syntax <code>&lt;expr&gt; ; &lt;expr&gt;</code> and productions with <code>&lt;expr&gt;</code> as the right-most symbol:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="kw">let</span> test1 b =</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>  <span class="kw">if</span> b <span class="kw">then</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a>    <span class="dt">print_string</span> <span class="st">&quot;1&quot;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>  <span class="kw">else</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a>    <span class="dt">print_string</span> <span class="st">&quot;2&quot;</span>; <span class="dt">print_string</span> <span class="st">&quot;3&quot;</span></span></code></pre></div>
<p>Here <code>print_string "3"</code> is not a part of the <code>if</code> expression, so this function always prints “3”.</p>
<p>However, even though <code>match</code> also has <code>&lt;expr&gt;</code> as the right-most symbol, it has different precedence in comparison to semicolon:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="kw">let</span> test2 b =</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a>  <span class="kw">match</span> b <span class="kw">with</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a>  | <span class="kw">true</span> -&gt; <span class="dt">print_string</span> <span class="st">&quot;1&quot;</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>  | <span class="kw">false</span> -&gt; <span class="dt">print_string</span> <span class="st">&quot;2&quot;</span>; <span class="dt">print_string</span> <span class="st">&quot;3&quot;</span></span></code></pre></div>
<p>Here <code>print_string "3"</code> is a part of the <code>false -&gt; ...</code> branch.</p>
<p>Try to guess how these functions are parsed:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="co">(* Is the last print part of `else` or not? *)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a><span class="kw">let</span> test3 b =</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a>  <span class="kw">if</span> b <span class="kw">then</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a>    <span class="dt">print_string</span> <span class="st">&quot;1&quot;</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a>  <span class="kw">else</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a>    <span class="kw">let</span> x = <span class="st">&quot;2&quot;</span> <span class="kw">in</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a>    <span class="dt">print_string</span> x;</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a>    <span class="dt">print_string</span> <span class="st">&quot;3&quot;</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true"></a><span class="co">(* Is this well-typed? *)</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true"></a><span class="kw">let</span> test4 b =</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true"></a>  <span class="kw">if</span> b <span class="kw">then</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true"></a>    <span class="dv">1</span>, <span class="dv">2</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true"></a>  <span class="kw">else</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true"></a>    <span class="dv">3</span>, <span class="dv">4</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true"></a><span class="co">(* Is the type of this `(int * int) array -&gt; unit` or `int array -&gt; unit * int`? *)</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true"></a><span class="kw">let</span> test5 a = a.(<span class="dv">0</span>) &lt;- <span class="dv">1</span>, <span class="dv">2</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true"></a><span class="co">(* What if I replace `,` with `;`? Does this set the element 1 or 2? *)</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true"></a><span class="kw">let</span> test6 a = a.(<span class="dv">0</span>) &lt;- <span class="dv">1</span>; <span class="dv">2</span></span></code></pre></div>
<p>When writing OCaml you have to keep these rules in mind.</p>
<p>It also has <a href="https://en.wikipedia.org/wiki/Dangling_else">the “dangling else” problem</a>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a><span class="co">(* Is `else` part of the inner `if` or the outer? *)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a><span class="kw">if</span> e1 <span class="kw">then</span> <span class="kw">if</span> e2 <span class="kw">then</span> e3 <span class="kw">else</span> e4</span></code></pre></div>
<p>Finally, and I think this is probably the most strange thing about OCaml’s syntax and I’m not even sure what’s exactly happening here (I can’t find anything relevant in the language documentation), comments in OCaml are somehow tokenized and those tokens need to be terminated. They can be terminated inside another comment, or even outside. This is a bit difficult to explain but here’s a simple example:</p>
<pre><code>(* &quot; *)
print_string &quot;hi&quot;</code></pre>
<p>OCaml 5.0.0 rejects this program with this error:</p>
<pre><code>File &quot;./test.ml&quot;, line 2, characters 16-17:
2 | print_string &quot;hi&quot;
                    ^
  String literal begins here</code></pre>
<p>From the error message it seems like the <code>"</code> in the comment line actually starts a string literal, which is terminated in the first quote of <code>"hi"</code>. The closing double quote of <code>"hi"</code> thus starts another string literal, which is not terminated.</p>
<p>However that doesn’t explain why this works:</p>
<pre><code>(* &quot; *)
print_string &quot;hi&quot;
(* &quot; *)
print_string &quot;bye&quot;</code></pre>
<p>If my explanation of the previous version were correct this would fail with an unbound <code>hi</code> variable, but it works and prints “bye”!</p>
<h1 id="rest-of-the-package-is-also-not-that-good">Rest of the package is also not that good</h1>
<p>I’m not following developments in OCaml ecosystem too closely, but just two years ago it was common to use Makefiles to build OCaml projects. The language server barely worked on a project with less than 50 kloc. There was no standard way of doing compile-time metaprogramming and some projects even used the C preprocessor (cpp).</p>
<p>Some of these things probably improved in the meantime, but the overall package is still not good enough compared to the alternatives.</p>
<h1 id="but-at-least-its-a-functional-language">But at least it’s a functional language?</h1>
<p>Almost all modern statically typed languages have closures, higher-order functions/methods, lazy streams, and combinators that run efficiently. Persistent/immutable data structures can be implemented even in C.</p>
<p>Also, OCaml has no tracking of side-effects (like in Haskell), and the language and the standard library have lots of features and functions with mutation, such as the array update syntax, mutable record fields, <code>Hashtbl</code>, and the regex module.</p>
<p>The only thing that makes OCaml more “functional” than e.g. Dart, Java, or Rust is that it supports tail calls. While having tail calls is important for functional programming, I would happily give up on tail calls if that means not having the problems listed above.</p>
<p>Also keep in mind that when you mix imperative and functional styles tail calls become less important. For example, I don’t have to implement a stream <code>map</code> function in Dart with a tail call to map the rest of the stream, I can just use a <code>while</code> or <code>for</code> loop.</p>
<h1 id="when-should-i-use-it">When should I use it?</h1>
<p>In my opinion there is no reason to use OCaml in a new project in 2023. If you have a reason to think that OCaml is the best choice for a new project please let me know your use case, I’m genuinely curious.</p>]]></summary>
</entry>
<entry>
    <title>Fast polymorphic record access</title>
    <link href="http://osa1.net/posts/2023-01-23-fast-polymorphic-record-access.html" />
    <id>http://osa1.net/posts/2023-01-23-fast-polymorphic-record-access.html</id>
    <published>2023-01-23T00:00:00Z</published>
    <updated>2023-01-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I like <a href="https://osa1.net/posts/2021-04-10-sums-and-products.html">anonymous records</a> and row polymorphism, but until recently I didn’t know how to generate efficient code for polymorphic record access. In this blog post I will summarize the different compilations of polymorphic record accesses that I’m aware of.</p>
<p>All of the ideas shown in this post can be used to access a record field when the record’s concrete type is not known, but the type system guarantees that it has the accessed field. This includes row polymorphism and record subtyping.</p>
<p>Most of the ideas also work when the record’s type is completely unknown and it may not have the accessed field, but some of the optimizations assume accesses cannot fail. Those optimizations can only be used on statically-typed but polymorphic records.</p>
<p>In some of the examples below I will use row polymorphism.</p>
<hr />
<h1 id="row-polymorphism-and-record-subtyping-briefly">Row polymorphism and record subtyping, briefly</h1>
<p>In this blog post we are interested in a specific application of row polymorphism to records. In short, row polymorphism allows type variables denoting sets of record fields, with their types. For example:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a>f <span class="op">:</span> <span class="ot">∀</span> r <span class="op">.</span> { x <span class="op">:</span> <span class="dt">Int</span>, y <span class="op">:</span> <span class="dt">Int</span> <span class="op">|</span> r } <span class="ot">-&gt;</span> <span class="dt">Int</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>f a <span class="ot">=</span> a<span class="op">.</span>x <span class="op">+</span> a<span class="op">.</span>y</span></code></pre></div>
<p>Here the type variable <code>r</code> ranges over set of rows (or records). This function accepts any record as argument as long as the record has at least <code>x : Int</code> and <code>y : Int</code> fields.</p>
<p>The main difference between row polymorphism and record subtyping is that the type variable <code>r</code> can be used in the right-hand side of an arrow as well, allowing passing the record around without losing its concrete type. For example:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a>mapAB <span class="op">:</span> <span class="ot">∀</span> r <span class="op">.</span> { a <span class="op">:</span> <span class="dt">Int</span>, b <span class="op">:</span> <span class="dt">Int</span> <span class="op">|</span> r } <span class="ot">-&gt;</span> (<span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>) <span class="ot">-&gt;</span> { a <span class="op">:</span> <span class="dt">Int</span>, b <span class="op">:</span> <span class="dt">Int</span> <span class="op">|</span> r }</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>mapAB r f <span class="ot">=</span> { a <span class="ot">=</span> f r<span class="op">.</span>a, b <span class="ot">=</span> f r<span class="op">.</span>b, <span class="op">..</span> r }</span></code></pre></div>
<p>This function takes any record that has <code>a : Int</code> and <code>b : Int</code> fields, and returns a new record with updated <code>a</code> and <code>b</code> fields and the rest of the fields. If I pass it a record with type <code>{ a : Int, b : Int, name : String }</code> I get the same type back.</p>
<p>With subtyping, type of this function would look like:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a>mapAB <span class="op">:</span> { a <span class="op">:</span> <span class="dt">Int</span>, b <span class="op">:</span> <span class="dt">Int</span> } <span class="ot">-&gt;</span> (<span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>) <span class="ot">-&gt;</span> { a <span class="op">:</span> <span class="dt">Int</span>, b <span class="op">:</span> <span class="dt">Int</span> }</span></code></pre></div>
<p>In this version the return type just has <code>a</code> and <code>b</code> fields. Rest of the fields are lost. If I pass this a <code>{ a : Int, b : Int, name : String }</code> I get <code>{ a : Int, b : Int }</code> back. The <code>name</code> field is lost.</p>
<hr />
<p>Without subtyping, when the record type in a field access expression is known, it’s easy to generate efficient code: we use the same offsets used when compiling a record literal with the type.</p>
<p>With subtyping, and with row-polymorphism when the record type is not a concrete record type but is a record type with a row variable, type of <code>r</code> in <code>r.a</code> does not immediately give us where in the record’s payload the field <code>a</code> is.</p>
<p>Let’s look at how we might go about implementing record field access in these cases.</p>
<h1 id="records-as-maps">(0) Records as maps</h1>
<p>I don’t think this idea is used in statically-typed languages, but I wanted to include it for completeness.</p>
<p>We can implement records as maps with string keys. Field access then becomes a map lookup.</p>
<p>This is easy to implement because our language probably already has a map implementation in the standard library.</p>
<p>The disadvantages are:</p>
<ul>
<li><p>Depending on the map implementation, every field access require a <code>O(N)</code> or <code>O(log(N))</code> map lookup.</p></li>
<li><p>Map entries will be stored in a separate memory location (instead of in the record object’s payload), which will require pointer chasing to read the field value.</p></li>
<li><p>Unnecessary memory overhead caused by map fields that are not really necessary for records: such as the <code>capacity</code> and <code>size</code> fields.</p></li>
</ul>
<p>With whole-program compilation, we can improve the constant factors a bit by mapping labels (field names) in the program to unique integers. This way lookups don’t require string hashing or comparison, but this is still slow and memory-inefficient compared to other techniques we will discuss below.</p>
<h1 id="passing-accessors-as-parameters">(1) Passing accessors as parameters</h1>
<p>If you’re familiar with Haskell, this is the Haskell way of implementing row polymorphic records.</p>
<p>The idea is that when we pass a record to a row-polymorphic function, we also pass, implicitly, and as functions, the accessors that the function needs.</p>
<p>In Haskell, type of <code>mapAB</code> we’ve seen above would look like this:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a>mapAB <span class="op">:</span> <span class="ot">∀</span> r <span class="op">.</span> (<span class="dt">HasField</span> r <span class="dt">&#39;A</span> <span class="dt">Int</span>, <span class="dt">HasField</span> r <span class="dt">&#39;B</span> <span class="dt">Int</span>) <span class="ot">=&gt;</span> <span class="dt">Record</span> r <span class="ot">-&gt;</span> (<span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>) <span class="ot">-&gt;</span> <span class="dt">Record</span> r</span></code></pre></div>
<p>The runtime values for <code>HasField ...</code> constraints are the accessors. When calling this function we don’t explicitly pass these accessors, the compiler generates them. In a well-typed program, we either have these values in the call site, or we know how to generate them (e.g. the record type is concrete in the call site), so it’s possible for the compiler to generate and pass these arguments.</p>
<p>The main advantage of this approach is that it doesn’t require any language support specifically for records.</p>
<p>The main disadvantages are:</p>
<ul>
<li><p>Every field access is a function call.</p></li>
<li><p>Parameter passing per field per record does not scale well and causes messy and slow generated code. For example, suppose we want to take two records with fields <code>x : Int</code> and <code>y : Int</code>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a>f <span class="op">:</span> <span class="ot">∀</span> r <span class="op">.</span> (<span class="dt">HasField</span> r <span class="dt">&#39;X</span> <span class="dt">Int</span>, <span class="dt">HasField</span> r <span class="dt">&#39;Y</span> <span class="dt">Int</span>) <span class="ot">=&gt;</span> <span class="dt">Record</span> r <span class="ot">-&gt;</span> <span class="dt">Record</span> r <span class="ot">-&gt;</span> <span class="op">...</span></span></code></pre></div>
<p>This function takes two implicit arguments, but it has a limitation that the record arguments need to have the same record types. I can’t call this function with two different records:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a>f { x <span class="ot">=</span> <span class="dv">123</span>, y <span class="ot">=</span> <span class="dv">456</span>, a <span class="ot">=</span> <span class="st">&quot;hi&quot;</span> } { x <span class="ot">=</span> <span class="dv">0</span>, y <span class="ot">=</span> <span class="op">-</span><span class="dv">1</span>, b <span class="ot">=</span> false }</span></code></pre></div>
<p>For this to work I need two row variables:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a>f <span class="op">:</span> <span class="ot">∀</span> r1 r2 <span class="op">.</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a>    (<span class="dt">HasField</span> r1 <span class="dt">&#39;X</span> <span class="dt">Int</span>, <span class="dt">HasField</span> r1 <span class="dt">&#39;Y</span> <span class="dt">Int</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true"></a>     <span class="dt">HasField</span> r2 <span class="dt">&#39;X</span> <span class="dt">Int</span>, <span class="dt">HasField</span> r2 <span class="dt">&#39;Y</span> <span class="dt">Int</span>) <span class="ot">=&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true"></a>    <span class="dt">Record</span> r1 <span class="ot">-&gt;</span> <span class="dt">Record</span> r2 <span class="ot">-&gt;</span> <span class="op">...</span></span></code></pre></div>
<p>This version works, but it also takes 4 implicit arguments.</p></li>
</ul>
<h1 id="prerequisite-integers-for-labels">Prerequisite: integers for labels</h1>
<p>Starting with the next approach, we will require mapping labels (field names) to integers in compile-time, to be used as indices.</p>
<p>Because these integers for labels will be used in record allocation and field accesses, it is possible that a label we see later in a program will cause different code generation for a record field access that we’ve already seen.</p>
<p>We have two options:</p>
<ul>
<li><p>We can avoid this problem with a whole-program pass to collect all labels in the program.</p>
<p>This is trivial with a whole-program compiler as a front-end pass can store all labels seen in a component (library, module) somewhere and we can map those labels to integers before code generation.</p></li>
<li><p>We can have a link-time step to update record allocation and field access code with the integers for the labels.</p></li>
</ul>
<p>In the rest of the post, labels will always get integers based on their lexicographical order and we will call these integers for labels just “labels”.</p>
<p>For example, if I have labels <code>a</code>, <code>c</code>, <code>b</code>, <code>d</code> in my program, their numbers will be 1, 3, 2, 4, respectively.</p>
<h1 id="per-record-label-to-field-offset-tables">(2) Per-record label-to-field-offset tables</h1>
<p>With integers as labels we can add a table to every record (records with the same set of keys sharing the same table) mapping labels in the program to offsets in the record’s payload. For example, the table for a record with fields <code>a</code> and <code>c</code> when the program has labels <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>, looks like this:</p>
<pre><code>[ 0, _, 1, _ ]</code></pre>
<p>This table is indexed by the label and the value gives the offset in the record’s payload for the field. <code>_</code> means the record does not have the field. In a well-typed program we won’t ever see a <code>_</code> value being read from a table.</p>
<p>This approach is quite wasteful as every table will have as many entries as number of labels in the program, but we will compress these tables below to reasonable sizes.</p>
<p>We will call these tables “record offset tables” or “offset tables” in short. When compiling a record access we need to get the record’s offset table. For this we add an extra word (pointer) to record objects pointing to their offset tables. We then generate this code for a record field access:</p>
<pre><code>record[record[OFFSET_TABLE_INDEX][label]]</code></pre>
<p><code>OFFSET_TABLE_INDEX</code> is the constant for where the offset table pointer is in record objects.</p>
<p>Offset tables are generated per record shape (set of labels), so the total number of tables shouldn’t be too large.</p>
<p>Since the <code>_</code> entries won’t ever be used, we can shrink the tables with trailing <code>_</code> entries. In our example above with a record with <code>a</code> and <code>c</code> fields, the last <code>_</code> entry can be omitted:</p>
<pre><code>[ 0, _, 1 ]</code></pre>
<h1 id="making-the-tables-global">(2.1) Making the tables global</h1>
<p>Because offset tables are per-shape, and the total number of record shapes in a program should be small, if we allocate a few bits in record object headers for the “shape index” of the record, this index can be used to index a global table mapping record shapes to their offset tables.</p>
<p>Generated code for record access expressions will look like:</p>
<pre><code>record[RECORD_OFFSET_TABLES[getRecordShapeId(record)][label]]</code></pre>
<p><code>getRecordShapeId</code> will read the bits in the object header for the record shape id. Depending on the actual header layout, it will look something like:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true"></a><span class="dt">int</span> getRecordShapeId(Object* object) {</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true"></a>  <span class="cf">return</span> (object-&gt;header &amp; RECORD_ID_MASK) &gt;&gt; HEADER_BITS;</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true"></a>}</span></code></pre></div>
<p>With record shape IDs in headers and a global table mapping shape IDs to offset tables, we no longer need an extra word in record objects for the offset table pointer.</p>
<p>Here’s an example of offset tables when we have labels <code>a</code>, <code>b</code>, <code>x</code>, <code>y</code>, and two records <code>0: {a, b}</code> and <code>1: {x, y}</code>:</p>
<pre><code>RECORD_0_OFFSET_TABLE = [
  0, // label a
  1, // label b
  _, // label x
  _, // label y
];

RECORD_1_OFFSET_TABLE = [
  _, // label a
  _, // label b
  0, // label x
  1, // label y
];

RECORD_OFFSET_TABLES = [
  RECORD_0_OFFSET_TABLE, // record 0
  RECORD_1_OFFSET_TABLE, // record 1
];</code></pre>
<p>As before, the offset table for record 0 can be shrunk as:</p>
<pre><code>RECORD_0_OFFSET_TABLE = [
  0, // label a
  1, // label b
];</code></pre>
<h1 id="sharing-label-ids-and-record-shapes">(2.2) Sharing label IDs and record shapes</h1>
<p>Labels that are not used in the same record program can be given the same ID.</p>
<p>In the example above, this allows us to have a single table for both records:</p>
<pre><code>RECORD_0_1_OFFSET_TABLE = [
  0, // label a or x
  1, // label b or y
];

RECORD_OFFSET_TABLES = [
  RECORD_0_1_OFFSET_TABLE, // record 0
  RECORD_0_1_OFFSET_TABLE, // record 1
];</code></pre>
<p>The problem of assigning IDs to labels is very similar to stack allocation when spilling during register allocation. We have practically infinite amount of IDs (stack space), but we want to reuse the same ID for labels as long as they’re never used in the same record (live at the same time).</p>
<p>After sharing label IDs, some of the shapes may be identical, as in our example. We can give those shapes the same ID and avoid redundant entries in the offset tables.</p>
<p>With this, our example with two records <code>{a, b}</code> and <code>{x, y}</code> compiles to just one offset table:</p>
<pre><code>RECORD_0_1_OFFSET_TABLE = [
  0, // label a or x
  1, // label b or y
];

RECORD_OFFSET_TABLES = [
  RECORD_0_1_OFFSET_TABLE, // record 0 and 1
];</code></pre>
<h1 id="flattening-the-table">(2.3) Flattening the table</h1>
<p>Suppose we have these record shapes in a program:</p>
<ul>
<li><code>{a, b, q}</code></li>
<li><code>{x, y, q}</code></li>
</ul>
<p>The <code>RECORD_OFFSET_TABLES</code> table is currently an array of pointers, and indexing the offset table still requires pointer chasing.</p>
<p>To avoid pointer chasing we can flatten the table.</p>
<p>For our current program, the tables, without flattening, look like this:</p>
<pre><code>RECORD_0_OFFSET_TABLE = [
  0, // label a
  1, // label b
  _, // label x
  _, // label y
  2, // label q
];

RECORD_1_OFFSET_TABLE = [
  _, // label a
  _, // label b
  0, // label x
  1, // label y
  2, // label q
];

RECORD_OFFSET_TABLES = [
  RECORD_0_OFFSET_TABLE,
  RECORD_1_OFFSET_TABLE,
];</code></pre>
<p>We can flatten this as:</p>
<pre><code>RECORD_0_OFFSET_TABLE = [
  0, // label a
  1, // label b
  _, // label x
  _, // label y
  2, // label q
];

RECORD_1_OFFSET_TABLE = [
  _, // label a
  _, // label b
  0, // label x
  1, // label y
  2, // label q
];

RECORD_LABEL_OFFSETS = [
  0, // record 0, label a
  1, // record 0, label b
  _, // record 0, label x
  _, // record 0, label y
  2, // record 0, label z

  _, // record 1, label a
  _, // record 1, label b
  0, // record 1, label x
  1, // record 1, label y
  2, // record 1, label z
];</code></pre>
<p>Field indexing then becomes:</p>
<pre><code>record[RECORD_LABEL_OFFSETS[(getRecordShapeId(record) * NUM_LABELS) + label]]</code></pre>
<p>With this version we eliminate one layer of indirection.</p>
<h1 id="removing-the-constant-factor">(2.4) Removing the constant factor</h1>
<p>The idea here is not too important on its own, but it will enable further improvements.</p>
<p>The <code>NUM_LABELS</code> factor in field access code above can be eliminated by incrementing record shape IDs by <code>NUM_LABELS</code> instead of 1. In our example, instead of having record IDs 0 and 1, we will have 0 and 5 (incremented by the number of labels in the program).</p>
<p>Since there may be large number of labels in a program and we may have only a few bits to store the record IDs, an alternative would be to convert the table to label-major order like this:</p>
<pre><code>RECORD_LABEL_OFFSETS = [
  0, // label a, record 0
  _, // label a, record 1

  1, // label b, record 0
  _, // label b, record 1

  _, // label x, record 0
  1, // label x, record 1

  _, // label y, record 0
  2, // label y, record 1

  3, // label z, record 0
  3, // label z, record 1
];</code></pre>
<p>With this table, indexing code becomes:</p>
<pre><code>record[RECORD_LABEL_OFFSETS[(label * NUM_RECORDS) + getRecordShapeId(record)]]</code></pre>
<p>We can then eliminate the <code>NUM_RECORDS</code> factor the same way, by incrementing label IDs by <code>NUM_RECORDS</code> instead of 1, and index with:</p>
<pre><code>record[RECORD_LABEL_OFFSETS[label + getRecordShapeId(record)]]</code></pre>
<h1 id="compacting-the-table-further">(2.5) Compacting the table further</h1>
<p>Now that the table index of a label is <code>label + shape_id</code> and we have a single table, we can shift the entries in the table by decrementing label IDs.</p>
<p>For this it doesn’t matter whether we store in label-major or record-major order. Which one of these will generate a smaller table will probably depend on the program. As an example, suppose we store the table in label-major order, and we have these records in the program:</p>
<ul>
<li><code>0: {x, y, z, t}</code></li>
<li><code>1: {x, y}</code></li>
<li><code>2: {z, t}</code></li>
</ul>
<p>The table will look like:</p>
<pre><code>[ 0, 0, _,   // label x
  1, 1, _,   // label y
  2, _, 0,   // label z
  3, _, 1 ]  // label t</code></pre>
<p>Record IDs will be 0, 1, 2, and label IDs will be 0, 3, 6, 9.</p>
<p>We can use the unused slot for label x, record 2, by decrementing the label index for <code>y</code> by one. If we then do the same for <code>z</code>, the label IDs become 0, 2, 4, 7, and the table becomes:</p>
<pre><code>[ 0, 0,      // label x
  1, 1,      // label y
  2, _, 0,   // label z
  3, _, 1 ]  // label t</code></pre>
<p>This idea can be used to fill any gaps in previous label rows, as long as the used slots in a row fits into the gaps. For example, if we have a table like:</p>
<pre><code>[ 0, _, _, 1,  // label x
  _, 0, 1, _,  // label y
  ... ]</code></pre>
<p>We can decrement <code>y</code>’s ID to fit it into the row for label <code>x</code>:</p>
<pre><code>[ 0, 0, 1, 1,  // label x and y, interleaved
  ... ]</code></pre>
<h1 id="conclusions">Conclusions</h1>
<p>Collecting and numbering all labels in the program allows using a global table for mapping labels to offsets.</p>
<p>These offset tables can be made smaller by</p>
<ul>
<li>Giving same number to labels that don’t occur in the same record</li>
<li>Giving same ID to records that become identical after the previous step</li>
<li>Tweaking label numbers so that rows without overlapping entries can be merged into a single row</li>
</ul>
<p>The result is a very compact representation of record objects (no extra words in the header or unused space in the payload needed) and a fast polymorphic field access.</p>
<p>The offset table should also be small in practice, because different parts of the program will probably use disjoint set of names, and different labels and records will have the same IDs. In the remaining cases, tweaking label IDs to compact the table should help.</p>
<h1 id="references">References</h1>
<p>I’ve learned about the global table approach and some of the optimizations from the Dart compiler, which implements virtual calls using a “global dispatch table” (GDT), indexed by <code>classID + methodID</code> in call sites. See <a href="https://mrale.ph/dartvm/#global-dispatch-table-gdt">“Introduction to Dart VM”</a> for a description of how Dart AOT and JIT generate GDTs.</p>
<p>If you are interested in seeing some code, <a href="https://github.com/dart-lang/sdk/blob/ba8f0bd947c613013ed4659ea44da851bf35a99f/pkg/dart2wasm/lib/dispatch_table.dart#L411-L442">here</a> is where we generate the GDT in dart2wasm (Dart’s Wasm backend). The outer loop finds a selector ID (label ID in our examples) for a row (list of records in our examples, list of classes in dart2wasm). The inner loop <code>do { ... } while (!fits)</code> starts from the first row with gaps, and tries to fit the current row into the gaps. In the worst case it skips all of the rows, in which case rest of the code appends the table with the new row.</p>
<p><a href="https://github.com/dart-lang/language/blob/master/accepted/future-releases/records/records-feature-specification.md">Dart will soon have records</a>, and for the <a href="https://github.com/dart-lang/sdk/issues/50014">dart2wasm implementation of records</a> I’m thinking of using some of the ideas described in this post. Dart records do not support width subtyping (you can’t pass <code>{x, y, z}</code> where <code>{x, y}</code> is expected), but because of the <code>dynamic</code> type, we can have a dynamically typed record that we index.</p>
<hr />
<p>Thanks to <a href="https://twitter.com/josecalderon">José Manuel Calderón Trilla</a> for his feedback on a draft of this blog post.</p>]]></summary>
</entry>
<entry>
    <title>Products and sums, named and anonymous</title>
    <link href="http://osa1.net/posts/2021-04-10-sums-and-products.html" />
    <id>http://osa1.net/posts/2021-04-10-sums-and-products.html</id>
    <published>2021-04-10T00:00:00Z</published>
    <updated>2021-04-10T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I was recently thinking about why do so many languages have tuples, which can be thought of as simple anonymous products (more on the definition of this below), but not something similar for sums. Both sum and product types are widely used, so it seems inconsistent to have anonymous products but not sums.</p>
<p>I recently <a href="https://twitter.com/_osa1/status/1379260986574667776">tweeted about this</a> and got helpful responses that made me realize that I got my definitions wrong. As I think more about what “anonymous type” means it became clear to me that the it’s not just tuples or other types with special syntax, instead of names. It’s more complicated than that.</p>
<p>So in this post I’d like to briefly talk about products and sums, and how are names used in type checking. I will then show a different way of type checking, and some examples from two widely used languages. Finally, I will argue that types are called “named” or “anonymous” depending on how they are checked.</p>
<p>Note that I’m not using any of these words as they are used in category theory or any other field of mathematics. These are mainly how I see them used in widely used PLs like Haskell, Rust, and OCaml, and in PL papers and books.</p>
<h1 id="products">Products</h1>
<p>A value of a product type contains zero or more fields with potentially different types. Some example product types are:</p>
<ul>
<li><code>data Coordinate = Coordinate { x :: Int, y :: Int }</code>: a product with two <code>Int</code> fields</li>
<li><code>data D = D Int String Float</code>: a product with <code>Int</code>, <code>String</code>, and <code>Float</code> fields</li>
<li><code>data Empty = Empty</code>: a product with no fields</li>
</ul>
<p>Note that the way you access the fields does not matter. In the examples above, fields of a <code>Coordinate</code> value can be accessed with pattern matching, or with the generated functions <code>x</code> and <code>y</code>. In the second example, we can only access the fields with pattern matching.</p>
<p>What matters is: products contain zero or more fields. The fields can have different types.</p>
<h1 id="sums">Sums</h1>
<p>A sum type specifies multiple “variants” (or “alternatives”), where each variant has a “name” (or “tag”, more on this later) and some number of fields.</p>
<p>A value of a sum type holds a name (or tag), and the fields of the variant with that name.</p>
<p>For example, if you have a parser for integers, you will want to return an integer when parsing succeeds, or an error message when something goes wrong. The sum type for the return value of your parse function would look like:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="kw">data</span> <span class="dt">ParseResult</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>  <span class="ot">=</span> <span class="dt">Success</span> <span class="dt">Int</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>  <span class="op">|</span> <span class="dt">Fail</span> <span class="dt">String</span></span></code></pre></div>
<p>Here, <code>Success</code> and <code>Fail</code> are names of the variants. <code>Success</code> variant has an <code>Int</code> field, and <code>Fail</code> variant has a <code>String</code> field.</p>
<p>A value of this type does not contain an <code>Int</code> and <code>String</code> at the same time. It’s either a <code>Fail</code> with a <code>String</code> field, or a <code>Success</code> with an <code>Int</code> field.</p>
<p>The way you access the fields is with pattern matching:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="kw">case</span> parse_result <span class="kw">of</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>   <span class="dt">Success</span> int <span class="ot">-&gt;</span> <span class="op">...</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>   <span class="dt">Fail</span> error_message <span class="ot">-&gt;</span> <span class="op">...</span></span></code></pre></div>
<h1 id="names-in-type-checking-nominal-typing">Names in type checking (nominal typing)</h1>
<p>If I have two types, named <code>T1</code> and <code>T2</code>, no matter how they are defined, they are considered different in Haskell, and most other widely used typed languages (Rust, Java, …). This is called “nominal” type checking, where differently named types are considered different, even if they are “structurally” the same. For example, <code>data T1 = T Int</code> and <code>data T2 = T Int</code> are structurally the same, but you can’t apply a value of type <code>T2</code> to a function that expects <code>T1</code>.</p>
<p>What “structurally same” mean is open to interpretation. We will come to this later.</p>
<p>In addition, all types have names<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, even types like tuples, which may look like they don’t have names, like our <code>Coordinate</code> or <code>ParseResult</code> have.</p>
<p>Tuples in most languages are just a bunch of product types, like the ones you can define yourself. They are often pre-defined for arities 0 to some number, and they have a special, “mixfix” syntax, with parentheses and commas to separate the fields. Other than that, they are no different than the ones you can define yourself.</p>
<p>You can see GHC’s definition of tuples <a href="https://github.com/ghc/ghc/blob/a951e06921f05df1601d9c3a39efcede27f3330c/libraries/ghc-prim/GHC/Tuple.hs#L34-L58">here</a>. In GHC, you can use the name directly if you don’t want the mixfix syntax, like <code>(,) 1 2</code>. So the name for an 2-ary tuple is <code>(,)</code> in Haskell, and it has a special syntax so you can write more readable <code>(1, 2)</code> (or <code>(Int, Int)</code> in type context). Other than syntax, there’s nothing special about tuples.</p>
<p>So it’s clear that most languages don’t have anonymous types. All types have some kind of names, and two types are only “compatible” if the names match.</p>
<p>Before defining what anonymous types are, I would like to give two examples, from PureScript and OCaml, where types are not checked based on their names, but based on their “structure”.</p>
<h1 id="structural-type-checking-for-products">Structural type checking for products</h1>
<p>A record is a product type with named (or “labelled”) fields. Our <code>Coordinate</code> example is a record.</p>
<p>In PureScript, records can be defined without giving names to them. For example:</p>
<pre class="purescript"><code>f :: { x :: Int, y :: Int } -&gt; Int
f a = a.x + a.y</code></pre>
<p>Here, <code>f</code> is a function that takes a record with two <code>Int</code> fields, named <code>x</code> and <code>y</code>, as an argument.</p>
<p>Here is a more interesting version of the same function:</p>
<pre class="purescript"><code>f :: forall r . { x :: Int, y :: Int | r } -&gt; Int
f a = a.x + a.y</code></pre>
<p>This version takes a record with <em>at least</em> <code>x :: Int</code> and <code>y :: Int</code> fields, but it can have more fields. Using this version, this code type checks:</p>
<pre class="purescript"><code>f { x: 1, y: 2, z: 3, t: 4 }</code></pre>
<p>The <code>r</code> in this type is not too important. Important part is, in PureScript, records are not type checked nominally. Indeed, in the example above, type of the record with 4 fields is not defined, and no names are used for the record in the type signature of <code>f</code>.</p>
<p>You might think that the record braces and commas are similar to the tuple syntax, so the name could be something like <code>{,}</code>, maybe applied to <code>x :: Int</code> somehow (assuming there is a type-level representation of field names).</p>
<p>However, even if that’s the case, type checking of these types are quite different than tuples. We’ve already seen that we can pass a record with more fields. You can also reorder fields in the function type signature<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, or in the record expression, and it still works.</p>
<p>So type checking for PureScript is quite different than Haskell tuples.</p>
<p>This kind of type checking where you look at the “structure” rather than just the names is called structural type checking.</p>
<p>Now let’s take a look at an example for sum types.</p>
<h1 id="structural-type-checking-for-sum-types">Structural type checking for sum types</h1>
<p>OCaml has named sum types, just like Haskell’s. Here is the OCaml version of our <code>ParseResult</code> type:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a><span class="kw">type</span> parse_result =</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a>  | Success <span class="kw">of</span> <span class="dt">int</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a>  | Fail <span class="kw">of</span> <span class="dt">string</span></span></code></pre></div>
<p>Name of this type is <code>parse_result</code> (following OCaml naming conventions), and it is type checked exactly the same way it is type checked in Haskell.</p>
<p>A second way of defining sum types in OCaml, and without names, is with <a href="https://ocaml.org/manual/lablexamples.html#s:polymorphic-variants">polymorphic variants</a>. Here’s the polymorphic variant for the same type:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a><span class="kw">type</span> parse_result = [ `Success <span class="kw">of</span> <span class="dt">int</span> | `Fail <span class="kw">of</span> <span class="dt">string</span> ]</span></code></pre></div>
<p>Crucially, even though we use a similar syntax with the <code>type</code> keyword, this is a type synonym. The right-hand side of this definition is an anonymous sum with two variants, tagged <code>`Success</code> and <code>`Fail</code>, with <code>int</code> and <code>string</code> fields, respectively.</p>
<p>Now, suppose I have a parse result handler, which, in addition to the success and failure cases, handles some “other” case as well:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a><span class="kw">let</span> f = <span class="kw">function</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a>  | `Success i -&gt; <span class="dt">Printf</span>.printf <span class="st">&quot;Parse result: %d</span><span class="ch">\n</span><span class="st">&quot;</span> i</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true"></a>  | `Fail msg -&gt; <span class="dt">Printf</span>.printf <span class="st">&quot;Parse failed: %s</span><span class="ch">\n</span><span class="st">&quot;</span> msg</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true"></a>  | `Other -&gt; <span class="dt">Printf</span>.printf <span class="st">&quot;Wat?</span><span class="ch">\n</span><span class="st">&quot;</span></span></code></pre></div>
<p>Type of this function as inferred by the OCaml compiler is:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true"></a>[&lt; `Fail <span class="kw">of</span> <span class="dt">string</span> | `Other | `Success <span class="kw">of</span> x ] -&gt; <span class="dt">unit</span></span></code></pre></div>
<p>What this type says is that the function accepts any polymorphic variant that has the tags <code>Fail</code>, <code>Other</code>, and <code>Success</code> (with the specified field types), or some subset of these tags. So if I have a value of type <code>parse_result</code>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true"></a><span class="kw">let</span> x : parse_result = `Success <span class="dv">123</span></span></code></pre></div>
<p>I can pass it to <code>f</code>, even though <code>f</code>’s argument type is not exactly <code>parse_result</code>. Here’s the full example, run in <a href="https://github.com/ocaml-community/utop">utop</a>: (<code>utop #</code> part is the prompt, lines after <code>;;</code> are utop outputs)</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true"></a>utop # <span class="kw">type</span> parse_result = [ `Success <span class="kw">of</span> <span class="dt">int</span> | `Fail <span class="kw">of</span> <span class="dt">string</span> ];;</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true"></a><span class="kw">type</span> parse_result = [ `Fail <span class="kw">of</span> <span class="dt">string</span> | `Success <span class="kw">of</span> <span class="dt">int</span> ]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true"></a>utop # <span class="kw">let</span> f = <span class="kw">function</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true"></a>  | `Success i -&gt; <span class="dt">Printf</span>.printf <span class="st">&quot;Parse result: %d</span><span class="ch">\n</span><span class="st">&quot;</span> i</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true"></a>  | `Fail msg -&gt; <span class="dt">Printf</span>.printf <span class="st">&quot;Parse failed: %s</span><span class="ch">\n</span><span class="st">&quot;</span> msg</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true"></a>  | `Other -&gt; <span class="dt">Printf</span>.printf <span class="st">&quot;Wat?</span><span class="ch">\n</span><span class="st">&quot;</span>;;</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true"></a><span class="kw">val</span> f : [&lt; `Fail <span class="kw">of</span> <span class="dt">string</span> | `Other | `Success <span class="kw">of</span> <span class="dt">int</span> ] -&gt; <span class="dt">unit</span> = &lt;<span class="kw">fun</span>&gt;</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true"></a>utop # <span class="kw">let</span> x : parse_result = `Success <span class="dv">123</span>;;</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true"></a><span class="kw">val</span> x : parse_result = `Success <span class="dv">123</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true"></a>utop # f x;;</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true"></a>Parse result: <span class="dv">123</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true"></a>- : <span class="dt">unit</span> = ()</span></code></pre></div>
<p>Neat!</p>
<p>Similar to PureScript records, and unlike Haskell tuples, type checking for OCaml polymorhic records is structural, not nominal.</p>
<h1 id="names---nominal---structural">Names -&gt; nominal, ??? -&gt; structural</h1>
<p>Now that we have seen structural type checking as an alternative to name-based (nominal) type checking, and some examples, here is my attempt at defining anonymous types: If named types are type checked nominally, then the types that are structurally type checked are called “anonymous”.</p>
<p>In other words:</p>
<ul>
<li>Nominally type checked types are named</li>
<li>Structurally type checked types are anonymous</li>
</ul>
<p>According to this definition, Haskell and many other languages don’t have anonymous types. PureScript records are an example to anonymous products, and OCaml polymorphic variants are an example to anonymous sums.</p>
<h1 id="conclusions">Conclusions</h1>
<p>Named types are checked nominally, anonymous types are checked structurally. According to this definition, Haskell, and many other languages, don’t have anonymous types, as all types are nominally checked.</p>
<p>Tuples are no exception: they have names, and type checked nominally.</p>
<p>PureScript records and OCaml polymorphic variants are great examples to anonymous products and sums, respectively.</p>
<!---




























# Tuples: named or anonymous?

Tuples in languages like Haskell, Rust, and OCaml, are pre-defined product
types that are often used for returning multiple values from functions, without
having to define a new type for the return value.

For example, the tuple type `(Int, Int)` in Haskell is a product with two `Int`
fields. This type is similar to our `Coordinate` example above.

Because tuples don't have "names", like our `Coordinate` has, it may seem like
tuples are unnamed, or "anonymous". This is actually not true. Tuples in most
languages are just a bunch of product types, like the ones you can define
yourself. They are often pre-defined for arities 0 to some number, and they have
a special, "mixfix" syntax, with parentheses and commas to separate the fields.
Other than that, they are no different than the ones you can define yourself.

As an example, you can see GHC's definition of tuples [here][2]. In GHC, you can
use the name directly if you don't want the mixfix syntax, like `(,) 1 2`. So
the name for an 2-ary tuple is `(,)` in Haskell, and it has a special syntax so
you can write more readable `(1, 2)` (or `(Int, Int)` in type context).

So it's clear that tuples in Haskell are not anonymous, they have names. But
what are anonymous types then? Does Haskell even have anonymous types? Before
defining anonymous types, let's briefly talk about how are names used in type
checking.

# Nominal and structural type checking

If I have two types, named `T1` and `T2`, no matter how they are defined, they
are considered different in Haskell, and most other widely used typed languages
(Rust, Java, ...). This is called "nominal" type checking, where differently
named types are considered different, even if they are "structurally" the same.
For example, `data T1 = T Int` and `data T2 = T Int` are structurally the same,
but you can't apply a value of type `T2` to a function that expects `T1`.


What does "structurally same" mean here is open to interpretation, but the
crucial part is with structural type checking, types can have different set of
fields or variants and still be compatible. We will shortly see examples of
this.

Now, here's the difficulty with defining anonymous types (and a point of
confusion, at least for me). Regardless of the syntax, I will have to introduce
some kind of type constructors for anonymous products and sums. One might always
consider those constructors as the names of the types (with type parameters
applied for the fields/ variants).

For example, if I use `*` syntax for anonymous products, like `Int * Int * Bool`
for a product type like `(Int, Int, Bool)`, you might argue that the "name" here
is `*`, and the desugared version is something like `(*) Int ((*) Int Bool)`,
and you would probably be right! In many (most?) type systems, including
Haskell's, complex types are made by applying types to type constructors. The
type constructors used for constructing product or sum types can be thought of
as the name of the types.

In that sense I think there really isn't any *obviously anonymous* types where
you will know it when you see it. Every type is constructed by applying some
number of arguments to a "name" (usually called "type constructors").

# Names -> nominal, ??? -> structural

With these definitions in mind, here's my attempt at defining anonymous types.
If named types are type checked nominally (where different names mean types are
incompatible), then the types that are structurally type checked are called
"anonymous".

In other words:

- Nominally type checked types are named
- Structurally type checked types are anonymous

In the simple structural type checking rule we've seen above, anonymous
products (constructed with `*`) and tuples (constructed with the mixfix tuple
syntax) are type checked exactly the same way. Let's add one more rule to make
them different:

- Before applying the rules given before, rearrange the type arguments to make
  the first argument of `*` a non-`*` type.

Example: if I have `(Int * Int) * (Int * Int)`, this rule rearranges it to make
it `Int * (Int * (Int * Int))`.

(This rule effectively makes `*` associative)

With this new rule we now accept these two types as compatible:

- `(Int * (Int * Int)) * Int`
- `(Int * Int) * (Int * Int)`

as they are both rearranged before checking as `Int * (Int * (Int * Int))`.

(Whether this rule is useful or desired is a different matter)

With this structural equality rule, type checking of tuples and products
constructed with `*` are different, and we call tuples named types and `*`
products anonymous.

# Anonymous sum types

Instead of inventing syntax and defining type checking for anonymous sum types,
like we did for products, I will show an example of anonymous sums in an
existing programming language: OCaml's [polymorphic variants][3].

Here's the OCaml version of our `ParseResult` type:

```ocaml
type parse_result =
  | Success of int
  | Fail of string
```

This type is nominally checked, so if you have a function that expects
`parse_result` argument, you have to pass it a `Success` or `Fail`. Anything
else will cause a type error.

Here's the polymorphic variant for the same type:

```ocaml
type parse_result = [ `Success of int | `Fail of string ]
```

Crucially, even though we use a similar syntax with the `type` keyword, this is
a type synonym. The right-hand side of this definition is an anonymous sum with
two variants, labelled `` `Success`` and `` `Fail``, with `int` and `string`
fields, respectively.

Here's an example of structural type checking of polymorphic variants. Suppose I
have a parse result handler, which, in addition to the success and failure
cases, handles some "other" case as well:

```ocaml
let f = function
  | `Success i -> Printf.printf "Parse result: %d\n" i
  | `Fail msg -> Printf.printf "Parse failed: %s\n" msg
  | `Other -> Printf.printf "Wat?\n"
```

Type of this function as inferred by the OCaml compiler is:

```ocaml
[< `Fail of string | `Other | `Success of x ] -> unit
```

What this type says is that the function accepts any polymorphic variant that
has the tags `Fail`, `Other`, and `Success` (with the specified field types), or
some subset of these tags. So if I have a value of type `parse_result`:

```ocaml
let x : parse_result = `Success 123
```

I can pass it to `f`, even though `f`'s argument type is not exactly
`parse_result`. Here's the full example, run in [utop][9]: (`utop #` part is the
prompt, lines after `;;` are utop outputs)

```ocaml
utop # type parse_result = [ `Success of int | `Fail of string ];;
type parse_result = [ `Fail of string | `Success of int ]

utop # let f = function
  | `Success i -> Printf.printf "Parse result: %d\n" i
  | `Fail msg -> Printf.printf "Parse failed: %s\n" msg
  | `Other -> Printf.printf "Wat?\n";;
val f : [< `Fail of string | `Other | `Success of int ] -> unit = <fun>

utop # let x : parse_result = `Success 123;;
val x : parse_result = `Success 123

utop # f x;;
Parse result: 123
- : unit = ()
```

Neat!

# Conclusions

Named types are checked nominally, anonymous types are checked structurally.
According to this definition, Haskell, and many other languages, don't have
anonymous types, as all types are nominally checked.

OCaml's [polymorphic variants][3] are a great example to anonymous sums.

For real-world anonymous products, it would be a shame to not mention records
and row types[^1]. A record is a product type with labelled fields, for example:
`{ a : Int, b : Bool }`. Row types allow (among other things) very flexible type
checking of records, where you can (without subtyping) pass a record with more
fields when less is expected. With row types, unlike subtyping, if you have a
function that expects a record type like `{ a : Int, b : Bool }` and returns the
argument after using or modifying the fields `a` and/or `b`, and pass the
function a record with more fields, like `{ a : Int, b : Bool, c : String }`, as
the return type you get your original record with 3 fields. More concretely:

```
{ a : Int, b : Bool, ..r } -> { a : Int, b : Bool, ..r }
```

is the type of a function that takes a record with fields `a` and `b` with the
specified types, and *possibly* more fields. These extra fields are represented
by `r`, which appears in both input and output types. This means you don't lose
the extra fields if you pass a record with more fields to this function, unlike
in a system with subtyping. With subtyping, if you have a function with type

```
{ a : Int, b : Bool } -> { a : Int, b : Bool }
```

and pass `{ a : Int, b : Bool, c : String }` to such a function, you lose the
field `c` in the return value, because the return type only mentions `a` and
`b`, without the "extra stuff" part as we've seen in the row polymorphic
version.

(As as aside, I'd like to mention that I really like row types. My first
exposure to them was back in 2013 ([1][5], [2][6]): I implemented two type
systems, one with row types and one for a multi-stage language, proved soundness
of the systems, gave a type and term translation from one to the other, and
proved that if your program is well-typed, then the translation of it is also
well-typed.)

My favorite paper on row-polymorphic records is probably (1). (2) uses row types
for algebraic effects. (3) uses rows for variants (sums).

-->
<hr />
<p>Thanks to <a href="https://twitter.com/_gilmi/">@_gilmi</a> and <a href="https://twitter.com/madgen_/">@madgen_</a> for their helpful comments on a draft of this blog post.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>With the exception of type synonyms. Type synonyms can be considered as simple macros for substituting types for names before type checking.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>In Haskell, reordering stuff at the type level is often done with type families (type-level functions). Types are still checked nominally, but by rearranging them before type checking you can often have something somewhat similar to structural checking.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>]]></summary>
</entry>

</feed>
