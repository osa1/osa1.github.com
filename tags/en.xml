<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>osa1.net - Posts tagged en</title>
    <link href="http://osa1.net/tags/en.xml" rel="self" />
    <link href="http://osa1.net" />
    <id>http://osa1.net/tags/en.xml</id>
    <author>
        <name>Ömer Sinan Ağacan</name>
        <email>omeragaca@gmail.com</email>
    </author>
    <updated>2017-10-16T00:00:00Z</updated>
    <entry>
    <title>A parallel scheduler in 50 lines of Haskell</title>
    <link href="http://osa1.net/posts/2017-10-16-a-parallel-scheduler.html" />
    <id>http://osa1.net/posts/2017-10-16-a-parallel-scheduler.html</id>
    <published>2017-10-16T00:00:00Z</published>
    <updated>2017-10-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Here’s a problem:</p>
<ul>
<li>You have N resources.</li>
<li>You have M tasks.</li>
<li>Each task requires exclusive access to a subset of the resources.</li>
<li>Tasks can be run in parallel.</li>
</ul>
<p>Implement a scheduler that runs these tasks in parallel, utilizing available resources as much as possible.</p>
<p>The code I’ll show here piggybacks on GHC RTS for scheduling. But for that we first have to implement our resources and tasks in a way that exposes necessary information to GHC’s scheduler. The idea is simple and fun to implement, but I can’t recommended using it in production :-) Scheduling is a hard problem, with many variations, and I’ve only recently started reading about it. This solution is a fun one than anything else.</p>
<hr />
<p>The idea is simple; we implement resources as <code>MVar</code>s and tasks as threads. Threads (tasks) take the <code>MVar</code>s before performing the operation. Because threads are scheduled by GHC RTS, GHC handles scheduling of our tasks. Because of fairness properties of <code>MVar</code>s, our threads are scheduled “fairly”, e.g. all tasks eventually finish even when we have infinitely many tasks.</p>
<p>A resource is an abstract object with a lock and unique identifier:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Resource</span> <span class="fu">=</span> <span class="dt">Resource</span>
  { _<span class="ot">resourceName ::</span> <span class="dt">T.Text</span>
  , _<span class="ot">resourceId   ::</span> <span class="dt">Unique</span>
  , _<span class="ot">resourceLock ::</span> <span class="dt">MVar</span> ()
  }

<span class="kw">instance</span> <span class="dt">Show</span> <span class="dt">Resource</span> <span class="kw">where</span>
  show <span class="fu">=</span> T.unpack <span class="fu">.</span> _resourceName</code></pre>
<p><code>_resourceName</code> is just a string to be used for tracing program execution.</p>
<p>A <code>Unique</code> is an integer that can be used in at most one resource:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">Unique</span> <span class="fu">=</span> <span class="dt">Unique</span> <span class="dt">Int</span>
  <span class="kw">deriving</span> (<span class="dt">Eq</span>, <span class="dt">Ord</span>)</code></pre>
<p>Using <code>Unique</code> we can define a total order for <code>Resource</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Eq</span> <span class="dt">Resource</span> <span class="kw">where</span>
  (<span class="fu">==</span>) <span class="fu">=</span> (<span class="fu">==</span>) <span class="ot">`on`</span> _resourceId

<span class="kw">instance</span> <span class="dt">Ord</span> <span class="dt">Resource</span> <span class="kw">where</span>
  compare <span class="fu">=</span> comparing _resourceId</code></pre>
<p>A task that requires exclusive access to a subset of all resources can be implemented using <code>withResources</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">withResources ::</span> (<span class="dt">MonadLogger</span> m, <span class="dt">MonadBaseControl</span> <span class="dt">IO</span> m) <span class="ot">=&gt;</span> <span class="dt">S.Set</span> <span class="dt">Resource</span> <span class="ot">-&gt;</span> m () <span class="ot">-&gt;</span> m ()
withResources locks a <span class="fu">=</span> acquire_locks (S.toList locks)
  <span class="kw">where</span>
    acquire_locks ls <span class="fu">=</span> <span class="kw">case</span> ls <span class="kw">of</span>
      [] <span class="ot">-&gt;</span>
        a
      l <span class="fu">:</span> ls&#39; <span class="ot">-&gt;</span> <span class="kw">do</span>
        logDebug (<span class="st">&quot;taking lock &quot;</span> <span class="fu">&lt;&gt;</span> (_resourceName l))
        withMVar (_resourceLock l) <span class="fu">$</span> \() <span class="ot">-&gt;</span>
          acquire_locks ls&#39;</code></pre>
<p>Note that when all tasks are implemented using this function a deadlock won’t occur: resources are ordered, and <code>S.toList</code> generates a sorted list, which in turn causes <code>acquire_locks</code> to take locks in order, effectively implementing <a href="https://en.wikipedia.org/wiki/Dining_philosophers_problem">Dijkstra’s resource hierarchy solution to the dining philosophers problem</a>.</p>
<p>Here are three task generators:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">Task</span> <span class="fu">=</span> <span class="dt">Task</span>
  {<span class="ot"> runTask ::</span> forall m <span class="fu">.</span> (<span class="dt">MonadLogger</span> m, <span class="dt">MonadBaseControl</span> <span class="dt">IO</span> m) <span class="ot">=&gt;</span> m () }

<span class="ot">mkFastTask ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">S.Set</span> <span class="dt">Resource</span> <span class="ot">-&gt;</span> <span class="dt">Task</span>
mkFastTask i res <span class="fu">=</span>
    <span class="dt">Task</span> <span class="fu">$</span> withResources res <span class="fu">$</span> <span class="kw">do</span>
      logDebug (<span class="st">&quot;Performing &quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i))
      threadDelay (<span class="dv">500</span><span class="ot"> ::</span> <span class="dt">Milliseconds</span>)
      logDebug (<span class="st">&quot;Fast task done (&quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i) <span class="fu">&lt;&gt;</span> <span class="st">&quot;)&quot;</span>)

<span class="ot">mkSlowTask ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">S.Set</span> <span class="dt">Resource</span> <span class="ot">-&gt;</span> <span class="dt">Task</span>
mkSlowTask i res <span class="fu">=</span>
    <span class="dt">Task</span> <span class="fu">$</span> withResources res <span class="fu">$</span> <span class="kw">do</span>
      logDebug (<span class="st">&quot;Performing &quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i))
      threadDelay (<span class="dv">3</span><span class="ot"> ::</span> <span class="dt">Seconds</span>)
      logDebug (<span class="st">&quot;Slow task done (&quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i) <span class="fu">&lt;&gt;</span> <span class="st">&quot;)&quot;</span>)

<span class="ot">mkCrashingTask ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">S.Set</span> <span class="dt">Resource</span> <span class="ot">-&gt;</span> <span class="dt">Task</span>
mkCrashingTask i res <span class="fu">=</span>
    <span class="dt">Task</span> <span class="fu">$</span> withResources res <span class="fu">$</span> <span class="kw">do</span>
      logDebug (<span class="st">&quot;Performing &quot;</span> <span class="fu">&lt;&gt;</span> T.pack (show i))
      error <span class="st">&quot;task failed&quot;</span></code></pre>
<p>Integer arguments are just for tracing task execution in program output. <code>mkFastTask</code> generates a task that takes 500 milliseconds to run. <code>mkSlowTask</code> generates a task that takes 3 seconds. <code>mkCrashingTask</code> makes a task that throws an exception, demonstrating that we release resources properly on exceptions.</p>
<p>Finally, the scheduler just spawns tasks using <code>forkIO</code> or <code>async</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">schedule ::</span> (<span class="dt">MonadLogger</span> m, <span class="dt">MonadBaseControl</span> <span class="dt">IO</span> m, <span class="dt">Forall</span> (<span class="dt">Pure</span> m)) <span class="ot">=&gt;</span> [<span class="dt">Task</span>] <span class="ot">-&gt;</span> m ()
schedule tasks <span class="fu">=</span> <span class="kw">do</span>
    thrs <span class="ot">&lt;-</span> forM tasks <span class="fu">$</span> \(<span class="dt">Task</span> task) <span class="ot">-&gt;</span>
              async (task <span class="ot">`catch`</span> (\(<span class="ot">e ::</span> <span class="dt">SomeException</span>) <span class="ot">-&gt;</span> logDebug <span class="st">&quot;Task failed&quot;</span>))
    forM_ thrs wait</code></pre>
<p>Here’s an example run</p>
<pre><code>taking lock resource5
Performing 0
taking lock resource0
Performing 1
taking lock resource2
taking lock resource6
taking lock resource7
Performing 2
Task failed
taking lock resource6
Performing 3
taking lock resource8
Performing 4
taking lock resource1
taking lock resource2
Performing 5
Task failed
taking lock resource2
taking lock resource3
taking lock resource8
taking lock resource0
taking lock resource3
taking lock resource4
Performing 9
Fast task done (3)
Fast task done (9)
Fast task done (0)
Slow task done (1)
taking lock resource4
taking lock resource8
Slow task done (4)
Performing 6
Fast task done (6)
taking lock resource7
Performing 8
Task failed
Performing 7
Slow task done (7)</code></pre>
<p>The whole code that randomly generates resources and tasks and then runs them is <a href="https://gist.github.com/osa1/e7416f6a0f299f88f275bb8d56a31da3">here</a>. It uses quite a lot of dependencies because it was extracted from a larger program, and I’m too lazy to make it smaller and simpler. I provided a <code>stack.yaml</code> so hopefully it’s still not too hard to run.</p>]]></summary>
</entry>
<entry>
    <title>More Rust woes</title>
    <link href="http://osa1.net/posts/2017-10-08-more-rust-woes.html" />
    <id>http://osa1.net/posts/2017-10-08-more-rust-woes.html</id>
    <published>2017-10-08T00:00:00Z</published>
    <updated>2017-10-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In the third part of the series (<a href="http://osa1.net/posts/2016-03-28-rust-brwchk-woes.html">1</a>, <a href="http://osa1.net/posts/2016-09-11-more-rust-problems.html">2</a>) we’re going to look at two curious cases, first one related with “drop checker” and the second one with “borrow checker”.</p>
<p>(examples below are tested with <code>rustc 1.22.0-nightly (05f8ddc46 2017-10-07)</code>)</p>
<h1 id="redundant-semicolon-fixes-borrow-or-drop-checker">1. Redundant semicolon fixes borrow (or drop) checker</h1>
<p>It turns out if you’re getting a weird borrow checker error about something not living long enough to be dropped you can sometimes fix it by adding more semicolons.</p>
<p>The error message itself is weird because intuitively you’d think that for something to be dropped it should first become dead, but the error message says something like “<code>x</code> dropped here while still borrowed”. Because the variable is not dropped explicitly by the user, this error message is actually complaining about compiler’s behavior not being consistent in itself.</p>
<p>Here’s an example:</p>
<pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::sync::Arc;
<span class="kw">use</span> std::sync::Mutex;

<span class="kw">fn</span> main() {
    <span class="kw">let</span> s: Arc&lt;Mutex&lt;<span class="kw">i32</span>&gt;&gt; = Arc::new(Mutex::new(<span class="dv">0</span>));
    <span class="kw">match</span> s.lock().unwrap() {
        _ =&gt; {}
    }
}</code></pre>
<p>This fails to compile with:</p>
<pre><code>error[E0597]: `s` does not live long enough
 --&gt; src/main.rs:9:1
  |
6 |     match s.lock().unwrap() {
  |           - borrow occurs here
...
9 | }
  | ^ `s` dropped here while still borrowed
  |
  = note: values in a scope are dropped in the opposite order they are created</code></pre>
<p>Solution? Add more semicolons! In this example, just put a semicolon after the match expression and it compiles fine.</p>
<p>Here’s <a href="https://github.com/rust-lang/rust/issues/21114#issuecomment-312447832">one more example</a>. It turns out questions about this error message are regularly asked on the IRC channel.</p>
<p><a href="https://github.com/rust-lang/rust/issues/21114">#21114</a> reported this issue on Jan 14, 2015, but no progress has been made towards a solution so far. It’s not clear if non-lexical lifetimes will help solving this.</p>
<h1 id="match-expression-keeps-values-alive-longer-than-necessary">2. <code>match</code> expression keeps values alive longer than necessary</h1>
<p>This problem is kind of special. All other problems mentioned in this series were about borrow checker being too strict. This one is different: it causes runtime bugs.</p>
<p><code>match</code> expression keeps the value to be examined (sometimes called <code>scrutinee</code> in Haskell land) alive longer than necessary. Because alive values are not dropped, if you rely on dynamic borrow checks in the scrutinee and in the branches, your checks fail. Here’s an example:</p>
<pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::sync::Arc;
<span class="kw">use</span> std::sync::Mutex;

<span class="kw">struct</span> S(<span class="kw">i32</span>);

<span class="kw">impl</span> S {
    <span class="kw">pub</span> <span class="kw">fn</span> get_int(&amp;<span class="kw">self</span>) -&gt; <span class="kw">i32</span> {
        <span class="kw">self</span>.<span class="dv">0</span>
    }

    <span class="kw">pub</span> <span class="kw">fn</span> set_int(&amp;<span class="kw">mut</span> <span class="kw">self</span>, i: <span class="kw">i32</span>) {
        <span class="kw">self</span>.<span class="dv">0</span> = i;
    }
}

<span class="kw">fn</span> main() {
    <span class="kw">let</span> s = Arc::new(Mutex::new(S(<span class="dv">0</span>)));
    <span class="kw">match</span> s.lock().unwrap().get_int() {
        i =&gt; {
            s.lock().unwrap().set_int(i);
        }
    };
}</code></pre>
<p>(notice how I use a redundant semicolon after the match expression, to fix #1)</p>
<p>Even though <code>get_int()</code> returns in <code>i32</code> as a value, not a reference, the <code>MutexGuard</code> returned by <code>Mutex::lock()</code> is kept alive in the branches of this <code>match</code> expression, so the second <code>Mutex::lock()</code> call causes a deadlock. Solution? Use a <code>let</code> expression:</p>
<pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> x = s.lock().unwrap().get_x();
<span class="kw">match</span> x { ... }</code></pre>
<p>This problem makes <code>match &lt;expr&gt; { ... }</code> less useful than <code>let x = &lt;expr&gt;; match x { ... }</code>.</p>
<p><a href="https://github.com/rust-lang/rust/issues/38355">#38355</a> reported this issue on Dec 14, 2016, but no progress towards a solution has been made so far.</p>]]></summary>
</entry>
<entry>
    <title>Enable these two flags in GHC 8.2</title>
    <link href="http://osa1.net/posts/2017-07-15-two-flags.html" />
    <id>http://osa1.net/posts/2017-07-15-two-flags.html</id>
    <published>2017-07-15T00:00:00Z</published>
    <updated>2017-07-15T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>As usual, the next major GHC release will be <a href="https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-8.2.1#Releasehighlights">pretty great</a>. It’ll come with a bunch of new features that I can’t wait to start using, and I’ve contributed to three of the new features<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, but what excites me the most is not any of these features. I’m most excited about the improved <code>-Werror</code> flag.</p>
<p>The summary is that with GHC 8.2 we’ll be able to promote some warnings into errors, without making <em>all warnings</em> errors (which is how <code>-Werror</code> worked pre-8.2). With this we can finally fix some of the Haskell 2010 warts.</p>
<hr />
<p>By the beginning of this year I moved from academia to industry. I was writing Haskell in academia, and I’m still writing Haskell, but the environment, tasks, and constraints are quite different, so the way I write Haskell changed quite a lot during this transition.</p>
<p>What I realized that some of the problems with Haskell 2010 are actually worse than I had previously thought.</p>
<h2 id="problem-1-initializing-records-without-initializing-all-of-its-fields">Problem 1: Initializing records without initializing all of its fields</h2>
<p><a href="https://www.haskell.org/onlinereport/haskell2010/haskellch3.html#x8-520003.15.2">Haskell 2010</a> says that when initializing records using labels, fields not mentioned are initialized as bottoms.</p>
<p>I just can’t fathom how Haskell 2010 people thought this is a good idea. In Haskell we constantly rely on compile-time errors to refactor our code. A common workflow is this: you update your data types, and follow the type errors to adapt your code to the changes. Quite often your program works as expected after this. I did this countless times during my career as a Haskell programmer, and I’m trying to improve GHC to <a href="https://github.com/ghc-proposals/ghc-proposals/pull/43">make this workflow even more efficient</a>.</p>
<p>The problem is this “feature” breaks this workflow, because adding a new field to a type no longer generates a compile error. It generates a warning, but that’s not good enough because (1) not all projects have <code>-Wall</code> enabled (2) not all projects are warning-free, which means new warnings sometimes go unnoticed (this happens in our code base all the time).</p>
<p>Indeed, even very experienced Haskellers release buggy code because of this. For example, warp-3.2.10 added a new field (<code>connFree</code>) to one of its types (<code>Connection</code>), and for some reason only the minor version was bumped (3.2.9 to 3.2.10, which is probably wrong according to <a href="https://pvp.haskell.org/">PVP</a> because the type was exported). The problem was warp-tls-3.2.2 had 3.3 as warp upper bound, so it compiled fine against warp-3.2.10, even though it didn’t initialize the field. This caused bugs in our system, which we thankfully discovered in our test environment rather than on production. The fix was <a href="https://github.com/yesodweb/wai/commit/b63ec0e865cf91af4143416adaf430969ba0ebb5#diff-44ce89cb2a54be5e525d74b83901f561R348">easy</a>, but the damage was done (the buggy warp-tls-3.2.2 is still on Hackage).</p>
<h2 id="problem-2-non-exhaustive-pattern-matching">Problem 2: Non-exhaustive pattern matching</h2>
<p>While I can’t find any mention to exhaustiveness of pattern matching in Haskell 2010, it clearly covers the case where patterns do not cover all values when defining <a href="https://www.haskell.org/onlinereport/haskell2010/haskellch3.html#x8-610003.17.3">formal semantics of pattern matching</a> (see case (b)). You only realize that this is a bad idea when (1) your code is not warning-free so new warnings sometimes go unnoticed and (2) you can’t promote individual warnings to errors. This again breaks the workflow I mentioned above, and makes code reviews much harder.</p>
<hr />
<p>The solution that GHC 8.2 brings is we can now make these two warnings errors, using <code>-Werror=missing-fields -Werror=incomplete-patterns</code>. There’s still one problem though, the error message is not good enough. Suppose we had this code:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">module</span> <span class="dt">Lib</span> <span class="kw">where</span>

<span class="kw">data</span> <span class="dt">Rec</span> <span class="fu">=</span> <span class="dt">Rec</span> {<span class="ot"> f1 ::</span> <span class="dt">Int</span>,<span class="ot"> f2 ::</span> <span class="dt">Int</span> }

<span class="kw">data</span> <span class="dt">S</span> <span class="fu">=</span> <span class="dt">C1</span> <span class="dt">Int</span> <span class="fu">|</span> <span class="dt">C2</span> <span class="dt">Int</span>

<span class="co">-- incomplete pattern</span>
sInt s <span class="fu">=</span> <span class="kw">case</span> s <span class="kw">of</span>
           <span class="dt">C1</span> i <span class="ot">-&gt;</span> i

<span class="co">-- missing field</span>
initRec <span class="fu">=</span> <span class="dt">Rec</span> { f1 <span class="fu">=</span> <span class="dv">1</span> }</code></pre>
<p>Compile this with <code>ghc -Wall</code> and you get:</p>
<pre><code>[1 of 1] Compiling Lib              ( test.hs, test.o )

test.hs:11:1: warning: [-Wmissing-signatures]
    Top-level binding with no type signature: sInt :: S -&gt; Int
   |
11 | sInt s = case s of
   | ^^^^

test.hs:11:10: warning: [-Wincomplete-patterns]
    Pattern match(es) are non-exhaustive
    In a case alternative: Patterns not matched: (C2 _)
   |
11 | sInt s = case s of
   |          ^^^^^^^^^...

test.hs:15:1: warning: [-Wmissing-signatures]
    Top-level binding with no type signature: initRec :: Rec
   |
15 | initRec = Rec { f1 = 1 }
   | ^^^^^^^

test.hs:15:11: warning: [-Wmissing-fields]
    • Fields of ‘Rec’ not initialised: f2
    • In the expression: Rec {f1 = 1}
      In an equation for ‘initRec’: initRec = Rec {f1 = 1}
   |
15 | initRec = Rec { f1 = 1 }
   |           ^^^^^^^^^^^^^^</code></pre>
<p>We only care about missing fields and incomplete patterns, so with GHC 8.2 we compile this with <code>ghc -Wall -Werror=missing-fields -Werror=incomplete-patterns</code>, which generates the same warnings, but the process exits with non-zero, and prints these extra lines:</p>
<pre><code>&lt;no location info&gt;: error:
Failing due to -Werror.</code></pre>
<p>This is not too useful, because if you get dozens of warnings there’s basically no way of knowing which of those warnings caused this error. One alternative is to disable <code>-Wall</code> and only use <code>-Werror</code>s. That way you know that the warnings you’re seeing are actually errors.</p>
<p>Still, this is not entirely satisfactory, because even though we don’t cause our build to fail when we have warnings, they’re still sometimes useful to see (for example, name shadowing warnings often catches accidental loops). So to improve this I recently <a href="https://phabricator.haskell.org/D3709">submitted a patch</a>, which is merged, but unfortunately won’t make it to GHC 8.2 (hopefully we’ll see it in GHC 8.4). With that patch when you have both <code>-Wall</code> and some <code>-Werror</code>s, you see this instead:</p>
<pre><code>[1 of 1] Compiling Lib              ( test.hs, test.o )

test.hs:11:1: warning: [-Wmissing-signatures]
    Top-level binding with no type signature: sInt :: S -&gt; Int
   |
11 | sInt s = case s of
   | ^^^^

test.hs:11:10: error: [-Wincomplete-patterns, -Werror=incomplete-patterns]
    Pattern match(es) are non-exhaustive
    In a case alternative: Patterns not matched: (C2 _)
   |
11 | sInt s = case s of
   |          ^^^^^^^^^...

test.hs:15:1: warning: [-Wmissing-signatures]
    Top-level binding with no type signature: initRec :: Rec
   |
15 | initRec = Rec { f1 = 1 }
   | ^^^^^^^

test.hs:15:11: error: [-Wmissing-fields, -Werror=missing-fields]
    • Fields of ‘Rec’ not initialised: f2
    • In the expression: Rec {f1 = 1}
      In an equation for ‘initRec’: initRec = Rec {f1 = 1}
   |
15 | initRec = Rec { f1 = 1 }
   |           ^^^^^^^^^^^^^^</code></pre>
<p>Much better!</p>
<p>This is probably not as exciting to many people as, say, new features like compact regions or join points, but I think this will significantly improve “refactor types, folow type error, repeat” style workflows and make code reviews much easier.</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I discovered and reported <a href="https://ghc.haskell.org/trac/ghc/ticket/10598">#10598</a> two years ago, which led to <code>-XDerivingStrategies</code> work, I was involved in the <a href="http://ezyang.com/papers/ezyang15-cnf.pdf">Compact regions paper</a>, and I implemented <a href="https://phabricator.haskell.org/D2259">unboxed sums</a> during my time at MSR Cambridge last summer.<a href="#fnref1">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>My new XFCE + i3 setup</title>
    <link href="http://osa1.net/posts/2016-11-30-new-xfce-i3-setup.html" />
    <id>http://osa1.net/posts/2016-11-30-new-xfce-i3-setup.html</id>
    <published>2016-11-30T00:00:00Z</published>
    <updated>2016-11-30T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I’ve been running Linux exclusively since 6-7 years ago, and since my first days on Linux I’ve been obsessed with two things:</p>
<ul>
<li><p>I hate the mouse, and I try really hard to not use it.</p></li>
<li><p>I need a very stable system. If my distro is not stable enough, I try to bring the system to a stable state and then I never update anything. My previous setup had one year uptime and that’s because I never updated anything and it kept running without any problems <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</p></li>
</ul>
<p>Initially I was running GNOME 2, but I had to switch to KDE because the distro I was working on at the time (Pardus) was mainly a KDE distro and as far as I remember it was the only DE that was officially supported<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. It took some time but I ended up liking it quite a lot, and kept using it after I stopped working on Pardus and switched to openSUSE.</p>
<p>My KDE setup was weird. I had dozens of key bindings for window management, and I was using vim and yakuake with lots of customization and key bindings. I basically rolled my own tiling window manager using KDE settings and key bindings.</p>
<p>I tried <a href="http://xmonad.org/">XMonad</a> and <a href="https://awesome.naquadah.org/">awesomewm</a> a couple of times, but I was too lazy to configure them to a stable state where all the services (login/logout, power management, sound and brightness settings, network controllers etc.) work flawlessly.</p>
<p>Then I discovered <a href="https://i3wm.org/">i3</a>. In my first hours with it all I had to change was the <code>jkl;</code> combination for left/down/up/right: I was already an experienced vim user so I changed it to <code>hjkl</code> and that was pretty much it. I had a usable setup already.</p>
<p>The way I run it was again weird. I replaced KDE’s window manager, so all other KDE services were running. This setup had many problems, for example, neither <code>i3bar</code> nor the KDE status bar worked, so I didn’t use a status bar. KDE’s desktop was still running, so I added a status bar widget to the desktop, and I was using a spare i3 desktop when I needed to use the status bar. I had to disable some of the KDE services (like the one that detects connected monitors) because they weren’t working as expected when I replaced the window manager etc. This system worked great for about 2 years once I disabled some of the KDE services that didn’t work properly.</p>
<p>Then, 3 weeks ago, I had some free time, and decided to finally update my system. I was using openSUSE, and I wanted to stick with it, so I installed openSUSE Tumbleweed. This time instead of using a weird KDE + i3 setup I wanted a proper i3 setup. I messed with a plain i3 setup for a while, but it got tiresome real quick, so I looked at other DEs to find one that works with i3.</p>
<p>Long story short, I found out that <a href="https://www.xfce.org/">XFCE</a> and i3 work really great together. It takes 15 minutes to set up my desktop. Here’s how I do it:</p>
<ol style="list-style-type: decimal">
<li><p>Install a distro with a recent XFCE and i3. Install a full XFCE desktop and i3.</p></li>
<li><p><code>xfce4-session-settings</code> &gt; “Session”: Remove everything other than <code>Xfsettingsd</code> and <code>Power Manager</code>.</p></li>
<li><p><code>xfce4-session-settings</code> &gt; “Advanced”: Enable “Launch GNOME services on startup”.</p></li>
<li><p><code>xfce4-session-settings</code> &gt; “Application Autostart”: Add <code>i3</code> executable.</p></li>
</ol>
<p>That’s all you need to get a working XFCE + i3 setup! <code>i3-bar</code> will be used instead of XFCE panel (which you disabled already in step (2)). After this just configure XFCE and i3 as usual.</p>
<p>Here is some of the configurations I do:</p>
<ul>
<li><p>I add <code>/usr/bin/setxkbmap -option &quot;ctrl:nocaps&quot;</code> to <code>xfce4-settings-manager</code> &gt; “Application Autostart” to make caps lock an additional ctrl.</p></li>
<li><p>I install <code>feh</code> and run it on i3 startup to set a desktop background image (see my i3 config below).</p></li>
<li><p>I add some key bindings in <code>xfce4-keyboard-settings</code> for sound controls. Normally I add key bindings to i3 config, but it’s hard to find key names for <code>Fn + key</code> combinations and XFCE helps with that part.</p></li>
<li><p>In <code>xfce4-keyboard-settings</code> I set repeat delay 260ms and repeat speed 55 key strokes/second.</p></li>
</ul>
<p>Then I install zsh, vim etc. and generate symlinks for my <a href="https://github.com/osa1/rcbackup">configs</a>. My i3 config is <a href="https://github.com/osa1/rcbackup/blob/master/.i3/config">here</a>.</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>It probably had some security issues though…<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>There was an unofficial work on a GNOME port but it was never completed as far as I know.<a href="#fnref2">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>Papers I read in 2015-2016</title>
    <link href="http://osa1.net/posts/2016-11-15-2015-2016-papers.html" />
    <id>http://osa1.net/posts/2016-11-15-2015-2016-papers.html</id>
    <published>2016-11-15T00:00:00Z</published>
    <updated>2016-11-15T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>This is my last week at Indiana University. It’ll be almost two years (1 year 11 months) since I came here, and it’s time for me to move on. While cleaning my messy desk covered with papers today I thought maybe I should make list of papers that I read (or at least printed) during this two-year period, so here it is.</p>
<p>Papers are sorted by publication dates. <code>???</code> indicates that the publication date is unknown (or may not be published at all), and those are listed last. I’ve added some very brief notes below some of the papers. Only last names of authors are listed.</p>
<hr />
<ul>
<li><p>On computable numbers, with an application to Entscheidungsproblem – Turing. 1936.</p></li>
<li><p>Computing Machinery and Intelligence – Turing. 1950.</p>
<p>Defines “the imitation game” aka. “Turing test”. Tries to answer some philosophical questions. I remember finding some of the arguments pretty weak.</p></li>
<li><p>Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I – McCarthy. 1960.</p>
<p>A classic. Defines “garbage collection”, “free list” and “stack” for the first time, without actually using those words.</p></li>
<li><p>A basis for a mathematical theory of computation – McCarthy. 1963.</p>
<p>Haven’t read.</p></li>
<li><p>The Next 700 Programming Languages – Landin. 1966.</p>
<p>Classic.</p></li>
<li><p>A Nonrecursive List Compacting Algorithm – Cheney. 1970.</p>
<p>A classic. Only two pages. Algorithm can easily be generalized to collect arbitrary heap objects. Known as “Cheney’s algorithm” in GC literature.</p></li>
<li><p>Monotone Data Flow Analysis Frameworks – Kam, Ullman. 1975.</p></li>
<li><p>Global Data Flow Analysis and Iterative Algorithms – Kam, Ullman. 1976.</p></li>
<li><p>Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints – Cousot, Cousot. 1977.</p>
<p>Cousot &amp; Cousot, so avoid. Read “Principles of Program Analysis” (book) by Nielson, Nielson and Hanking.</p></li>
<li><p>A Real-Time Garbage Collector Based on the Lifetimes of Objects – Lieberman, Hewitt. 1983.</p>
<p>An early generational GC paper. Defines “scavenging” and “evacuation”, some of the terms used in GHC’s GC.</p></li>
<li><p>Generation Scavenging: A Non-disruptive High Performance Storage Reclamation Algorithm – Ungar. 1984.</p></li>
<li><p>Compiling Pattern Matching – Augustsson. 1985.</p>
<p>A very early paper on lazy pattern matching in LML. IIRC the idea is very simple and maybe even obvious, but this is a very early publication on the topic.</p></li>
<li><p>How to Replace Failure by a List of Successes - A method for exception handling, backtracking, and pattern matching in lazy functional languages – Wadler. 1985.</p>
<p>I don’t remember reading this.</p></li>
<li><p>Multilisp: A anguage for Concurrent Symbolic Computation – Halstead. 1985.</p>
<p>Haven’t read this.</p></li>
<li><p>Programming as Theory Building – Naur. 1985.</p>
<p>All I remember about this paper is that I disagreed very strongly with the points made. I see some notes on the paper about why analogies don’t work and are harmful.</p></li>
<li><p>Control Operators, the SECD-Machine, and the λ-Calculus – Felleisen, Friedman. 1986.</p></li>
<li><p>Hygienic Macro Expansion – Kohlbecker, Friedman, Felleisen, Duba. 1986.</p></li>
<li><p>No Silver Bullet - Essence and Accident in Software Engineering – Brooks. 1986.</p></li>
<li><p>ORBIT: An Optimizing Compiler for Scheme. Kranz, Kelsey, Rees, Hudak, Philbin, Adams. 1986.</p></li>
<li><p>The Concept of a Supercompiler – Turchin. 1986.</p>
<p>This is one of the earliest supercompilation papers published in English.</p>
<p>First supercompilation papers were in Russian. First supercompilation paper in English was “A supercompiler system based on the langauge Refal”, Turchin, 1979. I don’t know what happened in the 7 year period, but I think the next paper was this one.</p></li>
<li><p>Efficient Compilation of Pattern-Matching (The Implementation of Functional Programming Languages book chapter) – Wadler. 1987.</p></li>
<li><p>Re-opening Closures – Appel. 1987.</p>
<p>The idea is to optimize closures in runtime using captured variables. I’ve heard that Mu uses some variant of this idea.</p></li>
<li><p>The Concatenate Vanishes – Wadler, 1987.</p>
<p>An even earlier work than the deforestation one. Wadler shows how to “deforest” intermediate lists in some programs. I don’t remember how the idea worked, but it must be just a very simple case-of-case transformation.</p></li>
<li><p>Theorems for free! – Wadler. 1989.</p>
<p>Great paper, shows how parametricity leads to theorems.</p></li>
<li><p>Deforestation: Transforming programs to eliminate trees – Wadler. 1990.</p>
<p>I think this is another classic and coined the term “deforestation”. The paper makes a huge simplifying assumption and assumes that variables are used linearly in function bodies, which makes beta reduction safe in terms of work duplication. So not very useful for practical purposes.</p></li>
<li><p>Linear types can change the world! – Wadler. 1990.</p></li>
<li><p>Implementing Projection-based Strictness Analysis – Kubiak, Hughes, Launchbury. 1992.</p></li>
<li><p>Undecidability of Static Analysis – Landi. 1992.</p>
<p>IIRC this paper shows how interesting static analysis problems are undecidable, by means of reductions from known undecidable problems like the halting problem.</p></li>
<li><p>Unboxed objects and polymorphic typing – Leroy. 1992.</p></li>
<li><p>A Short Cut to Deforestation – Gill, Launchbury, Jones. 1993.</p>
<p>Introduces fold/build rules. Still in use today in GHC.</p></li>
<li><p>Metaobject protocols: Why we want them and what else they can do – Kiczales, Ashley, Rodriguez, Vahdat, Bobrow. 1993.</p></li>
<li><p>Occam’s Razor in Metacomputation: the Notion of a Perfect Process Tree – Glück, Klimov. 1993.</p>
<p>An even earlier paper on “perfect information propagation”. Uses “process trees” which are only used in very early supercompilation papers (including Turchin ones IIRC).</p></li>
<li><p>Syntactic Abstraction in Scheme – Dybvig, Hieb, Bruggeman. 1993.</p>
<p>Go IU!</p></li>
<li><p>What is a Purely Functional Language? – Sabry. 1993.</p></li>
<li><p>Partial Deduction and Driving are Equivalent – Glück, Sørensen. 1994.</p></li>
<li><p>Mix Ten Years Later – Jones. 1995.</p>
<p>I love Neil Jones’s partial evaluation work (and especially the book “Partial Evaluation and Automatic Program Generation” by Jones, Gomard, Sestoft).</p></li>
<li><p>The Design of a Pretty-printing Library – Hughes. 1995.</p></li>
<li><p>A Roadmap to Metacomputation by Supercompilation – Glück, Sørensen. 1996.</p>
<p>Shows how to use supercompilation for metaprogramming tasks “specialization”, “composition” and “inversion”. I don’t even remember what are the latter two though.</p></li>
<li><p>Building Domain-Specific Embedded Languages – Hudak. 1996.</p></li>
<li><p>On Perfect Supercompilation – Secher, Sørensen. 1996.</p>
<p>This paper shows how to do “negative information propagation” during “driving” (see Jones, 2000). “Negative” means “what forms a value cannot take”.</p>
<p>Now that I think about this idea again, I’m wondering in what sense “negative” information is special. Assuming the set of values of a type is finite, you can always express negative information as positive information, e.g. if the set contains <code>{X, Y, Z}</code> <code>cannot be X =&gt; is one of {Y, Z}</code>.</p></li>
<li><p>Realistic Compilation by Partial Evaluator – Sperber, Thiemann. 1996.</p>
<p>I love this paper. It inspired <a href="http://osa1.net/posts/2015-05-13-comp-through-interp.html">a project of mine</a>. I met the first author at ICFP’16 after coincidentally sitting next to him at lunch :) .</p></li>
<li><p>A transformation-based optimiser for Haskell – Jones, Santos. 1997.</p>
<p>Describes “let-no-escape” optimizations that is still in used today in GHC.</p></li>
<li><p>Improvement Theory and its Application – Sands. 1997.</p>
<p>The idea is used in Bolingbroke’s PhD thesis, that’s why I printed this, but I haven’t read it yet.</p></li>
<li><p>MetaML and Multi-Stage Programming with Explicit Annotations – Taha, Sheard. 1997.</p>
<p>Introduction to MetaML.</p></li>
<li><p>Definitional Interpreters for Higher-Order Programming Languages – Reynolds. 1998.</p>
<p>Classic.</p></li>
<li><p>Growing a Language – Steele. 1998.</p>
<p>Watch his talk with the same title instead, it’s awesome.</p></li>
<li><p>Positive supercompilation for a higher-order call-by-value language – Jonsson, Nordlander. 1998.</p>
<p>Funny how the pages are full of notes, yet I don’t remember anything about this paper.</p></li>
<li><p>Type Inference with Constrained Types – Odersky, Sulzmann, Wehr. 1998.</p></li>
<li><p>On the Power of Homeomorphic Embedding for Online Termination – Leuschel, 1998.</p></li>
<li><p>A semantics for imprecise exceptions – Jones, Reid, Hoare, Marlow, Henderson. 1999.</p></li>
<li><p>Call-By-Push-Value: A Subsuming Paradigm (extended abstract) – Levy. 1999.</p>
<p>Another paper that I just couldn’t finish.</p></li>
<li><p>Introduction to Supercompilation – Sørensen, Glück. 1999.</p>
<p>This is a really good introduction. It uses “process trees” which help a lot when trying to understand the idea for the first time. I made a presentation here at IU using process trees in this paper.</p></li>
<li><p>Linear Scan Register Allocation – Poletto, Sarkar. 1999.</p>
<p>Very famous algorithm, used in many JIT compilers. I think GHC also has a variant of this (see <code>compiler/nativeGen/RegAlloc/Linear</code> directory).</p></li>
<li><p>Partial Evaluation and Automatic Program Generation – Jones, Gomard, Sestoft. 1999.</p>
<p>I really like this book. I tried to implement every language in this book, but it became tiresome real quick. Best introduction to partial evaluation.</p></li>
<li><p>Secrets of the Glasgow Haskell Compiler inliner – Jones, Marlow. 1999.</p></li>
<li><p>The STG runtime system (revised) – Jones, Marlow. 1999.</p></li>
<li><p>Compiling Embedded Languages – Elliott, Finne, de Moor. 2000.</p></li>
<li><p>Type-Preserving Garbage Collectors – Wang, Appel. 2001.</p>
<p>Haven’t read this.</p></li>
<li><p>The Essence of Program Transformation by Partial Evaluation and Driving – Jones. 2000.</p>
<p>This paper defines the concept of “driving” which IIRC is also used in some early (before Mitchell and Bolingbroke papers) supercompilation papers.</p></li>
<li><p>Composable and Compilable Macros - When Want it When? – Flatt. 2002.</p></li>
<li><p>Template Meta-programming for Haskell – Sheard, Jones. 2002.</p></li>
<li><p>A Functional Correspondence between Evaluators and Abstract Machines – Ager, Biernacki, Danvy, Midtgaard. 2003.</p></li>
<li><p>From Interpreter to Compiler and Virtual Machine: A Functional Derivation – Ager, Biernacki, Danvy, Midtgaard. 2003.</p></li>
<li><p>Garbage-First Garbage Collection – Detlefts, Flood, Heller, Printezis. 2004.</p></li>
<li><p>Self-Adjusting Computation (PhD thesis) – Acar. 2005.</p>
<p>I started reading this a couple of time, failed every time. I was looking for some “automated” way of getting incremental compilation out of compiler passes that don’t take incremental compilation into account.</p></li>
<li><p>Gaussian Elimination: a case study in efficient genericity with MetaOCaml – Carette. 2005.</p></li>
<li><p>Fast and Loose Reasoning is Morally Correct – Danielsson, Hughes, Hansson, Gibbons. 2006.</p></li>
<li><p>Haskell Is Not Not ML – Rudiak-Gould, Mycroft, Jones. 2006.</p>
<p>I remember trying to read this paper many times, but I couldn’t succeed. I was thinking about an intermediate language that support both lazy and strict programs equally well.</p></li>
<li><p>Out of the Tar Pit – Moseley, Marks. 2006.</p>
<p>Defines “essential complexity” and “accidental complexity”.</p></li>
<li><p>The Development of Chez Scheme – Dybvig. 2006.</p>
<p>Chez in <a href="https://github.com/cisco/ChezScheme">now open source</a>. The runtime performance of Chez programs is good, but the compiler was a huge disappointment for me. Unreadable, undocumented mess, and the passes I was expecting to see is not there (sub-0CFA).</p></li>
<li><p>Call-pattern Specialisation for Haskell Programs – Jones. 2007.</p></li>
<li><p>Faster Laziness Using Dynamic Pointer Tagging – Marlow, Yakushev, Jones. 2007.</p>
<p>The idea is very simple and very effective. It’s in use in GHC today, and it’s saving us a lot of jumps. One of the reasons why unpacking sum types are not as useful as one might expect.</p>
<p>Over the summer 2016 one of the projects I worked on was to improve this in some cases. The problem was that in some cases (when strict fields are involved) GHC is currently not tagging some pointers even though in theory it could and that’d save us some instructions in the binaries. Unfortunately the rabbit hole goes quite deep and I had to drop it to focus on unboxed sums.</p></li>
<li><p>System F with Type Equality Coercions – Sulzmann, Chakravarty, Jones, Donnelly. 2007.</p></li>
<li><p>Generational Real-Time Garbage Collection - A Three-Part Invention for Young Objects – Frampton, Bacon, Cheng, Grove. 2007.</p>
<p>Haven’t read yet.</p></li>
<li><p>Bitcoin: A Peer-to-Peer Electronic Cash System – Satoshi Nakamoto. 2008.</p></li>
<li><p>Computation and State Machines – Lamport. 2008.</p></li>
<li><p>Finally Tagless, Partially Evaluate - Tagless Staged Interpreters for Simpler Typed Languages – Carette, Kiselyov, Shan. 2009.</p></li>
<li><p>Idempotent Work Stealing – Michael, Vechev, Saraswat. 2009.</p>
<p>This idea is used in LVish.</p></li>
<li><p>Positive Supercompilation for a Higher Order Call-By-Value Language – Jonsson, Nordlander. 2009.</p>
<p>An attempt at supercompiling a call-by-value language.</p></li>
<li><p>Supercompiler HOSC 1.0: under the hood – Klyuchnikov, 2009.</p>
<p>The author’s another paper (also listed here) is my favorite introduction to supercompilation.</p></li>
<li><p>Tracing the Meta-Level: PyPy’s Tracing JIT Compiler – Bolz, Cuni, Fijalkowski, Rigo. 2009.</p>
<p>Everything done by RPython/PyPy team is great.</p></li>
<li><p>Types are calling conventions – Bolingbroke, Jones. 2009.</p>
<p>Yet another great Bolingbroke work. I worked on a variant of this during the summer of 2016.</p></li>
<li><p>Abstracting Abstract Machines – Horn, Might. 2010.</p>
<p>I was told that this is very cool work, but I haven’t read it yet.</p></li>
<li><p>A Play on Regular Expressions – Fischer, Huch, Wilke. 2010.</p></li>
<li><p>Lightweight Modular Staging: A Pragmatic Approach to Runtime Code Generation and Compiled DSLs – Rompf, Odersky. 2010.</p>
<p>Scala LMS paper.</p></li>
<li><p>Proving the Equivalence of Higher-Order Terms by Means of Supercompilation – Klyuchnikov, Romanenko. 2010.</p></li>
<li><p>Rethinking Supercompilation – Mitchell. 2010.</p>
<p>I remember that I really liked this paper at the time. Unlike most other papers, this paper can be implemented in a couple of hours, and it works good enough. IIRC the main novelty here was the tag-bag based termination criterion, which was later developed further by Bolingbroke in first “Supercompilation by evaluation” and then in his PhD thesis.</p></li>
<li><p>Scrapping your Inefficient Engine: Using Partial Evaluation to Improve Domain-Specific Language Implementation – Brady, Hammond. 2010.</p>
<p>Introduces Idris’s partial evaluator.</p></li>
<li><p>Supercompilation by Evaluation – Bolingbroke, Jones. 2010.</p>
<p>Best supercompilation paper at the time. The record was later broken again by the author of this paper in his PhD thesis (also listed here). The author is amazing and I was depressed for a very long time after reading his papers (another notable one is “Termination Combinators Forever” which is also listed here). I’ll never be this good as a researcher.</p></li>
<li><p>Ur: Statically-Typed Metaprogramming with Type-Level Record Computation – Chilpala. 2010.</p></li>
<li><p>C4: The Continuously Concurrent Compacting Collector – Tene, Iyengar, Wolf. 2011.</p>
<p>Haven’t read yet.</p></li>
<li><p>Flow-Sensitive Type Recovery in Linear-Log Time – Adams, Keep, Midtgaard, Might, Chauhan, Dybvig. 2011.</p>
<p>Sub-0CFA for type inference. Not used in current Chez implementation as far as I can see. Goal is to eliminate runtime type checks.</p></li>
<li><p>How To Write Shared Libraries – Drepper. 2011.</p></li>
<li><p>Practical aspects of evidence-based compilation in System FC – Vytiniotis, Jones. 2011.</p>
<p>IIRC this stuff was introduced with GHC 7.2. For some reason that I can’t recall, it’s sometimes useful to return coercions in functions. This paper is about that. I don’t remember much although the paper has some notes on it.</p></li>
<li><p>Termination Combinators Forever – Bolingbroke, Jones, Vytiniotis. 2011.</p>
<p>Shows how to build online termination checkers using some primitives and combinators. Checkers are correct by construction. The implementation is used in the author’s implementation of his PhD thesis.</p></li>
<li><p>Challenges for a Trace-Based Just-In-Time Compiler for Haskell – Schilling. 2012.</p>
<p>Read his PhD thesis instead.</p></li>
<li><p>Chaperones and Impersonators: Run-time Support for Reasonable Interposition – Strickland, Tobin-Hochstadt, Findler, Flatt. 2012.</p>
<p>I have a big “NO” marked on the paper in red.</p></li>
<li><p>Explicitly Heterogeneous Metaprogramming with MetaHaskell – Mainland. 2012.</p></li>
<li><p>Self-Optimizing AST Interpreters – Würthinger, Wöß, Stadler, Duboscq, Simon, Wimmer. 2012.</p></li>
<li><p>The HERMIT in the Machine - A Plugin for the Interactive Transformation of GHC Core Language Programs – Farmer, Gill, Komp, Sculthorpe. 2012.</p></li>
<li><p>Call-by-need supercompilation (PhD thesis) – Bolingbroke. 2013.</p></li>
<li><p>Forge: Generating a High Performance DSL Implementation from a Declarative Specification – Sujeeth, Gibbons, Brown, Lee, Rompf, Odersky, Olukotun. 2013.</p>
<p>After having played with LMS and Delite a little bit, I have nothing good to say about this work. Things may be improved since then though.</p></li>
<li><p>Hybrid Partial Evaluation – Shali, Cook. 2013.</p>
<p>Cook has an introductory blog post / web page about partial evaluation which is pretty good.</p></li>
<li><p>Optimizing Data Structures in High-Level Programs – Rompf, Sujeeth, Amin, Brown, Jovanovic, Lee, Jonnalagedda, Olukotun, Odersky. 2013.</p>
<p>A Scala LMS paper. All I remember about these papers is that I didn’t like them.</p></li>
<li><p>One VM to Rule Them All – Würthinger, Wimmer, Wöß, Stadler, Duboscq, Humer, Richards, Simon, Wolczko. 2013.</p>
<p>Has 9 authors.</p></li>
<li><p>Simple and Efficient Construction of Static Single Assignment Form – Braun, Buchwalk, Hack, Leißa, Malloc, Zwinkau. 2013.</p>
<p>I think the algorithm was already known in the compilers community, but this paper publishes it first and benchmarks it.</p></li>
<li><p>Supercompiling Erlang (MSc thesis) – Weinholt. 2013.</p></li>
<li><p>Terra: A Multi-Stage Language for High-Performance Computing – DeVito, Hegarty, Aiken, Hanrahan, Vitek. 2013.</p>
<p>Terra is awesome. I talked a little bit about it in my blog posts <a href="http://osa1.net/posts/2015-05-17-staging-is-not-just-codegen.html">1</a>, <a href="http://osa1.net/posts/2015-08-09-sufficiently-smart-compiler.html">2</a>.</p></li>
<li><p>Trace-based Just-in-time Compilation for Lazy Functional Programming Languages (PhD thesis) – Schilling, 2013.</p>
<p>Two good theses published in 2013, Bolingbroke and this one. Too bad neither of them were pursued further.</p>
<p>IIRC the JIT introduction in this thesis is very easy to read, doesn’t assume a lot of background.</p></li>
<li><p>Combinators for Impure yet Hygienic Code Generation – Kameyama, Kiselyov, Shan. 2014.</p></li>
<li><p>Compiling a Reflective Language using MetaOCaml – Asai. 2014.</p>
<p>I love everything related with MetaOCaml.</p></li>
<li><p>Freeze After Writing - Quasi-Deterministic Parallel Programming with LVars – Kuper, Turon, Krishnaswami, Newton. 2014.</p></li>
<li><p>Macros that Work Together - Compile-Time Bindings, Partial Expression, and Definition Contexts – Flatt, Culpepper, Darais, Findler. 2014.</p></li>
<li><p>Modular, Higher-Order Cardinality Analysis in Theory and Practice – Sergey, Vytiniotis, Jones. 2014.</p>
<p>This is still in use in GHC today. Cardinality analysis is done as a part of demand analysis (lattice is extended to handle cardinalities).</p></li>
<li><p>Optimizing SYB Is Easy! – Adams, Farmer, Magalhaes. 2014.</p></li>
<li><p>Safe Zero-cost Coercions for Haskell (extended edition) – Breitner, Eisenberg, Jones, Weirich. 2014.</p>
<p>Another paper full of notes yet I don’t remember anything.</p></li>
<li><p>Supercompilation: Ideas and Methods – Klyuchnikov, Krustev. 2014.</p>
<p>Published in “The Monad.Reader” issue 23, this is without a doubt the best introduction to supercompilation. It’s very well written, provides great bibliography for further reading, and comes with a simple implementation. Great stuff, although the language is too simple to be useful.</p></li>
<li><p>Taming the Parallel Effect Zoo – Kuper, Todd, Tobin-Hochstadt, Newton. 2014.</p></li>
<li><p>The Kansas University Rewrite Engine - A Haskell-Embedded Strategic Programming Language with Custom Closed Universes – Sculthorpe, Frisby, Gill. 2014.</p>
<p>This is about KURE, rewrite engine that powers HERMIT. I remember that at the time I decided to implement my own rewrite combinators than fighting HERMIT API to do whatever I wanted to do.</p></li>
<li><p>Go 1.5 concurrent garbage collector pacing – Celements. 2015.</p></li>
<li><p>Static Program Analysis (lecture notes) – Møller, Schwartzbach. 2015.</p>
<p><a href="https://cs.au.dk/~amoeller/spa/" class="uri">https://cs.au.dk/~amoeller/spa/</a></p></li>
<li><p>Static Single Assignment Book (in-progress book) – “Lots of authors”. 2015 (ongoing)</p>
<p>I’m still reading this.</p></li>
<li><p>Shallow Embedding of DSLs via Online Partial Evaluation – Leißa, Boesche, Hack, Membarth, Slusallek. 2015.</p></li>
<li><p>The Design of Terra: Harnessing the Best Features of High-Level and Low-Level Languages – DeVito, Hanrahan. 2015.</p></li>
<li><p>Improving Implicit Parallelism – Trilla, Runciman. 2015.</p></li>
<li><p>K-Java: A Complete Semantics of Java – Bogdanas, Rosu. 2015.</p></li>
<li><p>Zero-Overhead Metaprogramming – Marr, Seaton, Ducasse. 2015.</p>
<p>Related with JITs, partial evaluation, and metaobject protocols. I don’t remember reading this.</p></li>
<li><p>GADTs Meet Their Match: Pattern-Matching Warnings That Account for GADTs, Guards, and Laziness – Karachalias, Schrivers, Vytiniotis, Jones. 2016.</p></li>
<li><p>Staging Generic Programming – Yallop. 2016.</p></li>
<li><p>State Machines All The Way Down - An Architecture for Dependently Typed Applications – Brady. 2016.</p></li>
</ul>
<hr />
<ul>
<li><p>Common Subexpression Elimination in a Lazy Functional Language – Chitil. ???</p>
<p>Shows how CSE can lead to more memory residency and is not always beneficial.</p></li>
<li><p>Constructed Product Result Analysis for Haskell – Baker-Finch, Glynn, Jones. ???</p>
<p>This is still a part of GHC, done during demand analysis. We recently extended this to work on sum types.</p></li>
<li><p>Demand analysis (draft, not published) – Jones, Sestoft, Hughes</p>
<p>I hate this paper because it wasted so much of my time. GHC wiki links to that, even though this is not relevant to the implementation. Read Sergey et al. instead.</p></li>
<li><p>Lecture Notes: Control Flow Analysis for Functional Languages (lecture notes) – Aldrich. ???</p></li>
<li><p>Supercompiling with Staging – Inoue. ???</p>
<p>Shows how to use MetaOCaml’s staging operators to do supercompilation-like transformations.</p></li>
<li><p>Space and Time Efficient Supercompilation (PhD thesis) – Jonsson. ???.</p></li>
<li><p>The Design and Implementation of BER MetaOCaml – Kiselyov. ???</p></li>
<li><p>The Next Stage of Staging – Inoue, Kiselyov, Kameyama. ???</p></li>
<li><p>Two Techniques for Compiling Lazy Pattern Matching – Maranget. ???</p></li>
<li><p>Warnings for pattern matching – Maranget. ???</p></li>
</ul>]]></summary>
</entry>
<entry>
    <title>More Rust problems (and a sketch of a solution)</title>
    <link href="http://osa1.net/posts/2016-09-11-more-rust-problems.html" />
    <id>http://osa1.net/posts/2016-09-11-more-rust-problems.html</id>
    <published>2016-09-11T00:00:00Z</published>
    <updated>2016-09-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>It’s a nice coincidence that after a good productive weekend of Rust hacking I saw <a href="https://hackernoon.com/why-im-dropping-rust-fd1c32986c88">this blog post</a> about why the author is dropping Rust. I’ve been doing a lot of Rust programming lately (I have at least 3 programs –not libraries– that I’m hoping to publish in the near future), and I’m surprised to see that no one mentioned in the discussion threads about this blog post what IMHO is one of the most annoying problems with Rust.</p>
<p>Borrow checker rejects some programs that are perfectly valid in other languages, and by itself this isn’t a problem. Similar things happen in all languages <a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. One of the first problems I encountered after started to write Rust was the OP’s second problem, namely, cyclic data structures (or graphs, but more specifically, widgets with parent/child relations). However, there is at least one pretty good solution for this, and all you need is to think harder and experiment with alternative designs. I’m actually very happy with my solution to this (which is also discovered independently by many people, for an example, see <a href="https://crates.io/crates/petgraph">petgraph</a>).</p>
<p>However, there are problems that basically can’t be solved in Rust without paying some runtime costs or using bad practices. See my <a href="">previous blog post</a> for some examples. In this post I’m going to show another, and more annoying, problem.</p>
<h1 id="self-borrows-all-of-its-fields"><code>self</code> borrows all of its fields</h1>
<p>This is a problem that happened in pretty much every single Rust program I’ve ever written. In a method, you can’t borrow some fields, and call another <code>&amp;mut self</code> method. This is because methods borrow the whole <code>self</code>, so you get an error saying that you can’t borrow <code>self</code> twice.</p>
<p>As an example, imagine writing a compiler. For some reason you want to collect all the variables defined in a scope, and then generate fresh variables for those. You may do something like this:</p>
<pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> FreshGen { <span class="co">/* abstract */</span> }

<span class="kw">struct</span> Var { <span class="co">/* abstract */</span> }

<span class="kw">impl</span> FreshGen {
    <span class="kw">fn</span> fresh(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; Var {
        <span class="ot">unimplemented!</span>()
    }
}

<span class="kw">struct</span> Compiler {
    fresh_gen: FreshGen,
    vars_in_scope: Vec&lt;Var&gt;,
}

<span class="kw">impl</span> Compiler {
    <span class="kw">fn</span> fresh(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; Var {
        <span class="kw">self</span>.fresh_gen.fresh()
    }

    <span class="kw">fn</span> gen_locals(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
        <span class="kw">let</span> <span class="kw">mut</span> fresh_vars = <span class="ot">vec!</span>[];
        <span class="kw">for</span> var in <span class="kw">self</span>.vars_in_scope.iter() {
            fresh_vars.push(<span class="kw">self</span>.fresh());
        }
        <span class="co">// use fresh_vars</span>
    }
}</code></pre>
<p>Can you see any problems here? When I compile this with nightly 11/9/2016, I get this annoying error message:</p>
<pre><code>error[E0502]: cannot borrow `*self` as mutable because `self.vars_in_scope` is also borrowed as immutable
  --&gt; &lt;anon&gt;:24:29
   |
23 |         for var in self.vars_in_scope.iter() {
   |                    ------------------ immutable borrow occurs here
24 |             fresh_vars.push(self.fresh());
   |                             ^^^^ mutable borrow occurs here
25 |         }
   |         - immutable borrow ends here</code></pre>
<p>So basically, <code>self.vars_in_scope</code> is borrowed from <code>self</code>, and then <code>self.fresh()</code> is called while <code>vars_in_scope</code> is still borrowed. Even though <code>self.fresh()</code> doesn’t have anything to do with <code>self.vars_in_scope</code>, this is not allowed because the compiler simply doesn’t care about what pieces of <code>self</code> methods actually borrow. For me this is probably the #1 most annoying problem with Rust.</p>
<p>Now, I believe this problem is solvable. I imagine an algorithm like this:</p>
<p>It works in two steps.</p>
<ol style="list-style-type: decimal">
<li><p>We generate, for every method, borrow sets. A borrow set is a set of fields that are, at some point in the method, borrowed from <code>self</code>.</p></li>
<li><p>For every method call statement in every method, we look at intersections of currently borrowed fields and the borrow set of callee (i.e. (1) for the method being called).</p></li>
</ol>
<p>(1) works like this:</p>
<pre><code>workset = set of all methods
caller-graph = graph of all methods, with edges from callees to callers

# initially none of methods borrow any fields
for method in methods:
    method.borrows = empty set

while workset is not empty:
    work = workset.pop()
    for statement in work.statements:
        for field in self.borrowed_at(statement):
            if not work.borrows.contains(field):
                work.borrows.insert(field)
                for caller in caller-graph[work]:
                    workset.insert(caller)</code></pre>
<p>For a statement that has a method call, <code>borrowed_at()</code> returns the borrow set of the method being called. So when we update borrow set of a method, we add its callers to the workset and <code>borrowed_at()</code> will return more variables next time, propagating the information in the graph from callees to callers.</p>
<p>Now, for the second step, we first need to generate “live ranges” of borrowed fields. Assume that they’re generated.</p>
<pre><code>for method in methods:
    for borrowed_field in method.borrows():
        for field_live_range in borrowed_field.live_ranges():
            # for methods called in the range
            for method in method_calls(field_live_range):
                if method.borrows().contains(borrowed_field):
                    error(&quot;can&#39;t borrow twice&quot;)</code></pre>
<p>I sketched this in 30 minutes so I don’t expect this to work perfectly. Also, 4-level nested for loops look scary! But this is just to give an idea of how this might be solved.</p>
<p>In the example I showed above, borrow set of <code>fresh</code> would be <code>{fresh_gen}</code>, and borrow set of <code>gen_locals</code> would be <code>{vars_in_scope, fresh_gen}</code>. Now we look at live ranges of variables borrowed from <code>self</code> in <code>gen_locals</code>.</p>
<ul>
<li><code>vars_in_scope</code> lives between lines 2-4 in the method.</li>
<li><code>fresh_gen</code> lives in line 3 in the method.</li>
</ul>
<p>Since each variable has only one live range here, clearly there won’t be any intersections. So this would pass the borrow checker.</p>
<p>If <code>fresh</code> was also borrowing <code>vars_in_scope</code>, we’d get an error because <code>vars_in_scope</code> would now have two “live ranges”: between lines 2-4 as before, and in line 3. Since those intersect, we get an error.</p>
<p>(Again, this is a very quick sketch, so let me know if I’m missing something.)</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I’m hoping to write more about this later. For now, think Haskell’s type system that separates pure functions from effectful ones as an example.<a href="#fnref1">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>I'm available for job offers</title>
    <link href="http://osa1.net/posts/2016-09-05-available-for-offers.html" />
    <id>http://osa1.net/posts/2016-09-05-available-for-offers.html</id>
    <published>2016-09-05T00:00:00Z</published>
    <updated>2016-09-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>After two years as a PhD student at Indiana University, I finally decided to move to the industry, and I’m currently available for job offers.</p>
<p>For the most part I really enjoyed my time here at Indiana University. I still think that IU is the ideal place for someone like me to pursue a PhD. We have a great <a href="http://wonks.github.io/">programming languages group</a>, and the group I work more closely (with <a href="http://www.cs.indiana.edu/~rrnewton/homepage.html">my advisor</a>) is doing lots of hacking, on GHC (we have two core GHC developers in our group!), various Haskell libraries like <a href="https://github.com/iu-parfunc/lvars">lvish</a>, and <a href="http://www.cs.indiana.edu/~rrnewton/papers/pldi16-crossmod.pdf">runtime binary instrumentation tools</a>, which I really enjoy.</p>
<p>But publications are still a big part of the life as a PhD student, and I really, really disliked everything about publishing a paper. I’ve never wanted to have great publications, I’m more interested in learning about programming languages, compilers, and related tools, and contributing to projects that I believe are contributing to the community (which is one of my motivations when contributing to GHC). I want to have a deep understanding of fundamentals of programming languages and compilers, but I also want to develop as a programmer and software engineer.</p>
<p>Graduate school just didn’t let me do these as much as I’d like, and instead forced me to write papers. After about a year it started to become clear to me that academia is not the right place for me because I will probably never enjoy writing papers or grant proposals. So I realized that the long road to PhD in the US (about 6 years usually, followed by more years as postdoc) will be mostly a waste of time, and I won’t be as successful as I want because I don’t enjoy publishing papers.</p>
<p>Sure, I can be a PL researcher/developer in the industry after a PhD. But I believe if I can find a somewhat related job right now, in a few years I can be a PL researcher/developer, without wasting my 3-4 years suffering while trying to publish papers. If I can’t find such a job, well, I think I’ll still be happier because at least I’ll be programming and be much more productive.</p>
<p>So I decided that it’s best for me to do the switch as soon as possible.</p>
<p>If you’re interested, send me an email and let’s have a chat.</p>]]></summary>
</entry>
<entry>
    <title>Add a flag to your compiler to print errors in reversed order</title>
    <link href="http://osa1.net/posts/2016-09-04-reverse-error-messages.html" />
    <id>http://osa1.net/posts/2016-09-04-reverse-error-messages.html</id>
    <published>2016-09-04T00:00:00Z</published>
    <updated>2016-09-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>About a year ago <a href="https://ghc.haskell.org/trac/ghc/ticket/10848">I opened a feature request</a> for printing error messages in reversed order in GHC. By default most compilers print error messages by sorting them by the line number that they’re originated from. This is good when you get one or two error messages because in that case messages usually fit in the screen. But when you’re middle of a big refactoring (even if it’s just renaming a type) usually what happens is, you make your changes, reload/recompile the code, scroll up for 5 seconds to find the first error, fix it, and repeat.</p>
<p>The reason you scroll up is because most of the time declarations come before uses, and fixing a declaration makes error messages originated from use sites go away.</p>
<p>With a flag that reverses the error message order this becomes much simpler because you don’t need to scroll every time you reload/recompile. So if you’re developing a compiler, please consider adding this to your compiler.</p>
<p>(If you’re a GHC user, this is available with <code>-freverse-errors</code> flag)</p>]]></summary>
</entry>
<entry>
    <title>IORef and STRef under the hood</title>
    <link href="http://osa1.net/posts/2016-07-25-IORef-STRef-exposed.html" />
    <id>http://osa1.net/posts/2016-07-25-IORef-STRef-exposed.html</id>
    <published>2016-07-25T00:00:00Z</published>
    <updated>2016-07-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>In this post we’ll take a look at internals of GHC’s mutable variables, and how they’re used by <a href="http://hackage.haskell.org/package/base-4.9.0.0/docs/Data-IORef.html"><code>IORef</code></a> and <a href="http://hackage.haskell.org/package/base-4.9.0.0/docs/Data-STRef.html"><code>STRef</code></a>. The code is copied from GHC, with minor changes for clarity.</p>
<hr />
<pre><code>λ&gt; :m + Data.IORef
λ&gt; :info IORef
newtype IORef a
  = GHC.IORef.IORef (GHC.STRef.STRef GHC.Prim.RealWorld a)
        -- Defined in ‘GHC.IORef’
instance Eq (IORef a) -- Defined in ‘GHC.IORef’</code></pre>
<p><code>GHC.IORef</code> is defined in <code>libraries/base/GHC/IORef.hs</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | A mutable variable in the &#39;IO&#39; monad</span>
<span class="kw">newtype</span> <span class="dt">IORef</span> a <span class="fu">=</span> <span class="dt">IORef</span> (<span class="dt">STRef</span> <span class="dt">RealWorld</span> a)</code></pre>
<p>We’ll look at 3 operations: read, write, and atomic modify.</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | Read the value of an &#39;IORef&#39;</span>
<span class="ot">readIORef   ::</span> <span class="dt">IORef</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> a
readIORef  (<span class="dt">IORef</span> var) <span class="fu">=</span> stToIO (readSTRef var)

<span class="co">-- | Write a new value into an &#39;IORef&#39;</span>
<span class="ot">writeIORef  ::</span> <span class="dt">IORef</span> a <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
writeIORef (<span class="dt">IORef</span> var) v <span class="fu">=</span> stToIO (writeSTRef var v)

<span class="ot">atomicModifyIORef ::</span> <span class="dt">IORef</span> a <span class="ot">-&gt;</span> (a <span class="ot">-&gt;</span> (a,b)) <span class="ot">-&gt;</span> <span class="dt">IO</span> b
atomicModifyIORef (<span class="dt">IORef</span> (<span class="dt">STRef</span> r<span class="st">#)) f = IO $ \s -&gt; atomicModifyMutVar# r# f s</span></code></pre>
<p><code>STRef</code> is defined in <code>libraries/base/GHC/STRef.hs</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- | A value of type `STRef s a` is a mutable variable in state thread `s`,</span>
<span class="co">-- containing a value of type `a`</span>
<span class="kw">data</span> <span class="dt">STRef</span> s a <span class="fu">=</span> <span class="dt">STRef</span> (<span class="dt">MutVar</span><span class="st"># s a)</span>

<span class="co">-- | Read the value of an &#39;STRef&#39;</span>
<span class="ot">readSTRef ::</span> <span class="dt">STRef</span> s a <span class="ot">-&gt;</span> <span class="dt">ST</span> s a
readSTRef (<span class="dt">STRef</span> var<span class="st">#) = ST $ \s1# -&gt; readMutVar# var# s1#</span>

<span class="co">-- | Write a new value into an &#39;STRef&#39;</span>
<span class="ot">writeSTRef ::</span> <span class="dt">STRef</span> s a <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> <span class="dt">ST</span> s ()
writeSTRef (<span class="dt">STRef</span> var<span class="st">#) val = ST $ \s1# -&gt;</span>
    <span class="kw">case</span> writeMutVar<span class="st"># var# val s1# of</span>
      s2<span class="st"># -&gt; (# s2#, () #)</span></code></pre>
<p>Note that there’s no <code>atomicModifySTRef</code>, because that only makes sense in IO context. So <code>atomicModifyIORef</code> directly calls the primop.</p>
<p>In summary:</p>
<ul>
<li>IORef: <code>MutVar#</code>, wrapped with <code>STRef</code>. When we unpack an <code>IORef</code> in data constructor fields, internally we store a <code>MutVar#</code>.</li>
<li>writeIORef, writeSTRef: <code>writeMutVar#</code></li>
<li>readIORef, readSTRef: <code>readMutVar#</code></li>
<li>atomicModifyIORef: <code>atomicModifyMutVar#</code></li>
</ul>
<h1 id="readmutvar">readMutVar#</h1>
<p>Primop definition:</p>
<pre><code>primop  ReadMutVarOp &quot;readMutVar#&quot; GenPrimOp
   MutVar# s a -&gt; State# s -&gt; (# State# s, a #)
   {Read contents of {\tt MutVar\#}. Result is not yet evaluated.}
   with
   has_side_effects = True
   can_fail         = True</code></pre>
<p>Code generation is handled by <code>StgCmmPrim.emitPrimOp</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">emitPrimOp ::</span> <span class="dt">DynFlags</span>
           <span class="ot">-&gt;</span> [<span class="dt">LocalReg</span>]        <span class="co">-- where to put the results</span>
           <span class="ot">-&gt;</span> <span class="dt">PrimOp</span>            <span class="co">-- the op</span>
           <span class="ot">-&gt;</span> [<span class="dt">CmmExpr</span>]         <span class="co">-- arguments</span>
           <span class="ot">-&gt;</span> <span class="dt">FCode</span> ()

<span class="fu">...</span>

emitPrimOp dflags [res] <span class="dt">ReadMutVarOp</span> [mutv]
   <span class="fu">=</span> emitAssign (<span class="dt">CmmLocal</span> res) (cmmLoadIndexW dflags mutv (fixedHdrSizeW dflags) (gcWord dflags))</code></pre>
<p>This is just relative addressing, base is the <code>MutVar#</code> we’re reading, and we skip the closure header to read the contents.</p>
<h1 id="writemutvar">writeMutVar#</h1>
<p>Primop definition:</p>
<pre><code>primop  WriteMutVarOp &quot;writeMutVar#&quot;  GenPrimOp
   MutVar# s a -&gt; a -&gt; State# s -&gt; State# s
   {Write contents of {\tt MutVar\#}.}
   with
   has_side_effects = True
   code_size        = { primOpCodeSizeForeignCall }
                         -- for the write barrier
   can_fail         = True</code></pre>
<p>Code generation is again implemented in <code>emitPrimOp</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">emitPrimOp dflags [] <span class="dt">WriteMutVarOp</span> [mutv,var]
   <span class="fu">=</span> <span class="kw">do</span> emitStore (cmmOffsetW dflags mutv (fixedHdrSizeW dflags)) var
        emitCCall [<span class="co">{-no results-}</span>]
                  (<span class="dt">CmmLit</span> (<span class="dt">CmmLabel</span> mkDirty_MUT_VAR_Label))
                  [(<span class="dt">CmmReg</span> (<span class="dt">CmmGlobal</span> <span class="dt">BaseReg</span>), <span class="dt">AddrHint</span>), (mutv,<span class="dt">AddrHint</span>)]</code></pre>
<p>This is more involved than <code>readMutVar#</code>. First, we write the variable to the <code>MutVar#</code> in the first line (<code>emitStore</code>). Then, we call a function, specified by the variable <code>mkDirty_MUT_VAR_Label</code>, passing two arguments: a global called <code>BaseReg</code>, and the <code>MutVar#</code>. <code>mkDirty_MUT_VAR_Label</code> just holds the name of this function: (defined in <code>rts/sm/Storage.c</code>)</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="co">/*</span>
<span class="co">   This is the write barrier for MUT_VARs, a.k.a. IORefs.  A</span>
<span class="co">   MUT_VAR_CLEAN object is not on the mutable list; a MUT_VAR_DIRTY</span>
<span class="co">   is.  When written to, a MUT_VAR_CLEAN turns into a MUT_VAR_DIRTY</span>
<span class="co">   and is put on the mutable list.</span>
<span class="co">*/</span>
<span class="dt">void</span> dirty_MUT_VAR(StgRegTable *reg, StgClosure *p)
{
    Capability *cap = regTableToCapability(reg);
    <span class="kw">if</span> (p-&gt;header.info == &amp;stg_MUT_VAR_CLEAN_info) {
        p-&gt;header.info = &amp;stg_MUT_VAR_DIRTY_info;
        recordClosureMutated(cap,p);
    }
}</code></pre>
<p>Remember that for the first argument we passed something called <code>BaseReg</code>, and for the second argument we passed the <code>MutVar#</code>.</p>
<p>This function gets a <code>Capability</code> from the register table, and if the <code>MutVar#</code> is “clean”, it marks it as “dirty” and records in the capability that it’s now mutated.</p>
<p><code>Capability</code> lacks documentation, but it’s not too important, so we just skip that and look at <code>recordClsoureMutated</code>.</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="dt">void</span> recordClosureMutated(Capability *cap, StgClosure *p)
{
    bdescr *bd = Bdescr((StgPtr)p);
    <span class="kw">if</span> (bd-&gt;gen_no != <span class="dv">0</span>) recordMutableCap(p,cap,bd-&gt;gen_no);
}</code></pre>
<p><code>p</code> is our <code>MutVar#</code> here. <code>bdescr</code> stands for “block descriptor”. GHC RTS allocates memory in blocks, and every block belongs to a generation. First generation is special in that if a <code>MutVar#</code> is in the first generation, it can’t point to a younger generation, as the first generation is already the youngest generation. This is from <code>includes/rts/storage/GC.h</code>:</p>
<pre><code>- generation 0 is the allocation area.  It is given a fixed set of blocks
  during initialisation, and these blocks normally stay in G0S0.  In parallel
  execution, each Capability has its own nursery.</code></pre>
<p>This code basically checks if the <code>MutVar#</code> belongs to first generation (generation 0). If that’s not the case, we record the <code>MutVar#</code> in the generation’s “mut list”:</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="dt">void</span> recordMutableCap(<span class="dt">const</span> StgClosure *p, Capability *cap, <span class="dt">uint32_t</span> gen)
{
    bdescr* bd = cap-&gt;mut_lists[gen];
    <span class="kw">if</span> (bd-&gt;free &gt;= bd-&gt;start + BLOCK_SIZE_W) {
        bdescr *new_bd = allocBlockOnNode_lock(cap-&gt;node);
        new_bd-&gt;link = bd;
        bd = new_bd;
        cap-&gt;mut_lists[gen] = bd;
    }
    *bd-&gt;free++ = (StgWord)p;
}</code></pre>
<p>Garbage collector then checks that list when collecting younger generations, to avoid collecting young objects kept alive by older generations (i.e. pointers from older generations to younger generations, see <code>scavenge_capability_mut_lists</code> in <code>rts/sm/Scav.c</code>).</p>
<p>We saw in <code>dirty_MUT_VAR</code> that the <code>MutVar#</code> is marked as “dirty” when it’s mutated. When is it marked as “clean” again?</p>
<p>When a <code>MutVar#</code> is copied during GC, the object pointed by it is also copied to the same generation, and then the <code>MutVar#</code> becomes clean again, because it no longer points to a younger generation. This is the related code:</p>
<pre class="sourceCode c"><code class="sourceCode c"><span class="dt">static</span> <span class="dt">void</span>
scavenge_block(bdescr *bd)
{
    ...
    <span class="kw">case</span> MUT_VAR_DIRTY:
        gct-&gt;eager_promotion = rtsFalse;
        evacuate(&amp;((StgMutVar *)p)-&gt;var);
        gct-&gt;eager_promotion = saved_eager_promotion;
        <span class="kw">if</span> (gct-&gt;failed_to_evac) {
            ((StgClosure *)q)-&gt;header.info = &amp;stg_MUT_VAR_DIRTY_info;
        } <span class="kw">else</span> {
            ((StgClosure *)q)-&gt;header.info = &amp;stg_MUT_VAR_CLEAN_info;
        }
        p += sizeofW(StgMutVar);
        <span class="kw">break</span>;
    ...
}</code></pre>
<h1 id="atomicmodifymutvar">atomicModifyMutVar#</h1>
<p>Primop definition:</p>
<pre><code>primop  AtomicModifyMutVarOp &quot;atomicModifyMutVar#&quot; GenPrimOp
   MutVar# s a -&gt; (a -&gt; b) -&gt; State# s -&gt; (# State# s, c #)
   with
   out_of_line      = True
   has_side_effects = True
   can_fail         = True</code></pre>
<p><code>out_of_line = True</code> basically tells code generator that this primop is implemented as a function. Code generator then just generates a function call:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">cgOpApp ::</span> <span class="dt">StgOp</span>        <span class="co">-- The op</span>
        <span class="ot">-&gt;</span> [<span class="dt">StgArg</span>]     <span class="co">-- Arguments</span>
        <span class="ot">-&gt;</span> <span class="dt">Type</span>         <span class="co">-- Result type (always an unboxed tuple)</span>
        <span class="ot">-&gt;</span> <span class="dt">FCode</span> <span class="dt">ReturnKind</span>

<span class="fu">...</span>

cgOpApp (<span class="dt">StgPrimOp</span> primop) args res_ty <span class="fu">=</span> <span class="kw">do</span>
    dflags <span class="ot">&lt;-</span> getDynFlags
    cmm_args <span class="ot">&lt;-</span> getNonVoidArgAmodes args
    <span class="kw">case</span> shouldInlinePrimOp dflags primop cmm_args <span class="kw">of</span>
        <span class="dt">Nothing</span> <span class="ot">-&gt;</span> <span class="kw">do</span>  <span class="co">-- out-of-line</span>
          <span class="kw">let</span> fun <span class="fu">=</span> <span class="dt">CmmLit</span> (<span class="dt">CmmLabel</span> (mkRtsPrimOpLabel primop))
          emitCall (<span class="dt">NativeNodeCall</span>, <span class="dt">NativeReturn</span>) fun cmm_args
        <span class="fu">...</span></code></pre>
<p>The primop is implemented in Cmm, in <code>rts/PrimOps.cmm</code>. The code is a mess, but here’s the important part:</p>
<pre class="sourceCode c"><code class="sourceCode c">stg_atomicModifyMutVarzh ( gcptr mv, gcptr f )
{
  ...
  retry:
    x = StgMutVar_var(mv);
    StgThunk_payload(z,<span class="dv">1</span>) = x;
<span class="ot">#ifdef THREADED_RTS</span>
    (h) = ccall cas(mv + SIZEOF_StgHeader + OFFSET_StgMutVar_var, x, y);
    <span class="kw">if</span> (h != x) { <span class="kw">goto</span> retry; }
<span class="ot">#else</span>
    StgMutVar_var(mv) = y;
<span class="ot">#endif</span>

    <span class="kw">if</span> (GET_INFO(mv) == stg_MUT_VAR_CLEAN_info) {
        ccall dirty_MUT_VAR(BaseReg <span class="st">&quot;ptr&quot;</span>, mv <span class="st">&quot;ptr&quot;</span>);
    }

    <span class="kw">return</span> (r);
}</code></pre>
<p>It’s basically a compare-and-swap loop, and in the end it marks the <code>MutVar#</code> as “dirty”, using the same <code>dirty_MUT_VAR</code> function used by the code generated for <code>writeMutVar#</code>.</p>
<h1 id="the-mutvar-struct">The <code>MutVar#</code> struct</h1>
<p>As the last thing, we look at the definition of <code>MutVar#</code>: (in <code>includes/rts/storage/Closures.h</code>)</p>
<pre><code>typedef struct {
    StgHeader   header;
    StgClosure *var;
} StgMutVar;</code></pre>
<p>Nothing interesting here. See <a href="https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects?redirectedfrom=Commentary/Rts/HeapObjects">this Wiki page</a> for GHC’s heap object layout. In our case, payload contains a single closure.</p>
<hr />
<p>This concludes our <code>MutVar#</code> (which is used under the hood for <code>IORef</code> and <code>STRef</code>) tour. I guess lessons here are:</p>
<ol style="list-style-type: decimal">
<li><p><code>readIORef</code> is fast, but <code>writeIORef</code> is one function call in the best case. In the worst case, it does an expensive allocation (this is not just a heap pointer bump). If you have a tight loop with some state variables, prefer parameter passing instead.</p></li>
<li><p>Unpacking an <code>IORef</code> in a data constructor field does not really make the constructor mutable. Instead, it inlines the <code>MutVar#</code>, which has a mutable pointer field.</p></li>
</ol>
<p>If you think about it a little bit, you may realize that optimizing (2) is actually quite tricky. Imagine having something like this:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">D</span> <span class="fu">=</span> <span class="dt">D</span> {<span class="ot"> f1 ::</span> <span class="ot">{-# UNPACK #-}</span> <span class="fu">!</span>(<span class="dt">IORef</span> <span class="dt">Int</span>)
           ,<span class="ot"> f2 ::</span> <span class="dt">Int</span>
           }

<span class="ot">bumpf1 ::</span> <span class="dt">D</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
bumpf1 (<span class="dt">D</span> f1 _) <span class="fu">=</span> modifyIORef f1 (<span class="fu">+</span> <span class="dv">1</span>)

<span class="ot">bumpf2 ::</span> <span class="dt">D</span> <span class="ot">-&gt;</span> <span class="dt">D</span>
bumpf2 (<span class="dt">D</span> f1 f2) <span class="fu">=</span> <span class="dt">D</span> f1 (f2 <span class="fu">+</span> <span class="dv">1</span>)</code></pre>
<p>You’d expect this to print <code>True</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">do</span> ref <span class="ot">&lt;-</span> newIORef <span class="dv">0</span>
   <span class="kw">let</span> d1 <span class="fu">=</span> <span class="dt">D</span> ref <span class="dv">0</span>
       d2 <span class="fu">=</span> bumpD2 d1
   bumpf1 d1
   rv1 <span class="ot">&lt;-</span> readIORef (f1 d1)
   rv2 <span class="ot">&lt;-</span> readIORef (f1 d2)
   print (rv1 <span class="fu">==</span> rv2)</code></pre>
<p>If <code>D</code> becomes mutable after the <code>UNPACK</code>, this code doesn’t work anymore, because we lose sharing after the functional update in line <code>bumpD2 d1</code>.</p>
<p>See also <a href="https://ghc.haskell.org/trac/ghc/ticket/7662#comment:3">this discussion</a> for how other compilers improve this.</p>]]></summary>
</entry>
<entry>
    <title>Unboxed sums FAQ</title>
    <link href="http://osa1.net/posts/2016-07-22-unboxed-sums-faq.html" />
    <id>http://osa1.net/posts/2016-07-22-unboxed-sums-faq.html</id>
    <published>2016-07-22T00:00:00Z</published>
    <updated>2016-07-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>The unboxed sums patch that implements unlifted, unboxed sum types (as described in <a href="https://ghc.haskell.org/trac/ghc/wiki/UnpackedSumTypes">this Wiki page</a>) was merged yesterday, and a <a href="https://www.reddit.com/r/haskell/comments/4txuo7/unboxed_sum_types_with_unpack_support_will_be_in/">/r/haskell discussion</a> emerged shortly after. As the implementor, I tried to answer questions there, but to keep answers more organized I wanted to write a blog post about it.</p>
<p>The reason I’m not writing this to the Wiki page is because this is about current plans and status of the feature. The wiki page may be updated in the future as the feature evolves and/or may be edited by others. This page reflects the current status as of today, future plans, and my own ideas.</p>
<hr />
<h2 id="syntax-is-awful-why">Syntax is awful, why?</h2>
<p>This feature is designed to complement the similar feature for product types (tuples), called <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#unboxed-tuples">“unboxed tuples”</a>. The syntax is thus chosen to reflect this idea. Instead of commas in the unboxed tuple syntax, we used bars (similar to how bars used in sum type declarations). The syntax looks bad for several reasons:</p>
<ul>
<li><p>Type argument of an alternative have to be a single type. If we want multiple types in an alternative, we have to use an unboxed tuple. For example, unboxed sum version of the type <code>data T = T1 Int | T2 String Bool</code> is <code>(# Int | (# String, Bool #) #)</code>. That’s a lot of parens and hashes.</p></li>
<li><p>Similarly, for nullary alternatives (alternatives/constructors with no arguments) we have to use empty unboxed tuples. So a bool-like type looks like <code>(# (# #) | (# #) #)</code>.</p></li>
<li><p>Data constructors use the same syntax, except we have to put spaces between bars. For example, if you have a type with 10 alternatives, you do something like <code>(# | | | | value | | | | | #)</code>. Space between bars is optional in the type syntax, but not optional in the term syntax. The reason is because otherwise we’d have to steal some existing syntax. For example, <code>(# ||| a #)</code> can be parsed as singleton unboxed tuple of <code>Control.Arrow.|||</code> applied to an argument, or an unboxed sum with 4 alternatives.</p></li>
</ul>
<p>Note that the original Wiki page for unboxed sums included a “design questions” section that discussed some alterantive syntax (see <a href="https://ghc.haskell.org/trac/ghc/wiki/UnpackedSumTypes?version=32">this version</a>). Nobody made any progress to flesh out the ideas, and I updated the Wiki page to reflect the implementation. So it was known that the syntax is not good, but it just wasn’t a major concern.</p>
<p>Answer to the second question is also an answer to this question.</p>
<h2 id="how-is-this-supposed-to-be-used-by-users">How is this supposed to be used by users?</h2>
<p>We’re not expecting users to use this type extensively. It’ll mostly be used by the compiler, for optimizations. In fact, we could have skipped the front-end syntax entirely, and it’d be OK for the most part. If you haven’t used unboxed tuples before, you probably won’t be using unboxed sums.</p>
<p>The only place you may want to use this syntax is when you’re writing a high-performance library or program, and you have a sum type that’s used strictly and can take advantage of removing a level of indirection.</p>
<h2 id="how-is-this-used-by-the-compiler">How is this used by the compiler?</h2>
<p>A detailed answer would take too long, but here’s a summary:</p>
<ul>
<li><p><a href="research.microsoft.com/en-us/um/people/simonpj/Papers/cpr/cpr.ps.gz">Constructed product analysis</a> can now be used for returning sums efficiently. Note that this feature was left as “future work” in the paper (which is from 2004. See section 3.2). The high-level idea is that if a function returns a value that <em>it constructs</em>, then instead of boxing the components of the value and returning a boxed object, it can just return the components instead. In the case where the function result is directly scrutinized (i.e. case expressions), this usually reduces allocations. In other cases, it moves the allocation from the callee to the call site, which in turn leads to stack allocation is some cases (when the object doesn’t escape from the scope).</p>
<p>For product types, unboxed tuples are used for returning the value without heap allocation. For sum types, we use unboxed sums.</p></li>
<li><p>Result of strictness (or “demand”) analysis can now be used to pass sums efficiently. As a result worker/wrapper transformations can now be done for functions that take sum arguments. See <a href="https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/Demand">this Wiki page for demand analysis</a> and <a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/usage-types/cardinality-popl14.pdf">this 2014 paper</a>.</p></li>
<li><p><code>{-# UNPACK #-}</code> pragmas now work on sum types, using unboxed sums under the hood.</p></li>
</ul>
<p>Note that none of these need a concrete syntax for unboxed sums.</p>
<hr />
<p>Hopefully this clarifies some questions and concerns, especially about the syntax. We have plenty of time until the first RC for 8.2 (<a href="https://ghc.haskell.org/trac/ghc/wiki/Status/GHC-8.2.1">mid-February 2017</a>), so it’s certainly possible to improve the syntax, and I’ll be working on that part once I’m done with the optimizations.</p>]]></summary>
</entry>

</feed>
