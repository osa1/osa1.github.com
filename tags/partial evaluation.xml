<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>osa1.net - Posts tagged partial evaluation</title>
    <link href="http://osa1.net/tags/partial%20evaluation.xml" rel="self" />
    <link href="http://osa1.net" />
    <id>http://osa1.net/tags/partial%20evaluation.xml</id>
    <author>
        <name>Ömer Sinan Ağacan</name>
        <email>omeragaca@gmail.com</email>
    </author>
    <updated>2015-05-13T00:00:00Z</updated>
    <entry>
    <title>Compilation through interpretation, a small experiment</title>
    <link href="http://osa1.net/posts/2015-05-13-comp-through-interp.html" />
    <id>http://osa1.net/posts/2015-05-13-comp-through-interp.html</id>
    <published>2015-05-13T00:00:00Z</published>
    <updated>2015-05-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I’ve been studying different program transformation techniques recently, and to me <a href="http://osa1.net/posts/2015-01-11-understanding-futamura-projections.html">Futamura projections</a> are one of the most interesting applications of program transformations. Couple of days ago I finished a small project in which I implemented first Futamura projection(aka. interpreter specialization) using <a href="http://www.madore.org/~david/programs/unlambda/">Unlambda</a> as object language. You can see the project <a href="https://github.com/osa1/int-proj">here</a>. I tried to write some comments to the source when I get stuck because of a problem or realized something interesting, so I suggest reading the source if you’re interested.</p>
<p>I did two implementations and used a different meta language for each one. There are multiple ways to achieve first Futamura projections: We can use a partial evaluator, a supercompiler(which may actually subsume partial evaluation, depending on how sophisticated it is), or just a “sufficiently smart” compiler. The problem though, we don’t have a lot of(read: any) usable implementations of partial evaluators or supercompilers, so I had to use the only language with a partial evaluator that I could find: <a href="https://github.com/idris-lang/Idris-dev">Idris</a><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</p>
<p>There’s one another technique that we can use. The techniques I listed above are all completely automated. If things don’t go as expected we’re on our own to figure out why is that and hack around to make the tool transform the program the way we want. Indeed this is happened even in this project, which is deliberately kept simple and small<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>.</p>
<p>At the other end of the spectrum is multi-stage programming. In multi-stage programming the programmer specifies, using some annotations<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>, what code to generate and how to generate it. It clearly separates code that runs in code generation time and generated code. When generated code is printed to be compiled later, multi-stage programming feels like a compiler or a partial evaluator that the programmer can guide to generate the code he/she wants.</p>
<p>My second meta language is <a href="http://okmij.org/ftp/ML/MetaOCaml.html">MetaOCaml</a>, which is basically OCaml with multi-stage programming constructs. Using these two languages as representatives of two different program generation techniques, I implemented first Futamura projections for Unlambda.</p>
<p>There’s a report file in the repository, and I refer interesting readers to that document. README file contains compilation directives and some interesting executions. One interesting thing is that I later added a simple partial evaluator to MetaOCaml implementation, and in the <code>programs/</code> directory there’s an Unlambda interpreter, written in Unlambda. Using these two programs, you can do things like partially applying(specializing) Unlambda interpreter to other programs or even itself. Before every experiment, I suggest thinking about what is the generated code you’re expecting(what does it do). What would a “sufficiently smart” partial evaluator generate? What would a simple partial evaluator generate? Similarly, try these while generating first projections.</p>
<p>Finally, if you’re interested in program transformations, stay tuned for more blog posts.</p>
<p><a href="https://github.com/osa1/int-proj">Link to the project.</a></p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>There is actually an <a href="https://github.com/annenkov/unmix">implementation of well-known partial evaluator unmix</a>. I knew about the project, but didn’t remember by the time I started this project. Still, I think I’d choose Idris even if I remembered.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Although some of those problems were implementation related, e.g. Idris was buggy. See the source code for comments and Github issues.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>In MetaOCaml case those annotations are term-level, but there are other cases where annotations happen in type level only. See <a href="http://scala-lms.github.io/">LMS</a> as an example. (I think it’s the only example for now)<a href="#fnref3">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>
<entry>
    <title>Understanding Futamura Projections</title>
    <link href="http://osa1.net/posts/2015-01-11-understanding-futamura-projections.html" />
    <id>http://osa1.net/posts/2015-01-11-understanding-futamura-projections.html</id>
    <published>2015-01-11T00:00:00Z</published>
    <updated>2015-01-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Here’s a way to understand Futamura projections<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>:</p>
<p>(Quick note: “Partial evaluator” == “specializer”. As far as I can see these words are also used interchangeably in the literature)</p>
<p>We call our specializer <code>specialize</code>. We specify languages using capital letters, <code>S</code>, <code>T</code>, <code>L</code> etc. We use Haskell syntax for applications. (e.g. <code>f a1 a2 a3</code> is a function application of <code>f</code> to three arguments, applications are left-associative in the case of currying)</p>
<p><code>specialize</code> takes two arguments, first argument is the program(function) to specialize, second argument is the input to specialize the program(function) on.</p>
<p>Note that our specializers are “correct”: For all specializer <code>s</code>, program <code>f</code> and program arguments <code>a</code> and <code>b</code>, <code>(s f a) b</code> is semantically same as <code>f a b</code>.</p>
<p>We show a specializer written in L which operates on programs written in T as <code>specialize_L_T</code>.</p>
<p>Now there are three interesting “Futamura projections”. Let’s say we have an interpreter for a language <code>L</code>, called <code>int</code>, which is written in <code>T</code>. We use <code>*</code> as a wildcard for languages. (e.g. it can be substituted with any language)</p>
<ol style="list-style-type: decimal">
<li><p><code>specialize_*_T int int_pgm</code>: We specialized the interpreter on a program <code>int_pgm</code>, resulting program is in <code>T</code>. We now have a program in <code>T</code> which just gets arguments of the interpreted program and produces output. This gives us a compiled version of <code>int_pgm</code> to <code>T</code>.</p></li>
<li><p><code>specialize_T_T specialize_T_T int</code>: We specialized the specializer on an interpreter. Generated program will be in <code>T</code>, and it’ll be expecting interpreter programs as input. The output will be specialized version of <code>int</code> for the given interpreter program. So we got a compiler for the interpreter <code>int</code>!</p>
<p>Note that specializers now need to be written in the language that they operate on. Alternatively, we could use two different specializers: One for specialize the interpreter, and one for specializing the interpreter specializer. (e.g. in most general form, we can have <code>specialize_A_B specialize_B_C int</code> where <code>int</code> is written in <code>C</code>)</p></li>
<li><p><code>specialize_T_T specialize_T_T specialize T_T</code>: This one is tricky. Let’s try to think what will be the generated program. We know from (2) is that <code>specialize_T_T specialize_T_T int</code> is a compiler for the language that <code>int</code> interprets. Now, we know from the note above that specializing doesn’t change meaning of the program, so our term from (2) <code>specialize_T_T specialize_T_T int</code> should be same with <code>(specialize_T_T specialize_T_T specialize_T_T) int</code>. What happens if we don’t apply the last <code>int</code>? Then we got a program that takes an interpreter and specializes it, resulting with a program in <code>T</code> that doesn’t expect interpreter argument. This is a compiler-compiler. Given an interpreter in <code>T</code>, it gives us a compiled version.</p></li>
</ol>
<p>Futamura projections are originally introduced in Futamura’s <a href="https://cs.au.dk/~hosc/local/HOSC-12-4-pp381-391.pdf">“Partial Evaluation of Computation Process – An Approach to a Compiler-Compiler”</a> and also described in <a href="http://www.itu.dk/people/sestoft/pebook/jonesgomardsestoft-letter.pdf">“Partial Evaluation and Automatic Program Generation”</a>.</p>
<p>Thinking about languages and interpreters are good way to have an intuition about how partial evaluation, specializing specializers etc. work, and “writing interpreters on problem domain” may be a good and general approach to solving problems<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>, but I’m wondering what interesting programs and results we would get if we apply the these to different domains. Any ideas and pointers would be appreciated.</p>
<h1 id="problem-with-implementing-the-idea">Problem with implementing the idea</h1>
<p>Implementing ideas are generally a good way to learn, but in this case it’s a bit tricky. If we want to specialize specializers(like in projection (2) and (3)) we need to write one specializer in the language that it specializes, so we need a <code>specialize_T_T</code> for a <code>T</code>.</p>
<p>To be more concrete, if we want to write the specializer in Haskell, then it has to be operating on Haskell so that we could specialize it on itself. Now this is no trivial work, Haskell is a big and complicated language.</p>
<p>On the other hand, if we want to roll our own language just to try this idea, then we’ll have to write the specializer in our language. This is also not trivial, because we need implement a language that is expressive enough to write a specializer for itself.</p>
<p>Designing a minimal language that is expressive enough to implement the idea may be a good challenge.</p>
<hr />
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Futamura projections are what you get when you apply partial evaluators to interpreters and to themselves. Have a look at <a href="http://en.wikipedia.org/wiki/Partial_evaluation#Futamura_projections">related Wikipedia page</a> and see bottom of the post for more resources.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>I recently stumbled upon this <a href="http://stackoverflow.com/questions/27852709/enterprise-patterns-with-functional-programming/27860072#27860072">SO answer</a> to a question about functional design patterns. It’s interesting how forcing yourself to a particular paradigm leads to different approaches and ways to solving problems. This is one of the reasons why I’m trying to learn a new paradigm using a language that is specifically crafted for that paradigm(e.g. Haskell for functional programming instead of Lisps, Scala etc.).<a href="#fnref2">↩</a></p></li>
</ol>
</div>]]></summary>
</entry>

</feed>
